{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research the existence of the the \"zero gamma level\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import cme_expirations as cmeexp\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import peakutils\n",
    "from peakutils.plot import plot as pplot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "from py_vollib.black.greeks import analytical as pyva\n",
    "import ipdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n",
    "from barchartacs import plotly_utilities as pu\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define methods to manipulate datetime and pandas Timestamp objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_yyyymmdd(datetime_value):\n",
    "    '''\n",
    "    convert datetime.datetime object to integer yyyymmdd, \n",
    "       like datetime.datetime(2020,11,16) to 20201116\n",
    "    '''\n",
    "    y = int(datetime_value.year)\n",
    "    m = int(datetime_value.month)\n",
    "    d = int(datetime_value.day)\n",
    "    return y*100*100 + m*100 + d\n",
    "\n",
    "def yyyymmdd_to_dt(yyyymmdd):\n",
    "    '''\n",
    "    convert integer (or str) of yyyymmdd to a datetime.dateime object\n",
    "      like 20201116 to datetime.datetime(2020,11,16)\n",
    "    (The new datetime object will be Timezone naive)\n",
    "    '''\n",
    "    y = int(str(yyyymmdd)[0:4])\n",
    "    m = int(str(yyyymmdd)[4:6])\n",
    "    d = int(str(yyyymmdd)[6:8])\n",
    "    return datetime.datetime(y,m,d)\n",
    "\n",
    "def yyyymmdd_diff(yyyymmdd_low,yyyymmdd_high):\n",
    "    '''\n",
    "    Subtract to yyyymmdd dates\n",
    "    '''\n",
    "    dt_low = yyyymmdd_to_dt(yyyymmdd_low)\n",
    "    dt_high = yyyymmdd_to_dt(yyyymmdd_high)\n",
    "    return (dt_high-dt_low).days\n",
    "\n",
    "def add_days_to_yyyymmdd(yyyymmdd,days_to_add):\n",
    "    dt = datetime.datetime.strptime(str(int(str(yyyymmdd))),'%Y%m%d')\n",
    "    new_dt = dt + datetime.timedelta(days_to_add)\n",
    "    new_yyyymmdd = int(new_dt.strftime('%Y%m%d'))\n",
    "    return new_yyyymmdd\n",
    "\n",
    "def sub_days_from_yyyymmdd(yyyymmdd,days):\n",
    "    '''\n",
    "    Subtract days from a yyyymmdd date\n",
    "    '''\n",
    "    d = yyyymmdd_to_dt(yyyymmdd)\n",
    "    d2 = d - datetime.timedelta(days)\n",
    "    return dt_to_yyyymmdd(d2)\n",
    "\n",
    "def yyyymmdd_dayofweek(yyyymmdd):\n",
    "    '''\n",
    "    Get the day of week of a yyyymdd daste\n",
    "    '''\n",
    "    return yyyymmdd_to_dt(yyyymmdd).weekday()\n",
    "\n",
    "\n",
    "def get_local_peaks_and_valleys(df_in,n,col='close'):\n",
    "    '''\n",
    "    :param df - Input DataFrame\n",
    "    :param n - number of data points that surround peak and valley\n",
    "    :param col - the data column to observe\n",
    "    '''\n",
    "    df = df_in.copy()\n",
    "    # Find local peaks\n",
    "    df['valley'] = df.iloc[argrelextrema(df[col].values, np.less_equal, order=n)[0]][col]\n",
    "    df['peak'] = df.iloc[argrelextrema(df[col].values, np.greater_equal, order=n)[0]][col]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "select * from {futtab} where substring(symbol,1,2)='ES' and settle_date>='20100101'\n",
    "\"\"\"\n",
    "df_es = pga.get_sql(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es.settle_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get begin and end dates for volskew analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _get_last_dt(exp_dt,days_back):\n",
    "    '''\n",
    "    Change a pandas timestamp into a yyyymmdd integer that is days_back from the timestamp\n",
    "    '''\n",
    "    exp_back = exp_dt - datetime.timedelta(days_back)\n",
    "    exp_back_yyyymmdd =  int(exp_back.strftime('%Y%m%d'))\n",
    "    return exp_back_yyyymmdd\n",
    "    \n",
    "syms = [s for s in df_es.symbol.unique() if s != 'ESY99']\n",
    "df_es_syms = pd.DataFrame({'symbol':syms})\n",
    "df_es_syms['sym2'] = df_es_syms.symbol.str.slice(0,2) + df_es_syms.symbol.str.slice(-2,) + df_es_syms.symbol.str.slice(2,3)\n",
    "df_es_syms = df_es_syms.sort_values('sym2')\n",
    "df_es_syms.index = range(len(df_es_syms))\n",
    "df_es_syms = df_es_syms[['symbol']].copy()\n",
    "df_es_syms['expiry'] = df_es_syms.symbol.apply(cmeexp.get_expiry)\n",
    "df_es_syms['last_dt'] = df_es_syms.expiry.apply(lambda exp_date:_get_last_dt(exp_date,30))\n",
    "df_es_syms['first_dt'] = df_es_syms.last_dt.shift(1)\n",
    "df_es_syms.loc[0,'first_dt'] = add_days_to_yyyymmdd(int(df_es_syms.loc[0,'last_dt']),-90)\n",
    "df_es_syms.first_dt = df_es_syms.first_dt.astype(int)\n",
    "df_es_syms.first_dt = df_es_syms.first_dt.apply(lambda fd:add_days_to_yyyymmdd(fd,1))\n",
    "df_es_syms = df_es_syms[['symbol','first_dt','last_dt']].copy()\n",
    "df_es_syms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph changes in ATM vol and price to see how often large changes occur around expirations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_final_es = pd.read_csv('./temp_folder/df_iv_final_ES.csv')\n",
    "df_iv_final_es_atm = df_iv_final_es[df_iv_final_es.moneyness==0][['settle_date','atm_iv','close_y']]\n",
    "df_iv_skew_es = pd.read_csv('./temp_folder/df_iv_skew_ES.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iv_skew_es2 = df_iv_skew_es.merge(df_iv_final_es_atm,how='inner',on='settle_date')\n",
    "df_iv_skew_es2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __skew_delta(r,c):\n",
    "    F = r.close_y\n",
    "    K = (1+r[c]) * F\n",
    "    t = r[colmap['dte']]/365\n",
    "    iv = r[colmap['iv']] if 'iv' in _COLMAP else np.nan\n",
    "    cl = r[colmap[opt_col]]\n",
    "    \n",
    "df_iv_skew_es2.iloc[:1].apply(\n",
    "    lambda r: (\n",
    "        \"c\",r.close_y,r[0]+r.close_y,\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_final_es_atm = get_local_peaks_and_valleys(df_iv_final_es_atm,n=100,col='atm_iv')\n",
    "df_iv_final_es_atm.peak = df_iv_final_es_atm.peak.fillna(0)\n",
    "df_iv_final_es_atm.valley = df_iv_final_es_atm.valley.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pu.plotly_plot(\n",
    "    df_iv_final_es_atm,x_column='settle_date',\n",
    "    yaxis2_cols=['close_y'],\n",
    "    plot_title=\"Show the Dates of Peak Vol Points\",\n",
    "    y_left_label=\"ATM Vol\",\n",
    "    y_right_label=\"E-Mini SP Price\",\n",
    "    number_of_ticks_display=30\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the dollar amount of open interest in the CME E-mini options to that of SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_spy = yf.Ticker('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_exps = tick_spy.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get options for each expiration\n",
    "df_spy_options = pd.DataFrame()\n",
    "for exp in spy_exps:\n",
    "    opt = tick_spy.option_chain(exp)\n",
    "    opt = pd.DataFrame().append(opt.calls).append(opt.puts)\n",
    "    opt['expirationDate'] = exp\n",
    "    df_spy_options = df_spy_options.append(opt, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_sum = df_spy_options.openInterest.sum()\n",
    "spy_dollar_sum = spy_sum * 100\n",
    "print(f'Dollar volume of open interest in SPY options = {spy_dollar_sum/1000000} (millions)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pga = db_info.get_db_info('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_sql = f\"\"\"\n",
    "select * from {opttab} where settle_date=20210721 and substring(symbol,1,2)='ES'\n",
    "\"\"\"\n",
    "df_es_db = pga.get_sql(es_sql)\n",
    "es_sum = df_es_db.open_interest.sum()\n",
    "es_dollar_sum = es_sum * 5000\n",
    "print(f'Dollar volume of open interest in SPY options = {es_dollar_sum/1000000} (millions)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_sql_fut = f\"\"\"\n",
    "select * from {futtab} where settle_date=20210721 and substring(symbol,1,2)='ES'\n",
    "\"\"\"\n",
    "df_es_db_fut = pga.get_sql(es_sql_fut)[['symbol','close']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delta(r,inc=0.0025,fut_in=None,fut_col='close_y'):\n",
    "#     fut = r[fut_col] if fut_in is None else fut_in\n",
    "#     fut_up = fut + inc\n",
    "#     fut_down = fut - inc\n",
    "#     price = black.black(r.pc.lower(),fut,r.strike,.02,r.dte/365,r.iv)\n",
    "#     price_up = black.black(r.pc.lower(),fut_up,r.strike,.02,r.dte/365,r.iv)\n",
    "#     price_down = black.black(r.pc.lower(),fut_down,r.strike,.02,r.dte/365,r.iv)\n",
    "#     delta = ((price_up-price)/inc + (price - price_down)/inc)/2\n",
    "#     return delta\n",
    "\n",
    "# def gamma(r,inc=0.0025,fut_in=None,fut_col='close_y'):\n",
    "#     delta_flat = delta(r,inc=inc,fut_in=r[fut_col])\n",
    "#     delta_up = delta(r,inc=inc,fut_in=r[fut_col]+inc)\n",
    "#     delta_down = delta(r,inc=inc,fut_in=r[fut_col]-inc)\n",
    "#     gamma = ((delta_up - delta_flat)/inc + (delta_flat - delta_down)/inc)/2  \n",
    "#     return gamma\n",
    "\n",
    "# def vega(r,inc=0.0025,fut_in=None,fut_col='close_y'):\n",
    "#     return black.greeks.analytical.vega(r.pc.lower(),r[fut_col],r.strike,.02,r.dte/365,r.iv)\n",
    "\n",
    "def delta(r,inc=0.0025,fut_in=None,fut_col='close_y',rt=.02):\n",
    "    fut = r[fut_col] if fut_in is None else fut_in\n",
    "    return pyva.delta(r.pc.lower(),r[fut_col],r.strike,rt,r.dte/365,r.iv)\n",
    "\n",
    "def gamma(r,inc=0.0025,fut_in=None,fut_col='close_y',rt=.02):\n",
    "    fut = r[fut_col] if fut_in is None else fut_in\n",
    "    return pyva.gamma(r.pc.lower(),r[fut_col],r.strike,rt,r.dte/365,r.iv)\n",
    "\n",
    "def vega(r,inc=0.0025,fut_in=None,fut_col='close_y',rt=.02):\n",
    "    fut = r[fut_col] if fut_in is None else fut_in\n",
    "    return pyva.vega(r.pc.lower(),r[fut_col],r.strike,rt,r.dte/365,r.iv)\n",
    "\n",
    "\n",
    "def lam_pyvol(r,opt_col='close_x',fut_col='close_y'):\n",
    "    try:\n",
    "        return implied_volatility.implied_volatility(r[opt_col],r[fut_col],r.strike,.02,r.dte/365, r.pc.lower())\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def get_dte(sym,dt_now):\n",
    "    exp_date = cmeexp.get_expiry(sym)\n",
    "    dte = None if exp_date is None else (exp_date - dt_now).days\n",
    "    return dte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms = df_es_db.symbol.unique()\n",
    "dtes = [get_dte(s,datetime.datetime.now()) for s in syms]\n",
    "df_dte = pd.DataFrame({'symbol':syms,'dte':dtes})\n",
    "df_es_db2 = df_es_db.copy()\n",
    "df_es_db2 = df_es_db2.merge(df_dte,on='symbol',how='inner')\n",
    "\n",
    "df_es_db2 = df_es_db2.merge(df_es_db_fut,on='symbol',how='inner')\n",
    "df_es_db2['iv'] = df_es_db2.apply(lam_pyvol,axis=1)\n",
    "df_es_db2['delta'] = df_es_db2.apply(delta,axis=1)\n",
    "df_es_db2['gamma'] = df_es_db2.apply(gamma,axis=1)\n",
    "df_es_db2['gamma_oi'] = df_es_db2.gamma * df_es_db2.open_interest\n",
    "df_es_db2_gb = df_es_db2[['strike','gamma_oi']].groupby('strike',as_index=False).sum()\n",
    "fut_value = df_es_db2.close_y.iloc[0]\n",
    "sdate =  df_es_db2.settle_date.iloc[0]\n",
    "sdate = f'{str(sdate)[0:4]}-{str(sdate)[4:6]}-{str(sdate)[6:8]}'\n",
    "fig_oi = pu.plotly_plot(\n",
    "    df_es_db2_gb[df_es_db2_gb.gamma_oi>=1],\n",
    "    x_column='strike',bar_plot=True,\n",
    "    plot_title = f'Gamma X Open Interest vs Strike <br> With the Market at {fut_value} on {sdate}',\n",
    "    y_left_label='Gamma X Open Interest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dashtable(\n",
    "    dtable_id,\n",
    "    df_in,\n",
    "    left_align_cols = None,\n",
    "    editable=False,\n",
    "    filtering=False,\n",
    "    columns_to_display=None,\n",
    "    editable_columns=None,\n",
    "    max_width='90vw',\n",
    "    displayed_rows=20,\n",
    "):\n",
    "    left_cols = [] if left_align_cols is None else left_align_cols\n",
    "    ed_cols = [] if editable_columns is None else editable_columns\n",
    "    # create filter_action\n",
    "    filter_action = 'none'\n",
    "    if filtering:\n",
    "        filter_action = 'fe'\n",
    "    \n",
    "    dt = dash_table.DataTable(\n",
    "        page_current= 0,\n",
    "        page_size=displayed_rows,\n",
    "        filter_action=filter_action,\n",
    "        style_data_conditional=[\n",
    "            {\n",
    "                'if': {'row_index': 'odd'},\n",
    "                'backgroundColor': 'rgb(248, 248, 248)'\n",
    "            }\n",
    "        ],\n",
    "        style_cell_conditional=[\n",
    "            {\n",
    "                'if': {'column_id': c},\n",
    "                'textAlign': 'left',\n",
    "            } for c in left_cols\n",
    "        ],\n",
    "\n",
    "        style_as_list_view=False,\n",
    "        style_table={\n",
    "            'overflowX':'scroll','overflowY':'scroll',\n",
    "            'maxWidth': max_width\n",
    "        } ,\n",
    "        \n",
    "        style_data={\n",
    "            'whiteSpace': 'normal',\n",
    "            'height': 'auto'\n",
    "        },        \n",
    "        editable=editable,\n",
    "        css=[{\"selector\": \"table\"},{'selector': '.row', 'rule': 'margin: 0'}],   \n",
    "        id=dtable_id,\n",
    "    )\n",
    "    dt.data=df_in.to_dict('rows')\n",
    "    dt.columns=[{\"name\": i, \"id\": i,'editable': True if i in ed_cols else False} for i in df_in.columns.values]                    \n",
    "    \n",
    "    return dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_title():\n",
    "    title_div = html.Div(\n",
    "        [\n",
    "            html.Center(html.H4(\"Do Peaks in ATM Vol (and Valleys in Price)\")),\n",
    "            html.Center(html.H4(\"Occur Near Options Expirations?\")),\n",
    "        ]\n",
    "    )\n",
    "    return title_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_div = make_title(input_list=None)\n",
    "top_container = dbc.Container(\n",
    "#     [\n",
    "#             dbc.Card(\n",
    "#                 body=True\n",
    "#             )\n",
    "#     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = get_local_peaks_and_valleys(df_iv_final_es_atm,n=100,col='atm_iv')[['settle_date','peak']]\n",
    "df_peaks = df_peaks[~df_peaks.peak.isna()]\n",
    "df_peaks.settle_date = df_peaks.settle_date.apply(lambda i:f'{str(i)[0:4]}-{str(i)[4:6]}-{str(i)[6:8]}')\n",
    "df_peaks.peak = df_peaks.peak.round(4)\n",
    "df_peaks = df_peaks.rename(columns={'settle_date':'Peak Date','peak':'Peak Value'})\n",
    "dtable = make_dashtable(\n",
    "    'peaks_dtab',df_peaks,left_align_cols=['settle_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_app_page(input_list=None):\n",
    "    layout = dbc.Container(\n",
    "        [\n",
    "            dbc.Row(dbc.Col(dcc.Graph(figure=fig))),\n",
    "            dbc.Row(dbc.Col(dcc.Graph(figure=fig_oi))),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(\n",
    "                        [\n",
    "                            dbc.Row(\n",
    "                                dbc.Col(html.H4(html.Center(\"Dates of Peaks\")))\n",
    "                            ),\n",
    "                            dbc.Row(dbc.Col(dtable)),\n",
    "\n",
    "                        ],width={'size':8,'offset':2}\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    return layout\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_APP=True\n",
    "if RUN_APP:\n",
    "    app = dash.Dash(external_stylesheets=[dbc.themes.CERULEAN])\n",
    "    # create input\n",
    "    app.layout = html.Div(\n",
    "        [\n",
    "            dbc.Row(dbc.Col(html.Div([make_title()],id='title_div'),width={'size':8,'offset':2})),\n",
    "            top_container,\n",
    "            dcc.Loading(children=[\n",
    "                html.Div([make_app_page()],id='layout_div'),\n",
    "            ],type='cube',fullscreen=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    app.run_server(debug=False, port=8884)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_inputs(r,colmap,opt_col='close',fut_col='future'):\n",
    "    flag = r[colmap['pc']].lower()\n",
    "    F = r[colmap[fut_col]]\n",
    "    K = r[colmap['strike']]\n",
    "    t = r[colmap['dte']]/365\n",
    "    iv = r[colmap['iv']] if 'iv' in _COLMAP else np.nan\n",
    "    cl = r[colmap[opt_col]]\n",
    "    return flag,F,K,t,iv,cl\n",
    "\n",
    "def __lam_pyvol(r,colmap,rt=.02):\n",
    "    inputs = _get_inputs(r,colmap)\n",
    "    try:\n",
    "        flag = inputs[0]\n",
    "        F = inputs[1]\n",
    "        K = inputs[2]\n",
    "        t = inputs[3]\n",
    "        iv = inputs[4]\n",
    "        opt_pr = inputs[5]\n",
    "        return implied_volatility.implied_volatility(opt_pr,F,K,rt,t,flag)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def __delta(r,colmap,rt=0.02):\n",
    "    inputs = _get_inputs(r,colmap)\n",
    "    try:\n",
    "        flag = inputs[0]\n",
    "        F = inputs[1]\n",
    "        K = inputs[2]\n",
    "        t = inputs[3]\n",
    "        iv = inputs[4]\n",
    "        return pyva.delta(flag,F,K,t,rt,iv)\n",
    "    except:\n",
    "        print(flag,F,K,t,iv)\n",
    "        return pyva.delta(flag,F,K,t,rt,iv)\n",
    "\n",
    "def __gamma(r,colmap,rt=0.02):\n",
    "    inputs = _get_inputs(r,colmap)\n",
    "    try:\n",
    "        flag = inputs[0]\n",
    "        F = inputs[1]\n",
    "        K = inputs[2]\n",
    "        t = inputs[3]\n",
    "        iv = inputs[4]\n",
    "        return pyva.gamma(flag,F,K,t,rt,iv)\n",
    "    except:\n",
    "        print(flag,F,K,t,iv)\n",
    "        return pyva.gamma(flag,F,K,t,rt,iv)\n",
    "    \n",
    "def __vega(r,colmap,rt=0.02):\n",
    "    inputs = _get_inputs(r,colmap)\n",
    "    try:\n",
    "        flag = inputs[0]\n",
    "        F = inputs[1]\n",
    "        K = inputs[2]\n",
    "        t = inputs[3]\n",
    "        iv = inputs[4]\n",
    "        return pyva.vega(flag,F,K,t,rt,iv)\n",
    "    except:\n",
    "        print(flag,F,K,t,iv)\n",
    "        return pyva.vega(flag,F,K,t,rt,iv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a,b in [(1,3),[2,4]]:\n",
    "    print(a)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECREATE_ALL_DATES = True\n",
    "if RECREATE_ALL_DATES:\n",
    "    base_yyyymmdd = 20180101\n",
    "    es_sql_opt_all_dates = f\"\"\"\n",
    "    select opt.* from {opttab} opt\n",
    "    where substring(opt.symbol,1,2)='ES' \n",
    "    and opt.settle_date > {base_yyyymmdd}\n",
    "    \"\"\"\n",
    "    bg = datetime.datetime.now()\n",
    "    print(f'beg opt fetch {bg}',end=', ')    \n",
    "    df_es_opt_db_all_dates = pga.get_sql(es_sql_opt_all_dates)\n",
    "    print(f'time opt fetch {(datetime.datetime.now() - bg).seconds/60}')\n",
    "\n",
    "    es_sql_fut_all_dates = f\"\"\"\n",
    "    select fut.* from {futtab} fut\n",
    "    where substring(fut.symbol,1,2)='ES' \n",
    "    and fut.settle_date > {base_yyyymmdd}\n",
    "    \"\"\"\n",
    "    bg = datetime.datetime.now()\n",
    "    print(f'beg fut fetch {bg}',end=', ')    \n",
    "    df_es_fut_db_all_dates = pga.get_sql(es_sql_fut_all_dates)[['settle_date','symbol','close']]\n",
    "    print(f'time fut fetch {(datetime.datetime.now() - bg).seconds/60}')\n",
    "\n",
    "    df_es_fut_db_all_dates = df_es_fut_db_all_dates.rename(columns={'close':'future'})\n",
    "    df_es_db_all_dates = df_es_opt_db_all_dates.merge(\n",
    "        df_es_fut_db_all_dates,\n",
    "        on=['settle_date','symbol'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(f'df_es_db_all_dates len = {len(df_es_db_all_dates)}')\n",
    "    df_sym_dates = df_es_db_all_dates[['symbol','settle_date','future']].groupby(\n",
    "        ['symbol','settle_date'],as_index=False,\n",
    "    ).count()[['symbol','settle_date']]\n",
    "    \n",
    "    print(f'calculate dte values')\n",
    "    df_sym_dates = df_es_db_all_dates[['symbol','settle_date','future']].groupby(\n",
    "        ['symbol','settle_date'],as_index=False,\n",
    "    ).count()[['symbol','settle_date']]\n",
    "    df_sym_dates['settle_dt'] = [datetime.datetime.strptime(str(d),'%Y%m%d') for d in df_sym_dates.settle_date.values]\n",
    "    df_sym_dates['dte'] = [get_dte(arr[0],arr[1]) for arr in df_sym_dates[['symbol','settle_dt']].values]\n",
    "\n",
    "    print(f'Merge dtes with main data in df_es_db_all_dates')\n",
    "    df_es_db_all_dates = df_es_db_all_dates.merge(\n",
    "        df_sym_dates[['symbol','settle_date','dte']],\n",
    "        on=['symbol','settle_date'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    df_es_db_all_dates = df_es_db_all_dates[df_es_db_all_dates.dte!=0].copy()\n",
    "        \n",
    "    bg = datetime.datetime.now()\n",
    "    print(f'beg iv {bg}',end=', ')\n",
    "    _COLMAP = {df_es_db_all_dates.columns.values[i]:i for i in range(len(df_es_db_all_dates.columns.values))}\n",
    "    vals = df_es_db_all_dates.values\n",
    "    df_es_db_all_dates['iv'] = [__lam_pyvol(r,_COLMAP) for r in vals]\n",
    "    print(f'time iv {(datetime.datetime.now() - bg).seconds/60}')\n",
    "\n",
    "    for c,f in [('delta',__delta),('gamma',__gamma),('vega',__vega)]:\n",
    "        bg = datetime.datetime.now()\n",
    "        print(f'beg {c} {bg}',end=', ')\n",
    "        _COLMAP = {df_es_db_all_dates.columns.values[i]:i for i in range(len(df_es_db_all_dates.columns.values))}\n",
    "        vals = df_es_db_all_dates.values\n",
    "        df_es_db_all_dates[c] = [f(r,_COLMAP) for r in vals]\n",
    "        print(f'time {c} {(datetime.datetime.now() - bg).seconds/60}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_greek(greek_col):\n",
    "    oi_col = f'{greek_col}_oi'\n",
    "    if len(greek_col) <= 0:\n",
    "        df_es_db_all_dates[oi_col] = df_es_db_all_dates.open_interest\n",
    "    else:\n",
    "        df_es_db_all_dates[oi_col] = df_es_db_all_dates[greek_col].abs() * df_es_db_all_dates.open_interest\n",
    "\n",
    "    df_es_db_all_dates_gb_oi = df_es_db_all_dates[['settle_date',oi_col]].groupby(\n",
    "        'settle_date',as_index=False).sum()\n",
    "    df_es_db_all_dates_gb_oi = df_es_db_all_dates_gb_oi.merge(df_es_99,on='settle_date',how='inner')\n",
    "    return pu.plotly_plot(\n",
    "        df_es_db_all_dates_gb_oi,x_column='settle_date',\n",
    "        yaxis2_cols=[oi_col],\n",
    "        plot_title=f\"graph {oi_col.replace('_',' ')}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in ['','gamma','delta','vega']:\n",
    "    display.display(graph_greek(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_db_all_dates[df_es_db_all_dates.settle_date==20210721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sym_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_final_es = pd.read_csv('./temp_folder/df_iv_final_ES.csv')\n",
    "df_iv_final_es_atm = df_iv_final_es[df_iv_final_es.moneyness==0][['settle_date','atm_iv','close_y']]\n",
    "df_iv_skew_es = pd.read_csv('./temp_folder/df_iv_skew_ES.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_skew_es2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyva.gamma(flag, F, K, t, r, sigma)\n",
    "gamma_low =  pyva.gamma(\"c\",100,102,30/365,.02,.12)\n",
    "gamma_high = pyva.gamma(\"c\",100,102,30/365,.02,.30)\n",
    "gamma_low,gamma_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __skew_greek(r,greek_func,c,rt=0.02):\n",
    "    F = r.close_y\n",
    "    K = (1+c) * F\n",
    "    t = r.dte/365\n",
    "    iv = r.atm_iv + r[str(c)]\n",
    "    if np.isnan(iv):\n",
    "        return np.nan\n",
    "    opt_price = r[str(c)]\n",
    "    pc = \"p\" if c<0 else \"c\"\n",
    "    d = greek_func(pc,F,K,t,rt,iv)\n",
    "    return d\n",
    "\n",
    "def __skew_delta(r,c,rt=0.02):\n",
    "    return __skew_greek(r,pyva.delta,c,rt=rt)\n",
    "def __skew_gamma(r,c,rt=0.02):\n",
    "    return round(__skew_greek(r,pyva.gamma,c,rt=rt) * 1000,6)\n",
    "def __skew_vega(r,c,rt=0.02):\n",
    "    return __skew_greek(r,pyva.vega,c,rt=rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_skew_es2 = df_iv_skew_es.merge(df_iv_final_es_atm,how='inner',on='settle_date')\n",
    "df_iv_skew_es2 = df_iv_skew_es2.merge(\n",
    "    df_sym_dates[['symbol','settle_date','dte']],\n",
    "    on=['symbol','settle_date'],\n",
    "    how='inner'\n",
    ")\n",
    "df_iv_skew_es2 = df_iv_skew_es2[df_iv_skew_es2.dte>0].copy()\n",
    "\n",
    "skew_cols = []\n",
    "for c in df_iv_skew_es2.columns.values:\n",
    "    try:\n",
    "        skew_cols.append(float(c))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for f in [('gamma',__skew_gamma),('delta',__skew_delta),('vega',__skew_vega)]:    \n",
    "    for c in skew_cols:\n",
    "        label = f[0]\n",
    "        func = f[1]\n",
    "        df_iv_skew_es2[f'{label}_{c}'] = df_iv_skew_es2.apply(lambda r:func(r,c),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cols = [c for c in df_iv_skew_es2.columns.values if 'vega_' in c] \n",
    "c1 = df_iv_skew_es2.settle_date>=20210601\n",
    "c2 = df_iv_skew_es2.settle_date<=20210630\n",
    "c_all = c1 & c2\n",
    "df_iv_skew_trans = df_iv_skew_es2[c_all][g_cols].transpose()\n",
    "df_iv_skew_trans.columns = [str(v) for v in df_iv_skew_es2[c_all].settle_date.values]\n",
    "df_iv_skew_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfivst = df_iv_skew_trans[df_iv_skew_trans.columns.values]\n",
    "# dfivst['settle_date'] = dfivst.index\n",
    "greek_type = dfivst.index.values[0].split('_')[0]\n",
    "title = f\"{greek_type} per % out of money\"\n",
    "pu.plotly_plot(dfivst,x_column=None,plot_title=title,y_left_label=greek_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
