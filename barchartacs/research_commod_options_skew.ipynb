{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research various skew related topics\n",
    "* **This requires plotly 4.0 or greater** *\n",
    "\n",
    "### Analyse options volatility in futures contract, creating graphs that show vertical skew historically over time, and also show skew vs futures prices over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import cme_expirations as cmeexp\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bash barchartacs_step_03_specify_months.sh 'sep' 2020 2020 True local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "select * from {futtab} where symbol='CLF21' and settle_date>='20200101'\n",
    "\"\"\"\n",
    "df_clf21 = pga.get_sql(sql)\n",
    "df_clf21[(df_clf21.settle_date>=20200801) & (df_clf21.settle_date<=20201001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "select * from {opttab} where symbol='CLF21' and settle_date>='20200101' \n",
    "and strike = 50.0 and pc='P'\n",
    "\"\"\"\n",
    "df_clf21 = pga.get_sql(sql)\n",
    "df_clf21[(df_clf21.settle_date>=20200801) & (df_clf21.settle_date<=20201001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define methods to graph skew, and create subplots with separate legends.  \n",
    "\n",
    "#### This only works with plotly 4..0 and above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_yyyymmdd(datetime_value):\n",
    "    '''\n",
    "    convert datetime.datetime object to integer yyyymmdd, \n",
    "       like datetime.datetime(2020,11,16) to 20201116\n",
    "    '''\n",
    "    y = int(datetime_value.year)\n",
    "    m = int(datetime_value.month)\n",
    "    d = int(datetime_value.day)\n",
    "    return y*100*100 + m*100 + d\n",
    "\n",
    "def yyyymmdd_to_dt(yyyymmdd):\n",
    "    '''\n",
    "    convert integer (or str) of yyyymmdd to a datetime.dateime object\n",
    "      like 20201116 to datetime.datetime(2020,11,16)\n",
    "    (The new datetime object will be Timezone naive)\n",
    "    '''\n",
    "    y = int(str(yyyymmdd)[0:4])\n",
    "    m = int(str(yyyymmdd)[4:6])\n",
    "    d = int(str(yyyymmdd)[6:8])\n",
    "    return datetime.datetime(y,m,d)\n",
    "\n",
    "def yyyymmdd_diff(yyyymmdd_low,yyyymmdd_high):\n",
    "    '''\n",
    "    Subtract to yyyymmdd dates\n",
    "    '''\n",
    "    dt_low = yyyymmdd_to_dt(yyyymmdd_low)\n",
    "    dt_high = yyyymmdd_to_dt(yyyymmdd_high)\n",
    "    return (dt_high-dt_low).days\n",
    "\n",
    "def sub_days_from_yyyymmdd(yyyymmdd,days):\n",
    "    '''\n",
    "    Subtract days from a yyyymmdd date\n",
    "    '''\n",
    "    d = yyyymmdd_to_dt(yyyymmdd)\n",
    "    d2 = d - datetime.timedelta(days)\n",
    "    return dt_to_yyyymmdd(d2)\n",
    "\n",
    "def yyyymmdd_dayofweek(yyyymmdd):\n",
    "    '''\n",
    "    Get the day of week of a yyyymdd daste\n",
    "    '''\n",
    "    return yyyymmdd_to_dt(yyyymmdd).weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_crosshairs(fig):\n",
    "    ''' add crosshairs to plotly_plot figure\n",
    "    '''\n",
    "    fig['layout'].hovermode='x'\n",
    "    fig['layout'].yaxis.showspikes=True\n",
    "    fig['layout'].xaxis.showspikes=True\n",
    "    fig['layout'].yaxis.spikemode=\"toaxis+across\"\n",
    "    fig['layout'].xaxis.spikemode=\"toaxis+across\"\n",
    "    fig['layout'].yaxis.spikedash=\"solid\"\n",
    "    fig['layout'].xaxis.spikedash=\"solid\"\n",
    "    fig['layout'].yaxis.spikethickness=1\n",
    "    fig['layout'].xaxis.spikethickness=1\n",
    "    fig['layout'].spikedistance=1000\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plotly_plot(df_in,x_column,plot_title=None,\n",
    "                y_left_label=None,y_right_label=None,\n",
    "                bar_plot=False,width=800,height=400,\n",
    "                number_of_ticks_display=20,\n",
    "                yaxis2_cols=None,\n",
    "                x_value_labels=None,\n",
    "                modebar_orientation='v',modebar_color='grey',\n",
    "                legend_x=None,legend_y=None,\n",
    "                title_y_pos = 0.9,\n",
    "                title_x_pos = 0.5):\n",
    "    '''\n",
    "    Plot and x/y graph\n",
    "    '''\n",
    "    \n",
    "    ya2c = [] if yaxis2_cols is None else yaxis2_cols\n",
    "    ycols = [c for c in df_in.columns.values if c != x_column]\n",
    "    # create tdvals, which will have x axis labels\n",
    "    td = list(df_in[x_column]) \n",
    "    nt = len(df_in)-1 if number_of_ticks_display > len(df_in) else number_of_ticks_display\n",
    "    spacing = len(td)//nt\n",
    "    tdvals = td[::spacing]\n",
    "    tdtext = tdvals\n",
    "    if x_value_labels is not None:\n",
    "        tdtext = [x_value_labels[i] for i in tdvals]\n",
    "    \n",
    "    # create data for graph\n",
    "    data = []\n",
    "    # iterate through all ycols to append to data that gets passed to go.Figure\n",
    "    for ycol in ycols:\n",
    "        if bar_plot:\n",
    "            b = go.Bar(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        else:\n",
    "            b = go.Scatter(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        data.append(b)\n",
    "\n",
    "    # create a layout\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        xaxis=dict(\n",
    "            ticktext=tdtext,\n",
    "            tickvals=tdvals,\n",
    "            tickangle=45,\n",
    "            type='category'),\n",
    "        yaxis=dict(\n",
    "            title='y main' if y_left_label is None else y_left_label\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='y alt' if y_right_label is None else y_right_label,\n",
    "            overlaying='y',\n",
    "            side='right'),\n",
    "        autosize=True,\n",
    "#         autosize=False,\n",
    "#         width=width,\n",
    "#         height=height,\n",
    "        margin=Margin(\n",
    "            b=100\n",
    "        ),\n",
    "        modebar={'orientation': modebar_orientation,'bgcolor':modebar_color}\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': plot_title,\n",
    "            'y':title_y_pos,\n",
    "            'x':title_x_pos,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'})\n",
    "    if (legend_x is not None) and (legend_y is not None):\n",
    "        fig.update_layout(legend=dict(x=legend_x, y=legend_y))\n",
    "    fig = figure_crosshairs(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plotly_shaded_rectangles(beg_end_date_tuple_list,fig):\n",
    "    '''\n",
    "    Add shaded rectanges that highlight parts of an x/y graph\n",
    "    '''\n",
    "    ld_shapes = []\n",
    "    for beg_end_date_tuple in beg_end_date_tuple_list:\n",
    "        ld_beg = beg_end_date_tuple[0]\n",
    "        ld_end = beg_end_date_tuple[1]\n",
    "        ld_shape = dict(\n",
    "            type=\"rect\",\n",
    "            # x-reference is assigned to the x-values\n",
    "            xref=\"x\",\n",
    "            # y-reference is assigned to the plot paper [0,1]\n",
    "            yref=\"paper\",\n",
    "            x0=ld_beg[i],\n",
    "            y0=0,\n",
    "            x1=ld_end[i],\n",
    "            y1=1,\n",
    "            fillcolor=\"LightSalmon\",\n",
    "            opacity=0.5,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "        ld_shapes.append(ld_shape)\n",
    "\n",
    "    fig.update_layout(shapes=ld_shapes)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = list(range(1,101))\n",
    "y1vals = np.arange(101,201,1)\n",
    "y2vals = np.arange(11,1,-.1)\n",
    "y3vals = y2vals * .5\n",
    "             \n",
    "df = pd.DataFrame({'my_x_vals':xvals, \n",
    "                    'yvals_1':y1vals,\n",
    "                    'yvals_2':y2vals,\n",
    "                    'yvals_3':y3vals\n",
    "                  })\n",
    "fig = plotly_plot(df_in=df,x_column='my_x_vals',\n",
    "                    plot_title = \"example graph\",\n",
    "                    y_left_label='main y vals',\n",
    "                    y_right_label='alt y vals',\n",
    "                    yaxis2_cols = ['yvals_2','yvals_3'],\n",
    "                    number_of_ticks_display=25)\n",
    "iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew_per_date_df(df):\n",
    "    '''\n",
    "    Find the first settle_date whose count of rows is equal to max count of rows.\n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df.symbol.unique()[0]\n",
    "    # get just that symbol's data\n",
    "    df12 = df[df.symbol==contract]\n",
    "    df_counts = df12[['settle_date','moneyness']].groupby('settle_date',as_index=False).count()\n",
    "    max_count = df_counts.moneyness.max()\n",
    "    first_max_count_settle_date = df_counts[df_counts.moneyness==max_count].iloc[0].settle_date\n",
    "    \n",
    "    df_ret = df12[df12.settle_date==first_max_count_settle_date][['moneyness']]\n",
    "    all_settle_dates = sorted(df_counts.settle_date.unique())\n",
    "    for settle_date in all_settle_dates:\n",
    "        df_temp = df12[df12.settle_date==settle_date][['moneyness','vol_skew']]\n",
    "        df_ret = df_ret.merge(df_temp,on='moneyness',how='outer')\n",
    "        df_ret = df_ret.rename(columns={'vol_skew':str(settle_date)})\n",
    "    df_ret = df_ret.sort_values('moneyness')\n",
    "    df_ret.moneyness = df_ret.moneyness.round(4)\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_skew(df_iv_final,do_plot=False):\n",
    "    '''\n",
    "    Graph skew for ONLY ONE symbol.\n",
    "    If df_iv_final contains more than one symbol, we will only graph the first symbol in the DataFrames    \n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df_iv_final.symbol.unique()[0]\n",
    "    # get just that symbol's data and only days that have sufficient skew data\n",
    "    dft = df_iv_final[df_iv_final.symbol==contract]\n",
    "    dft_count = dft[['settle_date','symbol']].groupby('settle_date',as_index=False).count()\n",
    "    valid_settle_dates = dft_count[dft_count.symbol>2].settle_date.unique()\n",
    "    dft = dft[dft.settle_date.isin(valid_settle_dates)]\n",
    "    dfp = create_skew_per_date_df(dft)\n",
    "    \n",
    "    settle_dates = sorted([c for c in dfp.columns.values if c != 'moneyness'])\n",
    "    splits = list(np.arange(5,len(settle_dates),5))\n",
    "    settle_date_groups = np.split(np.array(settle_dates),splits)\n",
    "    ret_figs = []\n",
    "    for sdg in settle_date_groups:\n",
    "        sdg_sorted = [str(c) for c in sorted(sdg)]\n",
    "        cols = ['moneyness']+list(sdg_sorted)\n",
    "        dfp_sub = dfp[cols]\n",
    "        t = f'{contract} {sdg[0]} - {sdg[-1]}' \n",
    "        f = plotly_plot(dfp_sub,x_column='moneyness',plot_title=t,y_left_label='vol skew')\n",
    "        ret_figs.append(f)\n",
    "        if do_plot:\n",
    "            iplot(f)\n",
    "    return ret_figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same plots as above, but using a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_skew_subplot_quad(fig_group,rows=1,cols=2):\n",
    "    '''\n",
    "    Use subplots to output the results of the method graph_skew above\n",
    "    '''\n",
    "    f1 = make_subplots(rows=rows, cols=cols,  \n",
    "        shared_yaxes=False,\n",
    "        shared_xaxes=False,                       \n",
    "        subplot_titles=[fig_group[i]['layout'].title.text for i in range(len(fig_group))],\n",
    "        horizontal_spacing=0.05,\n",
    "        vertical_spacing=0.11,                       \n",
    "        print_grid=False)\n",
    "\n",
    "    pl_width=450*cols \n",
    "    pl_height=400*rows\n",
    "    title = 'Skew plots<br>'\n",
    "\n",
    "    f1.update_layout(title=title,                                 \n",
    "        font= Font(family=\"Open Sans, sans-serif\"),\n",
    "        showlegend=True,     \n",
    "        hovermode='x',  \n",
    "        autosize=True,       \n",
    "        width=pl_width,       \n",
    "        height=pl_height,\n",
    "        plot_bgcolor='#EFECEA', \n",
    "        bargap=0.05,\n",
    "        margin=Margin(\n",
    "                      l=5,\n",
    "                      r=5,\n",
    "                      b=55,\n",
    "                      t=50\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    for i in range(len(fig_group)):\n",
    "        x = int(i/2) + 1\n",
    "        y = i % 2 + 1\n",
    "        f = fig_group[i]\n",
    "        l = f.layout\n",
    "        if y > 1:\n",
    "            l.yaxis.title=''\n",
    "        try:\n",
    "            yaxis = f'yaxis{i+1}'\n",
    "            xaxis = f'xaxis{i+1}'\n",
    "            if i < 10:\n",
    "                yaxis = yaxis.replace('1','') \n",
    "                xaxis = xaxis.replace('1','') \n",
    "            gname = f'{x,y}'#rfs[i]['layout'].title\n",
    "            for d in f.data:\n",
    "                data_y = f'y{i+1}'.replace('1','') \n",
    "                d['yaxis']=data_y\n",
    "                d['legendgroup'] =  gname\n",
    "                d['name'] = f\"{d.name}\"\n",
    "                f1.add_trace(d,x,y)\n",
    "                f1.update_xaxes(patch=l.xaxis,row=x,col=y)\n",
    "                f1.update_yaxes(patch=l.yaxis,row=x,col=y)                \n",
    "        except Exception as e:\n",
    "            print(f'graph_skew_subplots ERRORS: {str(e)}')\n",
    "    return f1\n",
    "\n",
    "\n",
    "def graph_skew_subplots(df,rows=2,cols=2):\n",
    "    fig_list = graph_skew(df)\n",
    "    n = rows*cols   \n",
    "    # using list comprehension \n",
    "    fig_groups = [fig_list[i*n:(i + 1)*n] for i in range((len(fig_list) + n - 1) // n )]  \n",
    "    for fig_group in fig_groups:\n",
    "        iplot(graph_skew_subplot_quad(fig_group,rows=rows,cols=cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph skew changes historically, per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL_TO_RESEARCH = 'CL'\n",
    "df_iv_final = pd.read_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv')\n",
    "df_iv_skew = pd.read_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv')\n",
    "# all_contracts = pga.get_sql(f\"select symbol from {opttab} where substring(symbol,1,2)='{SYMBOL_TO_RESEARCH}'\").symbol.unique()\n",
    "all_contracts = df_iv_final[df_iv_final.symbol.str.slice(0,2)==SYMBOL_TO_RESEARCH].symbol.unique()\n",
    "all_contracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_plot=True\n",
    "clist = [c for c in all_contracts if (c[:2]==f'{SYMBOL_TO_RESEARCH}') & (c[-2:]=='21')]\n",
    "volcols = ['symbol','settle_date','moneyness','vol_skew']\n",
    "dfivf = df_iv_final[volcols].groupby(['symbol','settle_date','moneyness'],as_index=False).mean()\n",
    "\n",
    "for c in clist:\n",
    "    dft = dfivf[dfivf.symbol==c]\n",
    "    if len(dft)<=0:\n",
    "        print(f'no data for symbol {c}')\n",
    "        continue\n",
    "    if grid_plot:\n",
    "        graph_skew_subplots(dfivf[dfivf.symbol==c],rows=1,cols=2)\n",
    "    else:\n",
    "        rls = graph_skew(dfivf[dfivf.symbol==c],do_plot=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the implied vol skew dataframes to graph changes in vol skew vs price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = 20\n",
    "syms = [s for s in all_contracts if  (int(s[-2:]) >= y)]\n",
    "\n",
    "for sym in syms:\n",
    "    df_fut = pga.get_sql(f\"select symbol,settle_date,close from {futtab} where symbol = '{sym}'\")\n",
    "    df_year = df_iv_skew[df_iv_skew.symbol==sym]\n",
    "    df_year['2dn_2up'] = df_year['-0.2'] - df_year['0.2']\n",
    "    df_year = df_year[['settle_date','2dn_2up']]\n",
    "    df_year = df_year.merge(df_fut[['settle_date','close']],on='settle_date',how='inner')\n",
    "    iplot(plotly_plot(df_year,x_column='settle_date',\n",
    "            yaxis2_cols=['close'],y_left_label='skew',y_right_label=sym,\n",
    "                     plot_title=f'{sym} close vs skew -0.2, 0.2',\n",
    "                     number_of_ticks_display=15))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = 20\n",
    "syms = [s for s in all_contracts if  (int(s[-2:]) >= y)]\n",
    "\n",
    "for sym in syms:\n",
    "    df_fut = pga.get_sql(f\"select symbol,settle_date,close from {futtab} where symbol = '{sym}'\")\n",
    "    df_year = df_iv_final[['settle_date','atm_iv']][df_iv_final.symbol==sym]\n",
    "    df_year = df_year.groupby(['settle_date'],as_index=False).mean()\n",
    "    df_year.atm_iv = df_year.atm_iv.round(4)\n",
    "    df_year = df_year.merge(df_fut[['settle_date','close']],on='settle_date',how='inner')\n",
    "    iplot(plotly_plot(df_year,x_column='settle_date',\n",
    "            yaxis2_cols=['close'],y_left_label='atm_iv',y_right_label=sym,\n",
    "                     plot_title=f'{sym} close vs atm implied vol',\n",
    "                     number_of_ticks_display=15))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a constant maturety contract, and show it's skew over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 20\n",
    "start_yyyymmdd=20200101\n",
    "syms = [s for s in all_contracts if  (int(s[-2:]) >= y)]\n",
    "df_all_years = None\n",
    "for sym in syms:\n",
    "    df_year = df_iv_skew[df_iv_skew.symbol==sym]\n",
    "    df_year['2dn_2up'] = df_year['-0.2'] - df_year['0.2']\n",
    "    df_year = df_year[['settle_date','2dn_2up']]\n",
    "    if df_all_years is None:\n",
    "        df_all_years = df_year.copy()\n",
    "    else:\n",
    "        df_all_years = df_all_years.append(df_year,ignore_index=True)\n",
    "\n",
    "first_settle_date = df_all_years.settle_date.min()\n",
    "last_settle_date = df_all_years.settle_date.max()\n",
    "\n",
    "prod = syms[0][0:2]\n",
    "sql_99 = f\"\"\"\n",
    "select symbol,settle_date,close from {futtab} \n",
    "where symbol = '{prod}Z99' \n",
    "and settle_date>= {first_settle_date}\n",
    "and settle_date<={last_settle_date} \n",
    "\"\"\"\n",
    "\n",
    "df_fut = pga.get_sql(sql_99)\n",
    "df_all_years = df_all_years.merge(df_fut,on='settle_date',how='inner')\n",
    "df_all_years_save = df_all_years.copy()\n",
    "# only look from 05/01/2020 on b/c of the vol spike in April and change column titles\n",
    "df_all_years = df_all_years[df_all_years.settle_date>=start_yyyymmdd]\n",
    "df_all_years = df_all_years.sort_values('settle_date')\n",
    "df_all_years = df_all_years.rename(columns={'2dn_2up':'20% DN/UP','close':'CL Cash Price'})\n",
    "df_all_years = df_all_years[['settle_date','20% DN/UP','CL Cash Price']]\n",
    "years = df_all_years.settle_date.astype(str).str.slice(0,4)\n",
    "months = df_all_years.settle_date.astype(str).str.slice(4,6)\n",
    "days = df_all_years.settle_date.astype(str).str.slice(6,8)\n",
    "df_all_years.settle_date = years + '-' + months + '-' + days\n",
    "# create the figure\n",
    "fig = plotly_plot(df_all_years,x_column='settle_date',\n",
    "        yaxis2_cols=['CL Cash Price'],y_left_label='Skew Difference',y_right_label='CL Cash Price',\n",
    "                 plot_title=f'CL Cash Close VS the Vol Skew Difference between the<br>20% OTM Put and 20% OTM Call',\n",
    "                 number_of_ticks_display=15)\n",
    "fig.update_layout(yaxis_tickformat = '.2%')\n",
    "# display it\n",
    "iplot(fig)\n",
    "# write it to an html file\n",
    "fig.write_html('../docs/cl_cash_vs_volskew.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_postgres_data(contract,pga):\n",
    "    osql = f\"select * from {opttab} where symbol='{contract}';\"\n",
    "    dfo = pga.get_sql(osql)\n",
    "    usql = f\"select * from {futtab} where symbol='{contract}';\"\n",
    "    dfu = pga.get_sql(usql)\n",
    "    # Merge options and futures data\n",
    "    df = dfo.merge(dfu,how='inner',on=['symbol','settle_date'])\n",
    "    # Get options expiration dates\n",
    "    df_expiry_dates = dfo[['symbol','settle_date']].groupby('symbol',as_index=False).max()\n",
    "    df_expiry_dates.settle_date = df_expiry_dates.symbol.apply(lambda s:dt_to_yyyymmdd(cmeexp.get_expiry(s)))\n",
    "    return df,df_expiry_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PYVOL = True\n",
    "def lam_pyvol(r):\n",
    "    try:\n",
    "        return implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "    except:\n",
    "        return -1\n",
    "# lam_pyvol = lambda r:implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "lam_mibian = lambda r:mibian.BS([r.close_y,r.strike,2,r.dte], callPrice=r.close_x).impliedVolatility\n",
    "\n",
    "def get_implieds(df,df_expiry_dates,contract,contract_num=2):\n",
    "    df2 = df[['symbol','contract_num','pc','settle_date','strike','close_x','close_y']]\n",
    "    df2 = df2[(((df2.pc=='C' )& (df2.strike>=df2.close_y)) | ((df2.pc=='P' ) & (df2.strike<df2.close_y)))  & (df2.symbol.str.contains(contract))]\n",
    "    if contract_num is not None:\n",
    "        df2 = df2[df2.contract_num==contract_num]\n",
    "    phigh = df2.close_y.max()\n",
    "    plow = df2.close_y.min()\n",
    "    high_strike = round(phigh * 1.3)\n",
    "    low_strike = round(plow * .7)\n",
    "    df2 = df2[(df2.strike>=low_strike) & (df2.strike<=high_strike)]\n",
    "\n",
    "    df9 = df2[df2.symbol==contract]\n",
    "    df9 = df9.merge(df_expiry_dates.rename(columns={'settle_date':'expiry'}),on='symbol',how='inner')\n",
    "    df9['syear'] = df9.settle_date.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['smon'] = df9.settle_date.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['sday'] = df9.settle_date.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['eyear'] = df9.expiry.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['emon'] = df9.expiry.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['eday'] = df9.expiry.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['sdatetime'] = df9.apply(lambda r:datetime.datetime(r.syear,r.smon,r.sday),axis=1)\n",
    "    df9['edatetime'] = df9.apply(lambda r:datetime.datetime(r.eyear,r.emon,r.eday),axis=1)\n",
    "    df9['dte'] = df9.edatetime - df9.sdatetime\n",
    "    df9.dte = df9.dte.dt.days\n",
    "    df9 = df9[['symbol','settle_date','pc','contract_num','strike','close_x','close_y','dte']]\n",
    "    df10 = df9.iloc[:len(df9)].copy()\n",
    "    df10.index = list(range(len(df10)))\n",
    "    if USE_PYVOL:\n",
    "        df10['iv'] = df10.apply(lam_pyvol,axis=1)\n",
    "    else:\n",
    "        n = 100\n",
    "        for i in tqdm_notebook(np.arange(0,len(df10)-n,n)):\n",
    "                df10.loc[i:i+n,'iv'] = df10.loc[i:i+n].apply(lam_mibian,axis=1)\n",
    "        print(f'doing remaining {datetime.datetime.now()}')\n",
    "        i = df10[df10.iv.isna()].index[0]\n",
    "        df10.loc[i:,'iv'] = df10.loc[i:].apply(lam_mbian,axis=1)\n",
    "        print(f'done with remaining {datetime.datetime.now()}')\n",
    "    return df10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_moneyness_strikes(df10):\n",
    "    # define amounts around the money which will help create strikes to add\n",
    "    moneyness = np.arange(.7,1.4,.05).round(6)\n",
    "    # define columns on which to execute groupby\n",
    "#     gb_cols = ['symbol','settle_date','pc','contract_num','dte','close_y']\n",
    "    gb_cols = ['symbol','settle_date','contract_num','dte','close_y']\n",
    "    # define function used in groupby.apply to create strikes and iv's at those strikes\n",
    "    #   where the strikes are an even amount from the money \n",
    "    #   (like .7, .8, ... 1, 1.1, 1.2, etc)\n",
    "    def _add_even_moneyness_strikes(df):\n",
    "        # get underlying from first row (the groupby makes them all the same)\n",
    "        r = df.iloc[0]\n",
    "        underlying = r.close_y\n",
    "        # create new rows to append to df, using only the gb_cols\n",
    "        df_ret1 = df.iloc[:len(moneyness)][gb_cols].copy()\n",
    "        # add nan iv's !!!! MUST BE np.nan - NOT None\n",
    "        df_ret1['iv'] = np.nan\n",
    "        # add new strikes\n",
    "        df_ret1['strike'] = moneyness * underlying\n",
    "        # append the new strikes\n",
    "        dfa = df.append(df_ret1,ignore_index=True,sort=True).copy()\n",
    "        df_ret2 = dfa.sort_values(['symbol','settle_date','pc','strike'])\n",
    "        df_ret2 = df_ret2.drop_duplicates(subset='strike')\n",
    "        # set the index to the strike so that interpolate works\n",
    "        df_ret2.index = df_ret2.strike\n",
    "        # create interpolated iv's\n",
    "        df_ret2['iv'] = df_ret2.iv.interpolate(method='polynomial', order=2)\n",
    "        # reset the index\n",
    "        df_ret2.index = list(range(len(df_ret2)))\n",
    "        return df_ret2\n",
    "\n",
    "    # start here\n",
    "    df11 = df10.groupby(gb_cols).apply(_add_even_moneyness_strikes).copy()\n",
    "    df11.index = list(range(len(df11)))\n",
    "    df11['moneyness'] = df11.strike / df11.close_y\n",
    "    df11.moneyness = df11.moneyness.round(4)\n",
    "\n",
    "    df12 = df11[(df11.moneyness.isin(moneyness)) & (~df11.iv.isna())].copy()\n",
    "    df12.moneyness  = df12.moneyness - 1\n",
    "    df12.index = list(range(len(df12)))\n",
    "    df12_atm = df12[df12.moneyness==0][['symbol','settle_date','pc','iv']]\n",
    "    df12_atm = df12_atm.rename(columns={'iv':'atm_iv'})\n",
    "    \n",
    "    df12_atm = df12_atm.drop_duplicates()\n",
    "    df12 = df12.merge(df12_atm,on=['symbol','settle_date','pc'],how='inner')\n",
    "    df12.moneyness = df12.moneyness.round(4)\n",
    "    df12['vol_skew'] = (df12.iv - df12.atm_iv).round(4)\n",
    "    return df12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_per_symbol(symbol,pga,contract_num=2,strike_divisor=None):\n",
    "    '''\n",
    "    For a symbol like CLM16 or EZH19, create 2 Dataframes\n",
    "      1. df_iv - contains rows of implied vols, for only the 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "      2. df_skew - contains one row per day of skew data of for 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "    '''\n",
    "    _exception = None\n",
    "    _stacktrace = None\n",
    "    df_iv = None\n",
    "    df_skew = None\n",
    "    try:\n",
    "        df,df_expiry_dates = get_postgres_data(symbol,pga)\n",
    "        if (contract_num is None) or len(df[df.contract_num==contract_num])>0:\n",
    "            df10 = get_implieds(df,df_expiry_dates,symbol,contract_num=contract_num)\n",
    "            df12 = get_even_moneyness_strikes(df10)\n",
    "            df_sk = create_skew_per_date_df(df12)\n",
    "            df_sk.index = list(range(len(df_sk)))\n",
    "            df_skt = df_sk.T\n",
    "            df_skt.columns = df_skt.loc['moneyness']\n",
    "            df_skt = df_skt.iloc[1:].copy()\n",
    "            df_skt['symbol'] = symbol\n",
    "            df_skt['settle_date'] = df_skt.index\n",
    "            df_iv = df12.copy() \n",
    "            df_skew = df_skt.copy()\n",
    "    except Exception as e:\n",
    "        _exception = str(e)\n",
    "        _stacktrace = traceback.format_exc()\n",
    "    return df_iv,df_skew,_exception,_stacktrace\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cash_futures_to_csv(sym,pga):\n",
    "    cash_sql = f\"select * from sec_schema.underlying_table where symbol='{sym}Z99';\"\n",
    "    df_cash_futures = pga.get_sql(cash_sql)\n",
    "    print(len(df_cash_futures))\n",
    "    df_cash_futures.to_csv(f'./temp_folder/df_cash_futures_{sym}.csv',index=False)\n",
    "    return df_cash_futures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the methods above to compute volskew info and charts for one CL contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract='CLG21'\n",
    "contract_num=3\n",
    "df_iv,df_skew,_exception,_stacktrace = skew_per_symbol('CLG21',pga,contract_num=contract_num,strike_divisor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_stacktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moneyness = .2\n",
    "df_iv_neg20 = df_iv[df_iv.moneyness==-moneyness][['settle_date','iv','strike','atm_iv']]\n",
    "df_iv_neg20 = df_iv_neg20.rename(columns={'iv':'ivneg20','strike':'strikeneg20'})\n",
    "df_iv_pos20 = df_iv[df_iv.moneyness==moneyness][['settle_date','iv','strike']]\n",
    "df_iv_pos20 = df_iv_pos20.rename(columns={'iv':'ivpos20','strike':'strikepos20'})\n",
    "df_iv_20 = df_iv_pos20.merge(df_iv_neg20,on='settle_date',how='inner')\n",
    "df_cash = cash_futures_to_csv(contract[0:2],pga)\n",
    "df_iv_20 = df_iv_20.merge(df_cash[['settle_date','close']], on='settle_date')\n",
    "df_iv_20['20dn_20up'] = df_iv_20.ivneg20 - df_iv_20.ivpos20\n",
    "df_iv_20['strike_diff'] = df_iv_20.strikeneg20 - df_iv_20.strikepos20\n",
    "iplot(\n",
    "    plotly_plot(\n",
    "        df_iv_20[['settle_date','close','20dn_20up']],\n",
    "        x_column='settle_date',\n",
    "        yaxis2_cols=['close'],\n",
    "        y_left_label=\"Vol Skew\",\n",
    "        y_right_label=\"Closing Price\",\n",
    "        plot_title=\"Close vs Skew\"\n",
    "    )\n",
    ")\n",
    "\n",
    "iplot(\n",
    "    plotly_plot(\n",
    "        df_iv_20[['settle_date','atm_iv','20dn_20up']],\n",
    "        x_column='settle_date',\n",
    "        yaxis2_cols=['atm_iv'],\n",
    "        y_left_label=\"Vol Skew\",\n",
    "        y_right_label=\"ATM Vol\",\n",
    "        plot_title=\"ATM Vol vs Skew\"        \n",
    "    )\n",
    ")             \n",
    "\n",
    "df_iv_20['atm_iv_perc_chg'] = df_iv_20.atm_iv/df_iv_20.atm_iv.shift(1) - 1\n",
    "df_iv_20['20dn_20up_perc_chg'] = df_iv_20['20dn_20up']/df_iv_20['20dn_20up'].shift(1) - 1\n",
    "df_iv_20['perc_chg_diff'] = df_iv_20['atm_iv_perc_chg'] - df_iv_20['20dn_20up_perc_chg']\n",
    "\n",
    "iplot(\n",
    "    plotly_plot(\n",
    "        df_iv_20[['settle_date','perc_chg_diff','atm_iv']],\n",
    "        x_column='settle_date',\n",
    "        yaxis2_cols=['atm_iv'],\n",
    "        y_left_label=\"%Chg in ATM vol minus %Chg in Skew\",\n",
    "        y_right_label=\"ATM Vol\",\n",
    "        plot_title=\"ATM Vol vs Difference in % changes of Atm vol and Skew\"        \n",
    "    )\n",
    ")             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(plotly_plot(df_cash[df_cash.settle_date>=20190101][['settle_date','close']],x_column='settle_date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show average prices per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2011,2021)\n",
    "averages = [\n",
    "    df_cash[(df_cash.settle_date>=int(y*100*100+101)) & (df_cash.settle_date<int((y+1)*100*100+101))].close.mean()\n",
    "    for y in years\n",
    "]\n",
    "pd.DataFrame({'year':years,'average_price':averages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the historical path of a specific \"close strike\" option spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol='CLQ20'\n",
    "pc = 'P'\n",
    "beg_yyyymmdd = 20200629\n",
    "futsql = f\"select * from {futtab} where symbol = '{symbol}' and settle_date={str(beg_yyyymmdd)}\";\n",
    "fut_close = pga.get_sql(futsql).close.values[0]\n",
    "low_strike = int(fut_close/.5)*.5\n",
    "high_strike = low_strike + .5\n",
    "low_strike_close_sql = f\"\"\"\n",
    "select close from {opttab} \n",
    "where symbol = '{symbol}' \n",
    "and settle_date={beg_yyyymmdd} \n",
    "and pc='{pc}'\n",
    "and strike = {low_strike}\n",
    "\"\"\"\n",
    "low_strike_close = pga.get_sql(low_strike_close_sql).close.values[0]\n",
    "\n",
    "high_strike_close_sql = f\"\"\"\n",
    "select close from {opttab} \n",
    "where symbol = '{symbol}' \n",
    "and settle_date={beg_yyyymmdd} \n",
    "and pc='{pc}'\n",
    "and strike = {high_strike}\n",
    "\"\"\"\n",
    "high_strike_close = pga.get_sql(high_strike_close_sql).close.values[0]\n",
    "\n",
    "fut_close,low_strike,high_strike,fut_close,low_strike_close-high_strike_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_strike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_strike_close_sql = f\"\"\"\n",
    "select settle_date,close from {opttab} \n",
    "where symbol = '{symbol}' \n",
    "and settle_date>={beg_yyyymmdd} \n",
    "and pc='{pc}'\n",
    "and strike = {low_strike}\n",
    "\"\"\"\n",
    "df_low_strike_close = pga.get_sql(low_strike_close_sql)\n",
    "df_low_strike_close = df_low_strike_close.rename(columns={'close':f'call_{low_strike}'})\n",
    "\n",
    "high_strike_close_sql = f\"\"\"\n",
    "select settle_date,close from {opttab} \n",
    "where symbol = '{symbol}' \n",
    "and settle_date>={beg_yyyymmdd} \n",
    "and pc='{pc}'\n",
    "and strike = {high_strike}\n",
    "\"\"\"\n",
    "df_high_strike_close = pga.get_sql(high_strike_close_sql)\n",
    "df_high_strike_close = df_high_strike_close.rename(columns={'close':f'call_{high_strike}'})\n",
    "\n",
    "df_call_spread = df_low_strike_close.merge(df_high_strike_close,on='settle_date',how='inner')\n",
    "df_call_spread['spread'] = df_call_spread[f'call_{low_strike}'] - df_call_spread[f'call_{high_strike}']\n",
    "df_call_spread = df_call_spread.merge(df_cash[['settle_date','close']],on='settle_date',how='inner')\n",
    "                                                           \n",
    "pga.get_sql(f\"select settle_date,close from {opttab} where symbol='CLF21' and settle_date>=20200101\")\n",
    "iplot(\n",
    "    plotly_plot(\n",
    "        df_call_spread[['settle_date','close','spread']],\n",
    "        x_column='settle_date',\n",
    "        yaxis2_cols=['spread'],\n",
    "        plot_title=\"Cash futures from 2020-01-02\",\n",
    "        y_left_label='CLY00 price',\n",
    "        y_right_label=f'{low_strike}/{high_strike}_spread'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CME's Volume report for APO options for a specific day to see which APOs trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import pdb \n",
    "import xlrd\n",
    "trade_date = 20201207\n",
    "# apo_url = f\"https://www.cmegroup.com/CmeWS/exp/voiProductDetailsViewExport.ctl?media=xls&tradeDate={trade_date}&reportType=F&productId=4707\"\n",
    "apo_url = f\"https://www.cmegroup.com/CmeWS/exp/voiProductDetailsViewExport.ctl?media=xls&tradeDate={trade_date}&reportType=P&productId=4707\"\n",
    "r = requests.get( apo_url) # \n",
    "f = open('./temp_folder/cme_apo.xls','wb')\n",
    "f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = xlrd.open_workbook('./temp_folder/cme_apo.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sheet = book.sheet_by_index(0)\n",
    "print(first_sheet.name,first_sheet.nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beg_row = -1\n",
    "for row in range(100):\n",
    "    try:\n",
    "        cells = first_sheet.row_slice(rowx=row)        \n",
    "        cell0 = str(cells[0].value).lower()\n",
    "        if \"average\" in cell0:\n",
    "            beg_row = row\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rows = {}\n",
    "header = []\n",
    "for row in tqdm_notebook(range(beg_row,first_sheet.nrows)):\n",
    "    cells = first_sheet.row_slice(rowx=row)\n",
    "    cell0 = str(cells[0].value).lower()\n",
    "    if (\"call\" in cell0) or (\"put\" in cell0):\n",
    "        new_contract = cell0\n",
    "        valid_rows[new_contract] = []\n",
    "        for data_row in range(row+1,10000):\n",
    "            cells = first_sheet.row_slice(rowx=data_row)\n",
    "            cell0 = str(cells[0].value).lower()\n",
    "            if 'strike' in cell0:\n",
    "                valid_rows[new_contract].append([c.value for c in cells])\n",
    "                continue\n",
    "            try:\n",
    "                int(cell0)\n",
    "                valid_rows[new_contract].append([c.value for c in cells])\n",
    "            except:\n",
    "                row = data_row\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=None\n",
    "for pc in valid_rows.keys():\n",
    "    df = pd.DataFrame(valid_rows[pc][1:],columns=valid_rows[pc][0])\n",
    "    df['contract'] = pc[0:6]\n",
    "    df['pc'] = pc[7]\n",
    "    if df_all is None:\n",
    "        df_all = df.copy()\n",
    "    else:\n",
    "        df_all = df_all.append(df,ignore_index=True)\n",
    "df_all = df_all.rename(columns = {c:c.replace(' ','_').lower() for c in df_all.columns.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['total_volume'].astype(int)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = df_all[\n",
    "    df_all['total_volume'].astype(int)>0\n",
    "]\n",
    "df_all2.total_volume = df_all.total_volume.astype(int)\n",
    "df_all2[\n",
    "    ['contract','strike','pc','total_volume']\n",
    "].sort_values(['total_volume','contract','strike'],ascending=False).head(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 660*1000000\n",
    "c = 15000\n",
    "a/c-38000,c*10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metals_etf_dfs = pd.read_html(\"https://etfdb.com/etfs/natural-resources/industrial-metals/\")\n",
    "for df in metals_etf_dfs:\n",
    "    display.display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
