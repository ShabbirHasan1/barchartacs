{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research the idea of computing a history of implied volatilities by always having the underlying price the same value\n",
    "* **This requires plotly 4.0 or greater** *\n",
    "\n",
    "Calculate the implied volatility of each days options as if the underlying futures contract were always some fixed value. For example, if the actual futures is 100, make that price 50, and then change all of the strike prices so that the strike prices are relative to the value 50.  \n",
    "\n",
    "1. The 100 call would be a 50 dollar call.  \n",
    "2. The 95 put would be a 45 dollar put.  \n",
    "3. The 105 call would be a 55 dollar call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "import pathlib\n",
    "from dateutil.relativedelta import *\n",
    "import pandas_market_calendars as pmc\n",
    "\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n",
    "from dashapp import dashapp2 as dashapp\n",
    "\n",
    "# importlib.reload(build_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n",
    "print(f\"futtab max date: {pga.get_sql(f'select max(settle_date) from {futtab}')}\")\n",
    "print(f\"opttab max date: {pga.get_sql(f'select max(settle_date) from {opttab}')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew_per_date_df(df):\n",
    "    '''\n",
    "    Find the first settle_date whose count of rows is equal to max count of rows.\n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df.symbol.unique()[0]\n",
    "    # get just that symbol's data\n",
    "    df12 = df[df.symbol==contract]\n",
    "    df_counts = df12[['settle_date','moneyness']].groupby('settle_date',as_index=False).count()\n",
    "    max_count = df_counts.moneyness.max()\n",
    "    first_max_count_settle_date = df_counts[df_counts.moneyness==max_count].iloc[0].settle_date\n",
    "    \n",
    "    df_ret = df12[df12.settle_date==first_max_count_settle_date][['moneyness']]\n",
    "    all_settle_dates = sorted(df_counts.settle_date.unique())\n",
    "    for settle_date in all_settle_dates:\n",
    "        df_temp = df12[df12.settle_date==settle_date][['moneyness','vol_skew']]\n",
    "        df_ret = df_ret.merge(df_temp,on='moneyness',how='outer')\n",
    "        df_ret = df_ret.rename(columns={'vol_skew':str(settle_date)})\n",
    "    df_ret = df_ret.sort_values('moneyness')\n",
    "    df_ret.moneyness = df_ret.moneyness.round(4)\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_skew(df_iv_final,do_plot=False):\n",
    "    '''\n",
    "    Graph skew for ONLY ONE symbol.\n",
    "    If df_iv_final contains more than one symbol, we will only graph the first symbol in the DataFrames    \n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df_iv_final.symbol.unique()[0]\n",
    "    # get just that symbol's data and only days that have sufficient skew data\n",
    "    dft = df_iv_final[df_iv_final.symbol==contract]\n",
    "    dft_count = dft[['settle_date','symbol']].groupby('settle_date',as_index=False).count()\n",
    "    valid_settle_dates = dft_count[dft_count.symbol>2].settle_date.unique()\n",
    "    dft = dft[dft.settle_date.isin(valid_settle_dates)]\n",
    "    dfp = create_skew_per_date_df(dft)\n",
    "    \n",
    "    settle_dates = sorted([c for c in dfp.columns.values if c != 'moneyness'])\n",
    "    splits = list(np.arange(5,len(settle_dates),5))\n",
    "    settle_date_groups = np.split(np.array(settle_dates),splits)\n",
    "    ret_figs = []\n",
    "    for sdg in settle_date_groups:\n",
    "        sdg_sorted = [str(c) for c in sorted(sdg)]\n",
    "        cols = ['moneyness']+list(sdg_sorted)\n",
    "        dfp_sub = dfp[cols]\n",
    "        t = f'{contract} {sdg[0]} - {sdg[-1]}' \n",
    "        f = plotly_plot(dfp_sub,x_column='moneyness',plot_title=t,y_left_label='vol skew')\n",
    "        ret_figs.append(f)\n",
    "        if do_plot:\n",
    "            iplot(f)\n",
    "    return ret_figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same plots as above, but using a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_skew_subplot_quad(fig_group,rows=1,cols=2):\n",
    "    '''\n",
    "    Use subplots to output the results of the method graph_skew above\n",
    "    '''\n",
    "    f1 = make_subplots(rows=rows, cols=cols,  \n",
    "        shared_yaxes=False,\n",
    "        shared_xaxes=False,                       \n",
    "        subplot_titles=[fig_group[i]['layout'].title.text for i in range(len(fig_group))],\n",
    "        horizontal_spacing=0.05,\n",
    "        vertical_spacing=0.11,                       \n",
    "        print_grid=False)\n",
    "\n",
    "    pl_width=450*cols \n",
    "    pl_height=400*rows\n",
    "    title = 'Skew plots<br>'\n",
    "\n",
    "    f1.update_layout(title=title,                                 \n",
    "        font= Font(family=\"Open Sans, sans-serif\"),\n",
    "        showlegend=True,     \n",
    "        hovermode='x',  \n",
    "        autosize=True,       \n",
    "        width=pl_width,       \n",
    "        height=pl_height,\n",
    "        plot_bgcolor='#EFECEA', \n",
    "        bargap=0.05,\n",
    "        margin=Margin(\n",
    "                      l=5,\n",
    "                      r=5,\n",
    "                      b=55,\n",
    "                      t=50\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    for i in range(len(fig_group)):\n",
    "        x = int(i/2) + 1\n",
    "        y = i % 2 + 1\n",
    "        f = fig_group[i]\n",
    "        l = f.layout\n",
    "        if y > 1:\n",
    "            l.yaxis.title=''\n",
    "        try:\n",
    "            yaxis = f'yaxis{i+1}'\n",
    "            xaxis = f'xaxis{i+1}'\n",
    "            if i < 10:\n",
    "                yaxis = yaxis.replace('1','') \n",
    "                xaxis = xaxis.replace('1','') \n",
    "            gname = f'{x,y}'#rfs[i]['layout'].title\n",
    "            for d in f.data:\n",
    "                data_y = f'y{i+1}'.replace('1','') \n",
    "                d['yaxis']=data_y\n",
    "                d['legendgroup'] =  gname\n",
    "                d['name'] = f\"{d.name}\"\n",
    "                f1.add_trace(d,x,y)\n",
    "                f1.update_xaxes(patch=l.xaxis,row=x,col=y)\n",
    "                f1.update_yaxes(patch=l.yaxis,row=x,col=y)                \n",
    "        except Exception as e:\n",
    "            print(f'graph_skew_subplots ERRORS: {str(e)}')\n",
    "    return f1\n",
    "\n",
    "\n",
    "def graph_skew_subplots(df,rows=2,cols=2):\n",
    "    fig_list = graph_skew(df)\n",
    "    n = rows*cols   \n",
    "    # using list comprehension \n",
    "    fig_groups = [fig_list[i*n:(i + 1)*n] for i in range((len(fig_list) + n - 1) // n )]  \n",
    "    for fig_group in fig_groups:\n",
    "        iplot(graph_skew_subplot_quad(fig_group,rows=rows,cols=cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph skew changes historically, per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL_TO_RESEARCH = 'CL'\n",
    "all_contracts = pga.get_sql(f\"select symbol from {opttab} where substring(symbol,1,2)='{SYMBOL_TO_RESEARCH}'\").symbol.unique()\n",
    "all_contracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_holidays = open('expiration_data/uk_holidays.csv').readlines()\n",
    "# uksplit = [','.join([t.strip('\\n') for t in l.split(',')]) for l in  uk_holidays]\n",
    "uksplit = [','.join(l.split(',')) for l in  uk_holidays]\n",
    "fio = io.StringIO()\n",
    "fio.writelines(uksplit)\n",
    "fio.seek(0)\n",
    "df_ukh = pd.read_csv(fio)\n",
    "def ukh_to_yyyymmdd(month_day,year):\n",
    "    md = month_day.strip()\n",
    "    d = datetime.datetime.strptime(f'{md} {year}', '%B %d %Y')\n",
    "    return d\n",
    "#     return d.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "year_cols = [c for c in df_ukh.columns.values if '20' in str(c)]\n",
    "for c in year_cols:\n",
    "    df_ukh[c] = df_ukh[c].apply(lambda s:ukh_to_yyyymmdd(s,c))\n",
    "uk_holidays = sorted(df_ukh[year_cols].values.reshape(-1))\n",
    "uk_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_CODES = 'FGHJKMNQUVXZ'\n",
    "DICT_MONTH_CODE = {MONTH_CODES[i]:i+1 for i in range(len(MONTH_CODES))}\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "# bday_uk = pd.offsets.CustomBusinessDay(calendar=pmc.exchange_calendar_ice.ICEExchangeCalendar().regular_holidays)\n",
    "bday_uk = pd.offsets.CustomBusinessDay(holidays=uk_holidays)\n",
    "TIMEZONE = 'US/Eastern'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nth_weekday(year,month,target_weekday,nth_occurrence):\n",
    "    '''\n",
    "    weekday is the term that assigns numbers from 0 to 6 to the days of the weeks.\n",
    "    weekday 0 = monday\n",
    "    '''\n",
    "    # get dayofweeks of year,month,1\n",
    "    weekday_01 = datetime.datetime(year,month,1).weekday()\n",
    "    if weekday_01 <= target_weekday:\n",
    "        day_of_month_of_first_occurence = target_weekday - weekday_01\n",
    "        day_of_month_of_nth_occurence = day_of_month_of_first_occurence + 1 + (nth_occurrence - 1) * 7\n",
    "    else:\n",
    "        day_of_month_of_nth_occurence = target_weekday - weekday_01 + 1 + (nth_occurrence) * 7 \n",
    "    return datetime.datetime(year,month,day_of_month_of_nth_occurence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ES_expiry(symbol):\n",
    "    '''\n",
    "    3rd friday of month of symbol\n",
    "    '''\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    return get_nth_weekday(year,month,4,3)\n",
    "\n",
    "def get_E6_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    next_month = DICT_MONTH_CODE[monthcode_yy[0]] + 1\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    if next_month>12:\n",
    "        next_month = 1\n",
    "        year += 1\n",
    "    return datetime.datetime(year,next_month,1) - 7*bday_us\n",
    "\n",
    "def get_CL_expiry(symbol):\n",
    "    '''\n",
    "    Trading terminates 7 business days before the 26th calendar of the month prior to the contract month.\n",
    "    '''\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    month = month -1\n",
    "    if month<1:\n",
    "        month = 12\n",
    "        year = year - 1\n",
    "    return datetime.datetime(year,month,26) - 7*bday_us\n",
    "\n",
    "def get_NG_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    return datetime.datetime(year,month,1) - 4*bday_us\n",
    "\n",
    "def get_CB_expiry(symbol):\n",
    "    '''\n",
    "    This is the spec for the CME Brent, but it matches ICE.\n",
    "    Trading terminates the 4th last London business day of \n",
    "    the month, 2 months prior to the contract month \n",
    "    except for the February contract month which \n",
    "    terminates the 5th last London business day of the \n",
    "    month, 2 months prior to the contract month.  \n",
    "    '''\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    month = month - 1\n",
    "    if month<1:\n",
    "        month = 12 + month\n",
    "        year = year - 1\n",
    "    days_to_subtract = 4\n",
    "    if monthcode_yy[0] =='G':\n",
    "        days_to_subtract = 5\n",
    "    elif monthcode_yy[0] == 'F':\n",
    "        days_to_subtract = 3\n",
    "#     elif monthcode_yy == 'N22':\n",
    "#         days_to_subtract = 7\n",
    "    return datetime.datetime(year,month,1,0,0) - days_to_subtract * bday_uk\n",
    "\n",
    "DICT_PRODUCT = {\n",
    "    'E6':get_E6_expiry,\n",
    "    'ES':get_ES_expiry,\n",
    "    'CL':get_CL_expiry,\n",
    "    'NG':get_NG_expiry,\n",
    "    'CB':get_CB_expiry,\n",
    "}\n",
    "\n",
    "    \n",
    "def get_expiry(symbol):\n",
    "    product = symbol[:2]\n",
    "    if product not in DICT_PRODUCT:\n",
    "        return None\n",
    "    f = DICT_PRODUCT[product]\n",
    "    return f(symbol)\n",
    "\n",
    "\n",
    "def dt_from_yyyymmdd(yyyymmdd,hour=0,minute=0,timezone=TIMEZONE):\n",
    "    y = int(str(yyyymmdd)[0:4])\n",
    "    m = int(str(yyyymmdd)[4:6])\n",
    "    d = int(str(yyyymmdd)[6:8])  \n",
    "    return datetime.datetime(y,m,d,hour,minute,tzinfo=pytz.timezone(timezone))\n",
    "\n",
    "def yyyymmdd_from_dt(dt):\n",
    "    y = int(dt.year)\n",
    "    m = int(dt.month)\n",
    "    d = int(dt.day)\n",
    "    return y*100*100 + m*100 + d\n",
    "\n",
    "def get_dte_pct(trade_yyyymmdd,expiry_yyyymmdd):\n",
    "    dt_td = dt_from_yyyymmdd(trade_yyyymmdd)\n",
    "    dt_xp = dt_from_yyyymmdd(expiry_yyyymmdd)\n",
    "    return ((dt_xp - dt_td).days + 1)/365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_postgres_data(contract,pga):\n",
    "    osql = f\"select * from {opttab} where symbol='{contract}';\"\n",
    "    dfo = pga.get_sql(osql)\n",
    "    usql = f\"select * from {futtab} where symbol='{contract}';\"\n",
    "    dfu = pga.get_sql(usql)\n",
    "    # Merge options and futures data\n",
    "    df = dfo.merge(dfu,how='inner',on=['symbol','settle_date'])\n",
    "    # Get options expiration dates\n",
    "    df_expiry_dates = dfo[['symbol','settle_date']].groupby('symbol',as_index=False).max()\n",
    "    calculated_expiry = get_expiry(contract)    \n",
    "    if calculated_expiry is not None:\n",
    "        expiry_yyyymmdd = yyyymmdd_from_dt(calculated_expiry)\n",
    "        if expiry_yyyymmdd> df_expiry_dates.iloc[0].settle_date:\n",
    "            df_expiry_dates.loc[0,'settle_date'] = expiry_yyyymmdd\n",
    "    return df,df_expiry_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PYVOL = True\n",
    "def lam_pyvol(r):\n",
    "    try:\n",
    "        return implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "    except:\n",
    "        return -1\n",
    "# lam_pyvol = lambda r:implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "lam_mibian = lambda r:mibian.BS([r.close_y,r.strike,2,r.dte], callPrice=r.close_x).impliedVolatility\n",
    "\n",
    "def get_implieds(df,df_expiry_dates):\n",
    "    df2 = df[['symbol','contract_num','pc','settle_date','strike','close_x','close_y']]\n",
    "    df9 = df2.copy()\n",
    "    df9['expiry'] = df_expiry_dates.iloc[0].settle_date\n",
    "    df9['syear'] = df9.settle_date.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['smon'] = df9.settle_date.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['sday'] = df9.settle_date.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['eyear'] = df9.expiry.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['emon'] = df9.expiry.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['eday'] = df9.expiry.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['sdatetime'] = df9.apply(lambda r:datetime.datetime(r.syear,r.smon,r.sday),axis=1)\n",
    "    df9['edatetime'] = df9.apply(lambda r:datetime.datetime(r.eyear,r.emon,r.eday),axis=1)\n",
    "    df9['dte'] = df9.edatetime - df9.sdatetime\n",
    "    df9.dte = df9.dte.dt.days\n",
    "    df9 = df9[['symbol','settle_date','pc','contract_num','strike','close_x','close_y','dte']]\n",
    "    df10 = df9.iloc[:len(df9)].copy()\n",
    "    df10.index = list(range(len(df10)))\n",
    "    if USE_PYVOL:\n",
    "        df10['iv'] = df10.apply(lam_pyvol,axis=1)\n",
    "    else:\n",
    "        n = 100\n",
    "        for i in tqdm_notebook(np.arange(0,len(df10)-n,n)):\n",
    "                df10.loc[i:i+n,'iv'] = df10.loc[i:i+n].apply(lam_mibian,axis=1)\n",
    "        print(f'doing remaining {datetime.datetime.now()}')\n",
    "        i = df10[df10.iv.isna()].index[0]\n",
    "        df10.loc[i:,'iv'] = df10.loc[i:].apply(lam_mbian,axis=1)\n",
    "        print(f'done with remaining {datetime.datetime.now()}')\n",
    "    return df10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_moneyness_strikes(df10):\n",
    "    # define amounts around the money which will help create strikes to add\n",
    "    moneyness = np.arange(.7,1.4,.05).round(6)\n",
    "    # define columns on which to execute groupby\n",
    "#     gb_cols = ['symbol','settle_date','pc','contract_num','dte','close_y']\n",
    "    gb_cols = ['symbol','settle_date','contract_num','dte','close_y']\n",
    "    # define function used in groupby.apply to create strikes and iv's at those strikes\n",
    "    #   where the strikes are an even amount from the money \n",
    "    #   (like .7, .8, ... 1, 1.1, 1.2, etc)\n",
    "    def _add_even_moneyness_strikes(df):\n",
    "        # get underlying from first row (the groupby makes them all the same)\n",
    "        r = df.iloc[0]\n",
    "        underlying = r.close_y\n",
    "        # create new rows to append to df, using only the gb_cols\n",
    "        df_ret1 = df.iloc[:len(moneyness)][gb_cols].copy()\n",
    "        # add nan iv's !!!! MUST BE np.nan - NOT None\n",
    "        df_ret1['iv'] = np.nan\n",
    "        # add new strikes\n",
    "        df_ret1['strike'] = moneyness * underlying\n",
    "        # append the new strikes\n",
    "        dfa = df.append(df_ret1,ignore_index=True,sort=True).copy()\n",
    "        df_ret2 = dfa.sort_values(['symbol','settle_date','pc','strike'])\n",
    "        df_ret2 = df_ret2.drop_duplicates(subset='strike')\n",
    "        # set the index to the strike so that interpolate works\n",
    "        df_ret2.index = df_ret2.strike\n",
    "        # create interpolated iv's\n",
    "        df_ret2['iv'] = df_ret2.iv.interpolate(method='polynomial', order=2)\n",
    "        # reset the index\n",
    "        df_ret2.index = list(range(len(df_ret2)))\n",
    "        return df_ret2\n",
    "\n",
    "    # start here\n",
    "    df11 = df10.groupby(gb_cols).apply(_add_even_moneyness_strikes).copy()\n",
    "    df11.index = list(range(len(df11)))\n",
    "    df11['moneyness'] = df11.strike / df11.close_y\n",
    "    df11.moneyness = df11.moneyness.round(4)\n",
    "\n",
    "    df12 = df11[(df11.moneyness.isin(moneyness)) & (~df11.iv.isna())].copy()\n",
    "    df12.moneyness  = df12.moneyness - 1\n",
    "    df12.index = list(range(len(df12)))\n",
    "    df12_atm = df12[df12.moneyness==0][['symbol','settle_date','pc','iv']]\n",
    "    df12_atm = df12_atm.rename(columns={'iv':'atm_iv'})\n",
    "    \n",
    "    df12_atm = df12_atm.drop_duplicates()\n",
    "    df12 = df12.merge(df12_atm,on=['symbol','settle_date','pc'],how='inner')\n",
    "    df12.moneyness = df12.moneyness.round(4)\n",
    "    df12['vol_skew'] = (df12.iv - df12.atm_iv).round(4)\n",
    "    return df12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contracts(commod):\n",
    "    all_contracts = pga.get_sql(f\"select symbol from {opttab} where substring(symbol,1,2)='{commod}'\").symbol.unique()\n",
    "    return all_contracts\n",
    "\n",
    "\n",
    "def pseudo_vol(df,df_expiry,fatm=50,rows=100):\n",
    "    '''\n",
    "    get implied vol as if every underlying was the price specified in the arg fatm\n",
    "    :param df:  DataFrame with columns from get_postgres_data of:\n",
    "    'symbol','strike','pc','settle_date','close_x','close_y','contract_num'\n",
    "    :param df_expiry: a one row DataFrame with the expiration date of the options on \n",
    "       the symbol whose options data is in df\n",
    "    :param fatm: the futures atm price to use as the underlying futures for all\n",
    "      implied vol calculations\n",
    "    \n",
    "    '''\n",
    "    # get desired columns\n",
    "    df_cl2 = df[['symbol','strike','pc','settle_date','close_x','close_y','contract_num']]\n",
    "    # find the atm_op: the at the money option (closest to the money)\n",
    "    df_cl2['atm_op'] = [abs(v) for v in (df_cl2.strike - df_cl2.close_y)]\n",
    "    df_cl2_atm_op = df_cl2[['settle_date','atm_op']].groupby('settle_date',as_index=False).min()\n",
    "    df_cl2 = df_cl2_atm_op.merge(df_cl2,on=['settle_date','atm_op'],how='inner')\n",
    "    df_cl2.index = list(range(len(df_cl2)))\n",
    "    # get either the put or the call with the same atm_op value and lowest close_x value\n",
    "    #   close_x is the options price\n",
    "    df_cl2_put_or_call = df_cl2[['settle_date','close_x']].groupby('settle_date',as_index=False).min()\n",
    "    df_cl2 = df_cl2_put_or_call.merge(df_cl2,on=['settle_date','close_x'],how='inner')\n",
    "\n",
    "    # create a new strike\n",
    "    df_cl2.strike = fatm + df_cl2.strike - df_cl2.close_y\n",
    "    df_cl2['fprice'] = df_cl2.close_y\n",
    "    df_cl2.close_y = fatm\n",
    "    df_cl2 = df_cl2.iloc[-rows:]\n",
    "    df_cl_fut = df_cl2[['settle_date','fprice']].drop_duplicates()\n",
    "    df_cl_implieds = get_implieds(df_cl2,df_expiry)\n",
    "    df_cl_implieds2 = df_cl_implieds[df_cl_implieds.dte>0]\n",
    "    df_cl_implieds2 = df_cl_implieds2.merge(df_cl_fut,on='settle_date')\n",
    "    return df_cl_implieds2[['settle_date','iv','fprice']]\n",
    "\n",
    "#     df_cl_implieds2['atm_op'] = df_cl_implieds2.apply(\n",
    "#         lambda r:abs(r.strike - r.close_y),axis=1)\n",
    "#     df_cl_implieds3 = df_cl_implieds2[['settle_date','atm_op']].groupby('settle_date',as_index=False).min()\n",
    "#     df_cl_implieds4 = df_cl_implieds3.merge(\n",
    "#         df_cl_implieds2[['settle_date','atm_op','iv']],on=['settle_date','atm_op'],how='inner')\n",
    "#     df_cl_implieds4 = df_cl_implieds4[['settle_date','iv']]\n",
    "#     df_cl_implieds4 = df_cl_implieds4.merge(df_cl_fut,on='settle_date')\n",
    "#     return df_cl_implieds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pseudo_vol(dict_contract_df['CLM19'][0],dict_contract_df['CLM19'][1])\n",
    "display.display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_symbols(sym_list):\n",
    "    ordered_keys = [\n",
    "        s[:2]+s[-1]+s[2:4] \n",
    "        for s in sorted([v[0:2]+v[-2:]+v[2] for v in sym_list])\n",
    "    ]\n",
    "    return ordered_keys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_pseudo_vol(dict_contract_df,pga,\n",
    "                   fatm=50,rows=100):\n",
    "#     ordered_keys = [\n",
    "#         s[:2]+s[-1]+s[2:4] \n",
    "#         for s in sorted([v[0:2]+v[-2:]+v[2] for v in dict_contract_df.keys()])\n",
    "#     ]\n",
    "    ordered_keys = ordered_symbols(list(dict_contract_df.keys()))\n",
    "    \n",
    "    dict_df_implied = {}\n",
    "\n",
    "    for symbol in tqdm_notebook(ordered_keys):\n",
    "        if dict_contract_df[symbol] is None:\n",
    "            df,df_expiry = get_postgres_data(symbol,pga)\n",
    "        else:\n",
    "            df,df_expiry = dict_contract_df[symbol]\n",
    "        try:\n",
    "            df_implied = pseudo_vol(df,df_expiry,fatm=fatm,rows=rows)\n",
    "            dict_df_implied[symbol] = df_implied\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            continue\n",
    "    return dict_df_implied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contract_df = {c:None for c in get_contracts('CL')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for symbol in tqdm_notebook(dict_contract_df.keys()):\n",
    "    dict_contract_df[symbol] = get_postgres_data(symbol,pga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_small_cdf = {c:dict_contract_df[c] for c in dict_contract_df.keys() if ((c[2] >'N') and (int(c[-2:]) >= 20))}\n",
    "# dict_df_implied = loop_pseudo_vol(dict_small_cdf,pga)\n",
    "dict_df_implied = loop_pseudo_vol(dict_contract_df,pga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_implied['CLM19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "year = 2020\n",
    "for symbol in [k for k in dict_df_implied.keys() if int(k[-2:])==year-2000]:\n",
    "    df_to_graph = dict_df_implied[symbol][:-1]\n",
    "    fig = dashapp.plotly_plot(\n",
    "        df_in=df_to_graph,x_column='settle_date',yaxis2_cols=['fprice'],\n",
    "        y_left_label='Implied Volatility',y_right_label='Futures Close',\n",
    "        plot_title=f\"{symbol} Pseudo-Volatility vs Price\"\n",
    "    )\n",
    "    iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cl_all = None\n",
    "df_cl_all_expiry = None\n",
    "for symbol in tqdm_notebook(dict_contract_df.keys()):\n",
    "    df_temp = dict_contract_df[symbol][0]\n",
    "    df_temp_expiry = dict_contract_df[symbol][1]\n",
    "    if df_cl_all is None:\n",
    "        df_cl_all = df_temp.copy()\n",
    "        df_cl_all_expiry = df_temp_expiry.copy()\n",
    "    else:\n",
    "        df_cl_all = df_cl_all.append(df_temp,ignore_index=True)\n",
    "        df_cl_all_expiry = df_cl_all_expiry.append(df_temp_expiry,ignore_index=True)\n",
    "    df_cl_all.index = list(range(len(df_cl_all)))\n",
    "    df_cl_all_expiry.index = list(range(len(df_cl_all_expiry)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pathlib.Path.home()\n",
    "fname = f\"{h}/downloads/df_cl_all.pickle\"\n",
    "df_cl_all.to_pickle(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
