{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research processing CME span files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n",
    "import cme_expirations as cmeexp\n",
    "import re\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import urllib\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_crosshairs(fig):\n",
    "    fig['layout'].hovermode='x'\n",
    "    fig['layout'].yaxis.showspikes=True\n",
    "    fig['layout'].xaxis.showspikes=True\n",
    "    fig['layout'].yaxis.spikemode=\"toaxis+across\"\n",
    "    fig['layout'].xaxis.spikemode=\"toaxis+across\"\n",
    "    fig['layout'].yaxis.spikedash=\"solid\"\n",
    "    fig['layout'].xaxis.spikedash=\"solid\"\n",
    "    fig['layout'].yaxis.spikethickness=1\n",
    "    fig['layout'].xaxis.spikethickness=1\n",
    "    fig['layout'].spikedistance=1000\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plotly_plot(df_in,x_column,plot_title=None,\n",
    "                y_left_label=None,y_right_label=None,\n",
    "                bar_plot=False,width=800,height=400,\n",
    "                number_of_ticks_display=20,\n",
    "                yaxis2_cols=None,\n",
    "                x_value_labels=None,\n",
    "                modebar_orientation='v',modebar_color='grey',\n",
    "                legend_x=None,legend_y=None,\n",
    "                title_y_pos = 0.9,\n",
    "                title_x_pos = 0.5):\n",
    "    \n",
    "    ya2c = [] if yaxis2_cols is None else yaxis2_cols\n",
    "    ycols = [c for c in df_in.columns.values if c != x_column]\n",
    "    # create tdvals, which will have x axis labels\n",
    "    td = list(df_in[x_column]) \n",
    "    nt = len(df_in)-1 if number_of_ticks_display > len(df_in) else number_of_ticks_display\n",
    "    spacing = len(td)//nt\n",
    "    tdvals = td[::spacing]\n",
    "    tdtext = tdvals\n",
    "    if x_value_labels is not None:\n",
    "        tdtext = [x_value_labels[i] for i in tdvals]\n",
    "    \n",
    "    # create data for graph\n",
    "    data = []\n",
    "    # iterate through all ycols to append to data that gets passed to go.Figure\n",
    "    for ycol in ycols:\n",
    "        if bar_plot:\n",
    "            b = go.Bar(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        else:\n",
    "            b = go.Scatter(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        data.append(b)\n",
    "\n",
    "    # create a layout\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        xaxis=dict(\n",
    "            ticktext=tdtext,\n",
    "            tickvals=tdvals,\n",
    "            tickangle=45,\n",
    "            type='category'),\n",
    "        yaxis=dict(\n",
    "            title='y main' if y_left_label is None else y_left_label\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='y alt' if y_right_label is None else y_right_label,\n",
    "            overlaying='y',\n",
    "            side='right'),\n",
    "        autosize=True,\n",
    "#         autosize=False,\n",
    "#         width=width,\n",
    "#         height=height,\n",
    "        margin=Margin(\n",
    "            b=100\n",
    "        ),\n",
    "        modebar={'orientation': modebar_orientation,'bgcolor':modebar_color}\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': plot_title,\n",
    "            'y':title_y_pos,\n",
    "            'x':title_x_pos,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'})\n",
    "    if (legend_x is not None) and (legend_y is not None):\n",
    "        fig.update_layout(legend=dict(x=legend_x, y=legend_y))\n",
    "    fig = figure_crosshairs(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plotly_shaded_rectangles(beg_end_date_tuple_list,fig):\n",
    "    ld_shapes = []\n",
    "    for beg_end_date_tuple in beg_end_date_tuple_list:\n",
    "        ld_beg = beg_end_date_tuple[0]\n",
    "        ld_end = beg_end_date_tuple[1]\n",
    "        ld_shape = dict(\n",
    "            type=\"rect\",\n",
    "            # x-reference is assigned to the x-values\n",
    "            xref=\"x\",\n",
    "            # y-reference is assigned to the plot paper [0,1]\n",
    "            yref=\"paper\",\n",
    "            x0=ld_beg[i],\n",
    "            y0=0,\n",
    "            x1=ld_end[i],\n",
    "            y1=1,\n",
    "            fillcolor=\"LightSalmon\",\n",
    "            opacity=0.5,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "        ld_shapes.append(ld_shape)\n",
    "\n",
    "    fig.update_layout(shapes=ld_shapes)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the links on the CME Confluence documentation page that contain links to Span Expanded Format files that one finds on the CME ftp site (ftp://ftp.cmegroup.com/span/archive/cme/)\n",
    "* Create the variable `urls`, that points to the documentation pages for each record type in the Fixed Position Span files\n",
    "* Create the variable `rtypes` that contains single character Span Record Types\n",
    "  * The record type `8` will expand to `81`, `82`, `83`, `84`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_xpath = '//div[@id=\"main-content\"]//ul//li/a[starts-with(text(),\"Expanded Format\")]/@href'\n",
    "from lxml import html\n",
    "import requests\n",
    "page = requests.get('https://www.cmegroup.com/confluence/display/pubspan/Risk+Parameter+File+Layouts+for+the+Positional+Formats')\n",
    "tree = html.fromstring(page.content)\n",
    "links = tree.xpath(links_xpath)\n",
    "urls = ['https://www.cmegroup.com/'+l for l in links]\n",
    "rtypes = [re.findall('Type\\+(.)',l)[0] for l in links]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dictionary `dict_rec_types` which divides the records into separate DataFrames for each Span Record Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_url(url,table_index=0):\n",
    "    header = {\n",
    "      \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "      \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    r = requests.get(url, headers=header)\n",
    "    try:\n",
    "        dft = pd.read_html(r.text)[table_index]\n",
    "        return dft \n",
    "    except Exception as e:\n",
    "        print(f'error on type {rt}: {str(e)}')\n",
    "        return None\n",
    "    \n",
    "\n",
    "dict_rec_types={}\n",
    "for i in tqdm_notebook(range(len(urls))):\n",
    "    if rtypes[i]=='8':\n",
    "        dict_rec_types['81'] = get_url(urls[i],table_index=0)\n",
    "        cols = dict_rec_types['81'].iloc[0].values\n",
    "        dict_rec_types['81'] = dict_rec_types['81'].iloc[1:]\n",
    "        dict_rec_types['81'].columns = cols\n",
    "        dict_rec_types['82'] = get_url(urls[i],table_index=1)\n",
    "        dict_rec_types['82'] = dict_rec_types['82'].iloc[1:]\n",
    "        dict_rec_types['82'].columns = cols\n",
    "        dict_rec_types['83'] = get_url(urls[i],table_index=2)\n",
    "        dict_rec_types['83'] = dict_rec_types['83'].iloc[1:]\n",
    "        dict_rec_types['83'].columns = cols\n",
    "        dict_rec_types['84'] = get_url(urls[i],table_index=3)\n",
    "        dict_rec_types['84'] = dict_rec_types['84'].iloc[1:]\n",
    "        dict_rec_types['84'].columns = cols\n",
    "    else:\n",
    "        dict_rec_types[rtypes[i]] = get_url(urls[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_rec_types['81'].columns = dict_rec_types['81'].iloc[0].values\n",
    "dict_rec_types['84']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get example pa2 Span Data files with different types of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_extract_zip(url):\n",
    "    \"\"\"\n",
    "    Download a ZIP file and extract its contents in memory\n",
    "    yields (filename, file-like object) pairs\n",
    "    \"\"\"\n",
    "#     response = requests.get(url)\n",
    "    mysock = urllib.request.urlopen(url)\n",
    "    memfile = io.BytesIO(mysock.read())\n",
    "    with zipfile.ZipFile(memfile, 'r') as thezip:\n",
    "        d =  {\n",
    "            name: io.BytesIO(thezip.read(name)).read().decode('UTF-8')\n",
    "            for name in thezip.namelist()}\n",
    "        return list(d.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa22.split('\\r\\n')[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa2[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pa2 cme.nr.20201006.c.pa2\n",
    "print('fetching pa2 zip from CME ftp site ... (takes about 30 seconds)')\n",
    "pa2_url = 'ftp://ftp.cmegroup.com/span/archive/cme/2020/cme.20200106.c.pa2.zip'\n",
    "pa2 = download_extract_zip(pa2_url).split('\\r\\n')\n",
    "# pa2 = open(f'{pathlib.Path.home()}/downloads/cme.20200106.c.pa2','r').readlines()\n",
    "# create a dictionary of pa2 records per record_type (rt)\n",
    "data_dict = {}\n",
    "for rt in tqdm_notebook(dict_rec_types.keys()):\n",
    "    print(rt,end=\",\")\n",
    "    data_dict[rt] = [s for s in pa2 if s[0:len(rt)]==rt]\n",
    "\n",
    "len(data_dict['81'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['81']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `dict_df`, which holds a DataFrame of data extracted from the pa2 csv, for each Span Record Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of DataFrames per record type that hold the pa2 data for each\n",
    "#  record type (rt)\n",
    "dict_df = {}\n",
    "for rt in tqdm_notebook(dict_rec_types.keys()):\n",
    "    try:\n",
    "        dict_df[rt] = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    c[5].strip():r[int(c[1])-1:int(c[2])].strip()\n",
    "                    for c in dict_rec_types[rt].values if 'filler' not in c[5].lower()\n",
    "                }\n",
    "                for r in data_dict[rt]\n",
    "            ])\n",
    "    except Exception as e:\n",
    "        dict_df[rt] = None\n",
    "        print(f'error on {rt}: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_c_recs = dict_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'rtype':list(dict_rec_types.keys()),'rlen':[len(data_dict[rt]) for rt in dict_rec_types.keys()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['81']['Commodity (Product) Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dict_df['82'].columns.values\n",
    "cols2 = [' '.join(c.split(' ')[:8]) for c in cols]\n",
    "pd.DataFrame({'col':cols,'col2':cols2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = ['81','82','83','84']\n",
    "for c in ccs:\n",
    "    dict_df[c].columns = [' '.join(c.split(' ')[:8]) for c in dict_df[c].columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['81'][dict_df['81']['Exchange Acronym']=='NYM']['Commodity (Product) Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
