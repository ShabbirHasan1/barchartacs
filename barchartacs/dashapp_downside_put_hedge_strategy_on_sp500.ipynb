{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn your S&P500 portfolio into synthetic in-the-money calls.\n",
    "\n",
    "#### This notebook researches a strategy in which:\n",
    "1. You buy the S&P 500 (using an ETF);\n",
    "2. You choose the value ```put_perc_otm```, which is the **percent below the S&P purchase price** to use as the strike price of a put that limits your downside exposure;\n",
    "3. You choose the value ```years_to_hedge```, which is the duration of the put;\n",
    "4. Actions to take as the S&P price moves and time passes:\n",
    "  * S&P rises to  ``` 2 * put_perc_otm``` above current hedge strike: \n",
    "    * you sell the previous put, and purhase another put at a **higher** strike, and for the full ```years_to_hedge```, effectively buying diagonal put spreads\n",
    "  * S&P falls to ```2 * put_perc_otm``` below the current hedge strike: \n",
    "    * you sell the previous put, and purhase another put at a **lower** strike, and for the full ```years_to_hedge```, effectively selling diagonal put spreads\n",
    "\n",
    "#### The main benefit of this strategy\n",
    "* The strategy is designed to provide continual insurance  of your long S&P position, using a rolling series of puts.  These puts effectively turn your S&P position into a call that still collects dividends.\n",
    "* Depending on where the price of the S&P 500 is relative to the current put strike, you will either have a position that is long an in-the-money call (as the S&P 500 rises to newer all time highs, or an out of the money all (as the S&P falls from those all time highs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hedge strategy and use data on ^GSPC from yahoo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cost/revenue of the hedge.\n",
    "The put hedge that you will buy will initially be below the current SP price by a percentage which you set in the variable ```put_perc_otm```.  When the price of the SP rises high enough so that you can raise the strike price of the hedge, you sell the current put (if there is any value in it) and buy a new put that is ```put_perc_otm``` percent higher than the previous put.  In this way, you are not letting your hedge get too far from the money.\n",
    "\n",
    "\n",
    "* Remember that, since you are comparing this put strategy to \"Buy-And-Hold\"\n",
    "  * Rolls to a higher strike are a cost to the strategy\n",
    "  * Rolls to a lower strike are revenue to the strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF YOU WANT TO SEE WARNINGS, COMMENT THIS OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from IPython.core.display import  HTML\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs.layout import Font,Margin,Modebar\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb,pdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from ipysheet import from_dataframe,to_dataframe\n",
    "from dashapp import dashapp2 as dashapp\n",
    "# import dash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import plotly.express as px\n",
    "\n",
    "import pyarrow as pa\n",
    "import redis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a redis port.  This implies that a redis server is running.\n",
    "##### see the ipynb notebook ```redis_server.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_port = 6379\n",
    "redis_db = redis.Redis(host = 'localhost',port=6379,db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redis_df(key):\n",
    "    context = pa.default_serialization_context()\n",
    "    df = context.deserialize(redis_db.get(key))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 01: define important functions that are used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_yyyymmdd(d):\n",
    "    return int(d.year)*100*100 + int(d.month)*100 + int(d.day)\n",
    "\n",
    "def str_to_yyyymmdd(d,sep='-'):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d)[:10],f'%Y{sep}%m{sep}%d')\n",
    "    except:\n",
    "        return None\n",
    "    s = '%04d%02d%02d' %(dt.year,dt.month,dt.day)\n",
    "    return int(s)\n",
    "\n",
    "def str_to_date(d,sep='-'):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d)[:10],f'%Y{sep}%m{sep}%d')\n",
    "    except:\n",
    "        return None\n",
    "    return dt\n",
    "\n",
    "\n",
    "def fetch_history(symbol,dt_beg,dt_end):\n",
    "    df = pdr.DataReader(symbol, 'yahoo', dt_beg, dt_end)\n",
    "    # move index to date column, sort and recreate index\n",
    "    df['date'] = df.index\n",
    "    df = df.sort_values('date')\n",
    "    df.index = list(range(len(df)))\n",
    "    # make adj close the close\n",
    "    df = df.drop(['Adj Close'],axis=1)\n",
    "    cols = df.columns.values \n",
    "    cols_dict = {c:c[0].lower() + c[1:] for c in cols}\n",
    "    df = df.rename(columns = cols_dict)\n",
    "    df['settle_date'] = df.date.apply(str_to_yyyymmdd)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot(df_in,x_column,plot_title=None,\n",
    "                y_left_label=None,y_right_label=None,\n",
    "                bar_plot=False,width=800,height=400,\n",
    "                number_of_ticks_display=20,\n",
    "                yaxis2_cols=None,\n",
    "                x_value_labels=None,\n",
    "                modebar_orientation='v',modebar_color='grey',\n",
    "                legend_x=None,legend_y=None):\n",
    "    ya2c = [] if yaxis2_cols is None else yaxis2_cols\n",
    "    ycols = [c for c in df_in.columns.values if c != x_column]\n",
    "    # create tdvals, which will have x axis labels\n",
    "    td = list(df_in[x_column]) \n",
    "    nt = len(df_in)-1 if number_of_ticks_display > len(df_in) else number_of_ticks_display\n",
    "    spacing = len(td)//nt\n",
    "    tdvals = td[::spacing]\n",
    "    tdtext = tdvals\n",
    "    if x_value_labels is not None:\n",
    "        tdtext = [x_value_labels[i] for i in tdvals]\n",
    "    \n",
    "    # create data for graph\n",
    "    data = []\n",
    "    # iterate through all ycols to append to data that gets passed to go.Figure\n",
    "    for ycol in ycols:\n",
    "        if bar_plot:\n",
    "            b = go.Bar(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        else:\n",
    "            b = go.Scatter(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        data.append(b)\n",
    "\n",
    "    # create a layout\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        xaxis=dict(\n",
    "            ticktext=tdtext,\n",
    "            tickvals=tdvals,\n",
    "            tickangle=45,\n",
    "            type='category'),\n",
    "        yaxis=dict(\n",
    "            title='y main' if y_left_label is None else y_left_label\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='y alt' if y_right_label is None else y_right_label,\n",
    "            overlaying='y',\n",
    "            side='right'),\n",
    "        autosize=True,\n",
    "#         autosize=False,\n",
    "#         width=width,\n",
    "#         height=height,\n",
    "        margin=Margin(\n",
    "            b=100\n",
    "        ),\n",
    "        modebar={'orientation': modebar_orientation,'bgcolor':modebar_color}\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': plot_title,\n",
    "            'y':0.9,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'})\n",
    "    if (legend_x is not None) and (legend_y is not None):\n",
    "        fig.update_layout(legend=dict(x=legend_x, y=legend_y))\n",
    "    return fig\n",
    "\n",
    "def plotly_shaded_rectangles(beg_end_date_tuple_list,fig):\n",
    "    ld_shapes = []\n",
    "    for beg_end_date_tuple in beg_end_date_tuple_list:\n",
    "        ld_beg = beg_end_date_tuple[0]\n",
    "        ld_end = beg_end_date_tuple[1]\n",
    "        ld_shape = dict(\n",
    "            type=\"rect\",\n",
    "            # x-reference is assigned to the x-values\n",
    "            xref=\"x\",\n",
    "            # y-reference is assigned to the plot paper [0,1]\n",
    "            yref=\"paper\",\n",
    "#             x0=ld_beg[i],\n",
    "            x0=ld_beg,\n",
    "            y0=0,\n",
    "#             x1=ld_end[i],\n",
    "            x1=ld_end,\n",
    "            y1=1,\n",
    "            fillcolor=\"LightSalmon\",\n",
    "            opacity=0.5,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "        ld_shapes.append(ld_shape)\n",
    "\n",
    "    fig.update_layout(shapes=ld_shapes)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_put_spread(\n",
    "    atm_vol,current_hedge_strike,prev_hedge_strike,\n",
    "    hedge_date,prev_hedge_date,rate,put_perc_otm,years_to_hedge):\n",
    "    '''\n",
    "    !! This should only be exexuted on rows of dft where dft.time_to_hedge==True !!\n",
    "\n",
    "    Calculate the value of the option spread where the legs are: \n",
    "      1. the current_hedge_strike \n",
    "      2. previous hedge strike\n",
    "    The value will be positive if you are buying the spread b/c you are rolling\n",
    "      the previous hedge forward (to a higher strike).\n",
    "    The value will be negative if you are selling the spread b/c you are rolling\n",
    "      the previous hedge backward (to a lower strike)\n",
    "    '''\n",
    "     #black.black(flag, F, K, t, r, sigma)\n",
    "    atm_vol = atm_vol\n",
    "    if (np.isnan(prev_hedge_strike)) or (prev_hedge_strike < current_hedge_strike):\n",
    "        curr_strike_vol = atm_vol + .04 \n",
    "        prev_strike_vol = atm_vol + .08\n",
    "    else:\n",
    "        curr_strike_vol = atm_vol - .04 \n",
    "        prev_strike_vol = atm_vol - .06\n",
    "\n",
    "    days_left_in_prev_hedge = (hedge_date - prev_hedge_date).days\n",
    "\n",
    "    # calculate remaining of previous hedge\n",
    "    if np.isnan(prev_hedge_strike):\n",
    "        underlying_price = current_hedge_strike * (1+put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge,rate, curr_strike_vol)\n",
    "        remaining_opt_value = 0\n",
    "    elif prev_hedge_strike < current_hedge_strike:\n",
    "        # we are rolling up b/c the market is put_perc_otm ABOVE the current_hedge\n",
    "        underlying_price = current_hedge_strike * (1+put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge,rate, curr_strike_vol)\n",
    "        if days_left_in_prev_hedge > years_to_hedge*365:\n",
    "            remaining_opt_value = 0\n",
    "        else:\n",
    "            time_remaining = days_left_in_prev_hedge/(years_to_hedge*365)\n",
    "            remaining_opt_value = black.black('p', underlying_price, prev_hedge_strike, \n",
    "                                              time_remaining, rate, prev_strike_vol)\n",
    "    else:\n",
    "        # we are rolling down b/c the market is put_perc_otm BELOW the current_hedge\n",
    "        underlying_price = current_hedge_strike * (1-put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge, rate, curr_strike_vol)\n",
    "        if days_left_in_prev_hedge > years_to_hedge*365:\n",
    "            remaining_opt_value = prev_hedge_strike - underlying_price\n",
    "        else:\n",
    "            remaining_opt_value =  black.black('p', underlying_price, prev_hedge_strike, years_to_hedge, rate, prev_strike_vol)\n",
    "\n",
    "\n",
    "    return curr_hedge - remaining_opt_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yyyymmdd_to_dt_string(yyyymmdd_int):\n",
    "    y = str(yyyymmdd_int)[0:4]\n",
    "    mn = str(yyyymmdd_int)[4:6]\n",
    "    d = str(yyyymmdd_int)[6:8]\n",
    "    return f\"{y}-{mn}-{d}\"\n",
    "\n",
    "def dt_to_yyyymmdd(dt):\n",
    "    yyyymmdd = int(dt.year)*100*100 + int(dt.month)*100 + int(dt.day)\n",
    "    return yyyymmdd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 02: Define methods that creates the dataframe called ```dft``` which has all of the strategy info, incluing hedge values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInputs():\n",
    "    def __init__(self):\n",
    "        self.df_spy = get_redis_df('df_spy')\n",
    "        self.df_vix = get_redis_df('df_vix')\n",
    "        self.df_1yr_rate = get_redis_df('df_1yr_rate')\n",
    "        self.df_div = get_redis_df('df_div')\n",
    "\n",
    "class EveryScenario():\n",
    "    def __init__(self):\n",
    "        self.df_every_scenario = get_redis_df('df_every_scenario')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dft(put_perc_otm,years_to_hedge,\n",
    "              yyyymmdd_beg=None,yyyymmdd_end=None,use_fast=True,\n",
    "              data_inputs=None):\n",
    "    if data_inputs is None:\n",
    "        df_spy = get_redis_df('df_spy')\n",
    "        df_vix = get_redis_df('df_vix')\n",
    "        df_1yr_rate = get_redis_df('df_1yr_rate')\n",
    "        df_div = get_redis_df('df_div')\n",
    "    else:\n",
    "        df_spy = data_inputs.df_spy\n",
    "        df_vix = data_inputs.df_vix\n",
    "        df_1yr_rate = data_inputs.df_1yr_rate\n",
    "        df_div = data_inputs.df_div\n",
    "        \n",
    "            \n",
    "    # Create a lambda that converts yyyymmdd integer to a datetime object\n",
    "    yyyymmdd_to_dt = lambda v:datetime.datetime(\n",
    "            int(str(v)[0:4]),int(str(v)[4:6]),int(str(v)[6:8])\n",
    "    )\n",
    "\n",
    "    # Grab only the relevant columns from df_spy\n",
    "    dft = df_spy[['settle_date','close','high','low']]\n",
    "    if yyyymmdd_beg is not None:\n",
    "        dft = dft[dft.settle_date>=yyyymmdd_beg]\n",
    "    if yyyymmdd_end is not None:\n",
    "        dft = dft[dft.settle_date<=yyyymmdd_end]\n",
    "        \n",
    "    # Create a datetime settle date, along with the yyyymmdd settle_date column\n",
    "    dft['settle_dt'] = dft.settle_date.apply(yyyymmdd_to_dt)\n",
    "#     print(f\"create_dft inputs:{put_perc_otm,years_to_hedge,yyyymmdd_beg,yyyymmdd_end}\")\n",
    "    # Initialize currrent_strike, which is below the money\n",
    "    current_long_price = dft.iloc[0].close\n",
    "    current_strike = current_long_price * (1 - put_perc_otm)\n",
    "    current_strike_array = [current_strike]\n",
    "\n",
    "    # Create an array of high and low values, to speed up loop processing    \n",
    "    m = dft[['high','low']].values\n",
    "\n",
    "    # Loop here to determine the hedge strikes\n",
    "    for i in range(1,len(m)):\n",
    "        # Get high and low\n",
    "        curr_high = m[i][0]\n",
    "        curr_low = m[i][1]\n",
    "        # If the price rises past current_strike * (1 + put_perc_otm) * (1+ put_perc_otm)\n",
    "        #   then you want to roll the put strike up,essentially BUYING a put spread\n",
    "        if curr_high  >= current_strike * (1 + put_perc_otm)**2:\n",
    "            # roll strikes up, like buying put spreads as market goes up\n",
    "            current_strike = current_strike * (1 + put_perc_otm)\n",
    "        # If the price falls below current_strike * (1 - put_perc_otm) * (1- put_perc_otm)\n",
    "        #   then you want to roll the put strike down, essentially SELLING a put spread\n",
    "        elif curr_low <= current_strike * (1 - put_perc_otm)**2:\n",
    "            # Roll strikes down (like selling put spreads as market drops)\n",
    "            current_strike = current_strike * (1 - put_perc_otm)\n",
    "        # Accumulate the current_strike (it either remained unchanged, went up, or went down)\n",
    "        current_strike_array.append(current_strike)\n",
    "\n",
    "    # Update dft with the current_strike array    \n",
    "    dft['current_hedge_strike'] = current_strike_array\n",
    "    # Create previous strike, so that you can tell when you have to buy or sell\n",
    "    #   put spreads to roll your hedge to a new higher or lower level.\n",
    "    dft['prev_hedge_strike'] = dft.current_hedge_strike.shift(1)\n",
    "    \n",
    "    # The next 2 lines are where you determine the dates on which you execute hedges\n",
    "    dft.loc[dft.prev_hedge_strike!=dft.current_hedge_strike,'time_to_hedge'] = True\n",
    "    dft.loc[dft.prev_hedge_strike==dft.current_hedge_strike,'time_to_hedge'] = False\n",
    "\n",
    "    # On the next 4 rows, create the hedge_date, which will be used for calculating put prices.\n",
    "    dft.loc[dft.time_to_hedge,'hedge_date'] = dft.loc[dft.time_to_hedge].settle_date\n",
    "    #      Give all rows of dft that are NOT rows where time_to_hedge == True a value of the min settle_date\n",
    "    dft.loc[dft.time_to_hedge==False,'hedge_date'] = dft.settle_date.min()\n",
    "    #      This expanding command will make each row's hedge_date either the last hedge_date, or a new hedge_date\n",
    "    dft.hedge_date = dft.hedge_date.expanding(min_periods=1).max()\n",
    "    #      Now make the hedge_date a datetime object\n",
    "    dft.hedge_date = dft.hedge_date.apply(yyyymmdd_to_dt)\n",
    "    \n",
    "    # Create days_of_hedge, which will give you the total days that the hedge was on\n",
    "    dft['prev_hedge_date'] = dft.hedge_date.shift(1)\n",
    "    dft['days_of_hedge'] = (dft.settle_dt - dft.hedge_date).dt.days        \n",
    "    dft.loc[dft.time_to_hedge,'days_of_hedge'] = (dft[dft.time_to_hedge].hedge_date - dft[dft.time_to_hedge].prev_hedge_date).dt.days\n",
    "\n",
    "    # Obtain atm_vol from the VIX\n",
    "#     df_vix = fetch_history('^VIX',sp_data_beg_date,sp_data_end_date)\n",
    "    df_vix2 = df_vix[['settle_date','close']]\n",
    "    df_vix2 = df_vix2.rename(columns={'close':'atm_vol'})\n",
    "    df_vix2.atm_vol = df_vix2.atm_vol / 100\n",
    "    dft = dft.merge(df_vix2,on='settle_date',how='inner')\n",
    "\n",
    "    # Obtain interest rates fro the 1 year treasury rate\n",
    "    dft = dft.merge(df_1yr_rate,on='settle_date',how='inner')\n",
    "\n",
    "    # Obtain the divident yield from the SP dividend yield dataframe\n",
    "    dft['year'] = dft.settle_date.apply(lambda v:int(str(v)[0:4]))\n",
    "    df_div = pd.read_csv('sp_div_yield.csv')    \n",
    "    dft = dft.merge(df_div,on='year',how='inner')\n",
    "\n",
    "    # Now calculate cost/revenue of buying put spreads, or selling put spreads\n",
    "    def _calc_put_spread(r):\n",
    "        return calc_put_spread(\n",
    "            r.atm_vol,r.current_hedge_strike,r.prev_hedge_strike,\n",
    "            r.hedge_date,r.prev_hedge_date,r.rate,put_perc_otm,years_to_hedge)\n",
    "    dft.loc[dft.time_to_hedge,'hedge'] = dft.loc[dft.time_to_hedge].apply(_calc_put_spread,axis=1)\n",
    "    dft.loc[dft.time_to_hedge==False,'hedge'] = 0\n",
    "    dft['hedge_cumulative'] = [0] + dft.iloc[1:].hedge.cumsum().values.tolist()\n",
    "\n",
    "    if use_fast:\n",
    "        dft['hedged_value'] = np.maximum(dft.current_hedge_strike.values,dft.close.values) - dft.hedge_cumulative.values\n",
    "        dft['prev_hedged_value'] = dft.hedged_value.shift(1)\n",
    "        dft['hedged_daily_return'] = dft.hedged_value/dft.prev_hedged_value-1\n",
    "        dft['prev_close'] = dft.close.shift(1)\n",
    "        dft['unhedged_return']  = dft.close/dft.prev_close-1\n",
    "    else:\n",
    "        dft['hedged_value'] = dft.apply(lambda r:max(r.current_hedge_strike,r.close) - r.hedge_cumulative,axis=1)\n",
    "        dft['prev_hedged_value'] = dft.hedged_value.shift(1)\n",
    "        dft['hedged_daily_return'] = dft.apply(lambda r:r.hedged_value/r.prev_hedged_value-1,axis=1)\n",
    "        dft['prev_close'] = dft.close.shift(1)\n",
    "        dft['unhedged_return']  = dft.apply(lambda r:r.close/r.prev_close-1,axis=1) \n",
    "    \n",
    "    \n",
    "    # Return dft\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 03: Define method that calculates \"comparative\" returns.\n",
    "1. Return of unhedged portofolio\n",
    "2. Return of hedged portfolio\n",
    "3. Return of a partially invested portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparative_returns(dft,years_to_hedge,rebal_target,rebal_adjust,pom=.14):\n",
    "    ret = {}\n",
    "    \n",
    "    # Get the begin and end values of dft.close, using the lowest and highest dates\n",
    "    row_min = dft[dft.settle_dt == dft.settle_dt.min()].iloc[0]\n",
    "    row_max = dft[dft.settle_dt == dft.settle_dt.max()].iloc[0]\n",
    "    years_of_position = (row_max.settle_dt - row_min.settle_dt).days/365\n",
    "    beg_value = row_min.close\n",
    "    curr_value  = row_max.close\n",
    "    \n",
    "    # Caculate various returns\n",
    "    #   return not hedged\n",
    "    curr_return  = (curr_value/beg_value)**(1/years_of_position) - 1\n",
    "    #   return as of the date of the highest high\n",
    "    highest_high_value = dft[dft.high==dft.high.max()].iloc[0].close\n",
    "    highest_return_no_hedge = (highest_high_value/beg_value)**(1/years_of_position) - 1\n",
    "\n",
    "    #   current return if you hedged\n",
    "    hedge_cost = dft[dft.time_to_hedge].hedge.sum()\n",
    "    hedged_value = max(row_max.current_hedge_strike,curr_value) - hedge_cost\n",
    "    hedged_return = (hedged_value/beg_value)**(1/years_of_position) - 1\n",
    "\n",
    "    # Calculate the return from a portfolio that is rebalanced when the portfolio's\n",
    "    #     percentage of stock reaches some threshold.\n",
    "    \n",
    "    # Get the initial shares of stock and cash\n",
    "    shares = rebal_target / dft.close[0]\n",
    "    cash = 1 - rebal_target\n",
    "    # Set up arrays to accumlate daily changes\n",
    "    cash_per_day = []\n",
    "    stock_per_day = []\n",
    "    port_per_day = []\n",
    "    prices = dft.close.values\n",
    "    dates = dft.settle_date.values\n",
    "    cash_rates = dft.rate.values / 365\n",
    "    rebal_dates = []\n",
    "    rebal_sales = []\n",
    "    stock_percs = []\n",
    "\n",
    "    # Main loop to determine portfolio values over time, and to determine when to rebalance\n",
    "    for i in range(1,len(dft)):\n",
    "        # Calculate current stock dollars\n",
    "        stock_dollars = shares * prices[i]\n",
    "        # have your cash earn interest each day\n",
    "        cash_rate = cash_rates[i]\n",
    "        cash = cash * (1+cash_rate)\n",
    "        # determine portfolio value \n",
    "        port = stock_dollars + cash\n",
    "        # determine pre-rebalance stock percent\n",
    "        stock_perc = stock_dollars/port\n",
    "        stock_percs.append(stock_perc)\n",
    "        # determine if you should rebalance\n",
    "        if stock_perc >= rebal_adjust:\n",
    "            # do upside re-balance\n",
    "            dollars_to_sell = stock_dollars - rebal_target*port\n",
    "            new_stock_dollars = stock_dollars - dollars_to_sell\n",
    "            new_cash = cash + dollars_to_sell\n",
    "            new_port = new_stock_dollars + new_cash\n",
    "            shares = new_stock_dollars/prices[i]\n",
    "            cash = new_cash\n",
    "            stock_dollars = new_stock_dollars\n",
    "            rebal_dates.append(dates[i])\n",
    "            rebal_sales.append(dollars_to_sell)\n",
    "        elif stock_perc <= (rebal_target - (rebal_adjust-rebal_target)):\n",
    "            # do downside re-balance\n",
    "            dollars_to_buy = rebal_target*port - stock_dollars\n",
    "            new_stock_dollars = stock_dollars + dollars_to_buy\n",
    "            new_cash = cash - dollars_to_buy\n",
    "            new_port = new_stock_dollars + new_cash\n",
    "            shares = new_stock_dollars/prices[i]\n",
    "            cash = new_cash\n",
    "            stock_dollars = new_stock_dollars\n",
    "            rebal_dates.append(dates[i])\n",
    "            rebal_sales.append(-dollars_to_buy)\n",
    "            \n",
    "        cash_per_day.append(cash)\n",
    "        stock_per_day.append(stock_dollars)\n",
    "        port_per_day.append(cash+stock_dollars)    \n",
    "    \n",
    "    df_daily_values = pd.DataFrame({\n",
    "        'cash_per_day':cash_per_day,\n",
    "        'stock_per_day':stock_per_day,\n",
    "        'port_per_day':port_per_day,\n",
    "        'close':prices[1:],\n",
    "        'date':dates[1:],\n",
    "        'cash_rate':cash_rates[1:],\n",
    "        'stock_perc':stock_percs\n",
    "    })\n",
    "    df_rebalance_info = pd.DataFrame({\n",
    "        'rebal_date':rebal_dates,\n",
    "        'rebal_sale':rebal_sales,\n",
    "    })\n",
    "    # get total years and calculate annualized portfolio performance\n",
    "    total_days = (dft.settle_dt.values[-1] - dft.settle_dt.values[0]).astype('timedelta64[D]')// np.timedelta64(1, 'D')\n",
    "    total_years = total_days / 365\n",
    "    end_port_value = port_per_day[-1]\n",
    "    beg_port_value = port_per_day[0]\n",
    "    annualized_port_yield = round((end_port_value/beg_port_value)**(1/total_years) - 1,3)\n",
    "    return_types = [\n",
    "        'total years',\n",
    "        'annualized current return',\n",
    "        f'annualized highest return',\n",
    "        f'annualized current hedged return {round(pom*100,1)}%',\n",
    "        f'rebalanced ({int(rebal_target*100)}%,{int(rebal_adjust*100)}%) portfolio end value']\n",
    "    df_values = pd.DataFrame({\n",
    "        'return_type':return_types,\n",
    "        'current_value':[total_years,curr_value,highest_high_value,hedged_value,end_port_value],\n",
    "        'return':[0,curr_return,highest_return_no_hedge,hedged_return,annualized_port_yield]})\n",
    "    return df_values,df_daily_values,df_rebalance_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_TITLE={\n",
    "    'line-height': '20px',\n",
    "    'textAlign': 'center',\n",
    "    'background-color':'#47bacc',\n",
    "    'color':'#FFFFF9',\n",
    "    'vertical-align':'middle',\n",
    "    'horizontal-align':'middle',\n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 04: Create methods to convert input strings of:\n",
    "1. beg_date in format yyyy-mm-dd (e.g. 1990-01-02 for Jan 2nd, 1990)\n",
    "2. beg_date in format yyyy-mm-dd (e.g. 1990-01-02 for Jan 2nd, 1990)\n",
    "3. put percent out of the money as decimal (e.g .14 for 14% out of the money)\n",
    "\n",
    "#### into DataFrames and Graph Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_scenarios(beg_year,end_year,low_pom,high_pom,rebal_target,rebal_adjust):\n",
    "    # determine yyyymmdd_end\n",
    "    dt_now = datetime.datetime.now()\n",
    "    yyyymmdd_end = end_year*100*100 + 1231\n",
    "    yyyymmdd_now = dt_to_yyyymmdd(dt_now)\n",
    "    yyyymmdd_end = min(yyyymmdd_end,yyyymmdd_now)\n",
    "    # create array of beg_years to loop on\n",
    "    beg_years = np.arange(beg_year,end_year,1)\n",
    "\n",
    "    #   loop on increasing beg_year, but holding end_year constant\n",
    "    dft_dict = {}\n",
    "    data_inputs = DataInputs()\n",
    "    year_begs = []\n",
    "    poms = []\n",
    "    no_hedge_currents = []\n",
    "    no_hedge_highests = []\n",
    "    with_hedge_currents = []\n",
    "    rebalanced_currents = []\n",
    "    for y in tqdm_notebook(beg_years):\n",
    "        yyyymmdd_beg = int(y)*100*100 + 101 \n",
    "        #    loop on pom\n",
    "        for pom in [round(x,2) for x in np.arange(low_pom,high_pom+.01,.02)]:\n",
    "            _,df_values,_,_ =_get_df_values(\n",
    "                yyyymmdd_beg,yyyymmdd_end,pom,rebal_target,rebal_adjust,\n",
    "                data_inputs=data_inputs)\n",
    "            year_begs.append(y)\n",
    "            poms.append(pom)\n",
    "            no_hedge_currents.append(df_values.iloc[1]['return'])\n",
    "            no_hedge_highests.append(df_values.iloc[2]['return'])\n",
    "            with_hedge_currents.append(df_values.iloc[3]['return'])\n",
    "            rebalanced_currents.append(df_values.iloc[4]['return'])\n",
    "    return pd.DataFrame(\n",
    "        {'year_beg':year_begs,'pom':poms,'no_hedge_current':no_hedge_currents,\n",
    "         'no_hedge_highest':no_hedge_highests,'with_hedge_current':with_hedge_currents,\n",
    "         'rebalanced_current':rebalanced_currents})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 05: Create scenarios for 3d display of returns vs year, percent out of money (pom), and rebalance percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_values_from_input_data(input_data):\n",
    "    bd = input_data[0]\n",
    "    ed = input_data[1]\n",
    "    perc_otm_string = input_data[2]\n",
    "    rebal_target_string = input_data[3]\n",
    "    rebal_adjust_string = input_data[4]\n",
    "    yyyymmdd_beg = int(bd[0:4])*100*100 + int(bd[5:7])*100 + int(bd[8:10])\n",
    "    yyyymmdd_end = int(ed[0:4])*100*100 + int(ed[5:7])*100 + int(ed[8:10])\n",
    "    new_pom = float(perc_otm_string)\n",
    "    new_rebal_target = float(rebal_target_string)\n",
    "    new_rebal_adjust = float(rebal_adjust_string)\n",
    "    return _get_df_values(yyyymmdd_beg,yyyymmdd_end,new_pom,new_rebal_target,new_rebal_adjust)\n",
    "\n",
    "def _get_df_values(yyyymmdd_beg,yyyymmdd_end,pom,rebal_target,rebal_adjust,\n",
    "                   years_to_hedge=1,data_inputs=None):\n",
    "    # validate values\n",
    "    new_pom = pom\n",
    "    new_rebal_target = rebal_target\n",
    "    new_rebal_adjust = rebal_adjust\n",
    "    dft_new = create_dft(new_pom,years_to_hedge,\n",
    "                       yyyymmdd_beg=yyyymmdd_beg,yyyymmdd_end=yyyymmdd_end,\n",
    "                        data_inputs=data_inputs)\n",
    "\n",
    "    df_values,df_daily_values,df_rebalance_info = create_comparative_returns(\n",
    "        dft_new,years_to_hedge,new_rebal_target,new_rebal_adjust,pom=new_pom)\n",
    "    df_values.current_value = df_values.current_value.round(3) \n",
    "    df_values['return'] = df_values['return'].round(3) \n",
    "    return dft_new,df_values,df_daily_values,df_rebalance_info\n",
    "\n",
    "\n",
    "def _get_close_vs_hedge_stock_vs_cash_figure(input_data):\n",
    "    dft_new,df_values,df_daily_values,_ = _get_df_values_from_input_data(input_data)\n",
    "    df_daily_values['current_hedge_strike'] = dft_new.current_hedge_strike\n",
    "    names = ['stock_perc','port_per_day','close','current_hedge_strike']\n",
    "    x_columns = ['date' for _ in range(len(names))]\n",
    "    yp_rows = [1,1,1,1]\n",
    "    yp_cols = [1,1,2,2]\n",
    "    yp_secondary = [False,True,False,False]\n",
    "    yp_yaxis_titles = ['Stock Percent','Portolio Value','S&P Price / Hedge Strike','S&P Price / Hedge Strike']\n",
    "    df_yp = pd.DataFrame({'name':names,'x_column':x_columns,\n",
    "                      'row':yp_rows,'col':yp_cols,'is_secondary':yp_secondary,\n",
    "                     'yaxis_title':yp_yaxis_titles})\n",
    "    sp_titles = ['Stock Perc vs Portfolio Value','S&P Price vs Hedge Strike']\n",
    "    fig =  dashapp.plotly_subplots(df_daily_values,df_yp,title=\"Portfolio Analysis\",\n",
    "                      num_ticks_to_display=10,subplot_titles=sp_titles) \n",
    "    fig = go.Figure(fig)\n",
    "    fig.update_layout(\n",
    "        legend=dict(x=-0.1, y=1.4),\n",
    "        modebar={'orientation': 'v','bgcolor':'grey'}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# def _get_scenarios_data_old(input_data):\n",
    "#     beg_year = int(str(input_data[0]))\n",
    "#     end_year = int(str(input_data[1]))\n",
    "#     beg_pom = float(str(input_data[2]))\n",
    "#     end_pom = float(str(input_data[3]))  \n",
    "#     all3_query = f\"(year>={beg_year}) and (year<={end_year}) and (pom>={beg_pom}) and (pom<={end_pom})\"\n",
    "#     dft_dict = build_scenarios(beg_year,end_year,beg_pom,end_pom,.6,.7)\n",
    "#     df_all3,df_all = build_3d_display_df(dft_dict)\n",
    "#     df_all3_scenarios = df_all3.query(all3_query)\n",
    "#     return [{'df_all3':df_all3_scenarios.to_dict('rows'),'df_all':df_all.to_dict('rows')}]\n",
    "\n",
    "def _get_scenarios_data(input_data):\n",
    "    df_every_scenario = EveryScenario().df_every_scenario\n",
    "    beg_year = int(str(input_data[0]))\n",
    "    end_year = int(str(input_data[1]))\n",
    "    beg_pom = float(str(input_data[2]))\n",
    "    end_pom = float(str(input_data[3]))  \n",
    "#     dft_dict = build_scenarios(beg_year,end_year,beg_pom,end_pom,.6,.7)\n",
    "#     df_all3,df_all = build_3d_display_df(dft_dict)\n",
    "    \n",
    "    yb = df_every_scenario.year_beg>=beg_year\n",
    "    ye = df_every_scenario.year_end==end_year\n",
    "    bp = df_every_scenario.pom>=beg_pom\n",
    "    ep = df_every_scenario.pom<=end_pom\n",
    "    df_all = df_every_scenario[yb & ye & bp & ep]\n",
    "    cols = ['year_beg','pom','no_hedge_current','no_hedge_highest','with_hedge_current','rebalanced_current']\n",
    "    df_all = df_all[cols]\n",
    "    df_all = df_all.rename(columns={'year_beg':'year'})\n",
    "\n",
    "    df_all2 = df_all[['year','pom','no_hedge_current']].copy()\n",
    "    df_all2 = df_all2.rename(columns={'no_hedge_current':'ret'})\n",
    "    df_all2['ret_type'] = 'no_hedge_current'\n",
    "    df_all2.index = list(range(len(df_all2)))\n",
    "    for c in ['no_hedge_highest','with_hedge_current','rebalanced_current']:\n",
    "        df_temp = df_all[['year','pom',c]].copy()\n",
    "        df_temp.index=list(range(len(df_temp)))\n",
    "        df_temp = df_temp.rename(columns={c:'ret'})\n",
    "        df_temp['ret_type'] = c\n",
    "        df_all2 = df_all2.append(df_temp,ignore_index=True)\n",
    "        df_all2.index = list(range(len(df_all2)))\n",
    "    df_all2.ret_type.unique()\n",
    "    df_all3 = df_all2.query(\"ret_type in ['with_hedge_current','rebalanced_current']\")\n",
    "    return [{'df_all3':df_all3.to_dict('rows'),'df_all':df_all.to_dict('rows')}]\n",
    "    \n",
    "\n",
    "def _get_scenarios_figure_from_data(input_data):\n",
    "    df_all3_scenarios = pd.DataFrame(input_data[0]['df_all3'])\n",
    "    fig = px.scatter_3d(df_all3_scenarios, x='pom', y='year', z='ret',color='ret_type')\n",
    "    fig.update_layout(\n",
    "        legend=dict(x=-0.1, y=1.2),\n",
    "        modebar={'orientation': 'v','bgcolor':'grey'}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def make_page_title(title_text,div_id=None,html_container=None,parent_class=None,\n",
    "                   panel_background_color='#CAE2EB'):\n",
    "    par_class = parent_class\n",
    "    if par_class is None:\n",
    "        par_class = dashapp.pnnm\n",
    "    htmc = html_container\n",
    "    if htmc is None:\n",
    "        htmc = html.H2\n",
    "        \n",
    "    title_parts = title_text.split('\\n')\n",
    "    \n",
    "\n",
    "    title_list = [htmc(tp,className=dashapp.pnncnm) for tp in title_parts]\n",
    "    r = dashapp.multi_row_panel(title_list,\n",
    "                 parent_class=par_class,\n",
    "                 div_id=div_id,\n",
    "                 panel_background_color=panel_background_color) \n",
    "    return r   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_every_scenario = None\n",
    "# for y in tqdm_notebook(range(2000,2021,1)):\n",
    "#     df_1 = build_all_scenarios(1990,y,.1,.18,.6,.7)\n",
    "#     df_1['year_end'] = y\n",
    "#     if df_every_scenario is None:\n",
    "#         df_every_scenario = df_1.copy()\n",
    "#     else:\n",
    "#         df_every_scenario = df_every_scenario.append(df_1,ignore_index=True)\n",
    "#     df_every_scenario.index = list(range(len(df_every_scenario)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scenarios(beg_year,end_year,low_pom,high_pom,rebal_target,rebal_adjust):\n",
    "    # determine yyyymmdd_end\n",
    "    dt_now = datetime.datetime.now()\n",
    "    yyyymmdd_end = end_year*100*100 + 1231\n",
    "    yyyymmdd_now = dt_to_yyyymmdd(dt_now)\n",
    "    yyyymmdd_end = min(yyyymmdd_end,yyyymmdd_now)\n",
    "    # create array of beg_years to loop on\n",
    "    beg_years = np.arange(beg_year,end_year,1)\n",
    "\n",
    "    #   loop on increasing beg_year, but holding end_year constant\n",
    "    dft_dict = {}\n",
    "    data_inputs = DataInputs()\n",
    "    for y in tqdm_notebook(beg_years):\n",
    "        yyyymmdd_beg = int(y)*100*100 + 101 \n",
    "        #    loop on pom\n",
    "        for pom in [round(x,2) for x in np.arange(low_pom,high_pom+.01,.02)]:\n",
    "            dft_new,df_values,df_daily_values,df_rebalance_info =_get_df_values(\n",
    "                yyyymmdd_beg,yyyymmdd_end,pom,rebal_target,rebal_adjust,\n",
    "                data_inputs=data_inputs)\n",
    "#             dft_dict[(y,pom)] = [dft_new,df_values,df_daily_values,df_rebalance_info] \n",
    "            dft_dict[(y,pom)] = [None,df_values,df_daily_values,df_rebalance_info] \n",
    "    return dft_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_3d_display_df(dft_dict):\n",
    "    no_hedge_current =   [a[1].iloc[1]['return'] for a in dft_dict.values()]\n",
    "    no_hedge_highest =    [a[1].iloc[2]['return'] for a in dft_dict.values()]\n",
    "    with_hedge_current = [a[1].iloc[3]['return'] for a in dft_dict.values()]\n",
    "    rebalanced_current =  [a[1].iloc[4]['return'] for a in dft_dict.values()]\n",
    "    year_pom_array = list(dft_dict.keys())\n",
    "    year_array = [a[0] for a in year_pom_array]\n",
    "    pom_array  = [a[1] for a in year_pom_array]\n",
    "    df_all = pd.DataFrame({\n",
    "        'year':year_array,\n",
    "        'pom':pom_array,\n",
    "        'no_hedge_current':no_hedge_current,\n",
    "        'no_hedge_highest':no_hedge_highest,\n",
    "        'with_hedge_current':with_hedge_current,\n",
    "        'rebalanced_current':rebalanced_current\n",
    "    })\n",
    "\n",
    "    df_all2 = df_all[['year','pom','no_hedge_current']].copy()\n",
    "    df_all2 = df_all2.rename(columns={'no_hedge_current':'ret'})\n",
    "    df_all2['ret_type'] = 'no_hedge_current'\n",
    "    df_all2.index = list(range(len(df_all2)))\n",
    "    for c in ['no_hedge_highest','with_hedge_current','rebalanced_current']:\n",
    "        df_temp = df_all[['year','pom',c]].copy()\n",
    "        df_temp.index=list(range(len(df_temp)))\n",
    "        df_temp = df_temp.rename(columns={c:'ret'})\n",
    "        df_temp['ret_type'] = c\n",
    "        df_all2 = df_all2.append(df_temp,ignore_index=True)\n",
    "        df_all2.index = list(range(len(df_all2)))\n",
    "    df_all2.ret_type.unique()\n",
    "    df_all3 = df_all2.query(\"ret_type in ['with_hedge_current','rebalanced_current']\")\n",
    "    return df_all3,df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 06: Define rows of the displayed single page web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_otm_style = {\"font-size\":\"18px\",\"text-align\":\"center\",\"position\":\"relative\",\n",
    "    \"display\":\"inline-block\",\"width\":\"130px\",\"height\":\"45px\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_put_perc_otm=.14\n",
    "init_low_pom = .10\n",
    "init_high_pom = .18\n",
    "init_rebal_target = .6\n",
    "init_rebal_adjust = .7\n",
    "init_years_to_hedge=1\n",
    "init_beg_year = 1990\n",
    "init_beg_yyyymmdd = init_beg_year*100*100 + 701\n",
    "init_end_yyyymmdd = 203001010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row 1\n",
    "def create_row_1(dap):\n",
    "    # ************ Create row 1 (the main title) *******************\n",
    "    app_title = \"\"\"Compare Put-Protected SP500 Strategies\n",
    "vs\n",
    "Various Buy and Hold Strategies\"\"\"\n",
    "    r1 = make_page_title(app_title,div_id='r1',html_container=html.H3)                  \n",
    "    return r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_values_to_df_strategy(df_values):\n",
    "    df_strategy_compare = df_values.copy()    \n",
    "    df_strategy_compare = df_strategy_compare.iloc[1:]\n",
    "    df_strategy_compare.return_type = ['Long 100% SP500 (Current)',\n",
    "    'Long 100% SP500 (Highest)',\n",
    "    'Put Protected 100% SP500 (Current)',\n",
    "    'SP500 (x%) and 1 Yr Treasury (y%) (Current)']\n",
    "    \n",
    "    df_strategy_compare.columns = [' '.join([w[0].upper()+w[1:] for w in c.split('_')]) for c in df_strategy_compare.columns.values]\n",
    "    \n",
    "    return df_strategy_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row 2\n",
    "def create_row_2(dap):\n",
    "    # ************ Create comparative returns data *******************\n",
    "    dft_new,df_values,df_daily_values,df_rebalance_info = _get_df_values(\n",
    "#         init_beg_yyyymmdd,dt_to_yyyymmdd(datetime.datetime.now()),\n",
    "        init_beg_yyyymmdd,init_end_yyyymmdd,\n",
    "        init_put_perc_otm,init_rebal_target,init_rebal_adjust,\n",
    "        years_to_hedge=init_years_to_hedge)\n",
    "    df_strategy_compare = df_values_to_df_strategy(df_values)\n",
    "    dt_values,_ = dashapp.make_dashtable('dt_values',df_in=df_strategy_compare,max_width=None)\n",
    "\n",
    "    \n",
    "    # ************ Create row 2 (the strategy results from one example run ) *********\n",
    "    r2_style = {\"font-size\":\"18px\",\"text-align\":\"center\"}\n",
    "    dpr_beg_date =  dashapp.make_datepicker(dft_new,'beg_dp','settle_dt',style=r2_style)\n",
    "    dpr_end_date =  dashapp.make_datepicker(dft_new,'end_dp','settle_dt',style=r2_style,\n",
    "                                            init_date=1)\n",
    "    # lambda to make dcc.Input's\n",
    "    dcc_input = lambda dccid,val:dcc.Input(\n",
    "        id=dccid,type=\"number\",value=val,style=put_otm_style,debounce=True,step=.001)\n",
    "        \n",
    "    put_otm_inputbox = dcc_input('put_otm_inputbox',init_put_perc_otm)\n",
    "    init_rebal_target_inputbox = dcc_input('init_rebal_target_inputbox',init_rebal_target)\n",
    "    init_rebal_adjust_inputbox = dcc_input('init_rebal_adjust_inputbox',init_rebal_adjust)\n",
    "\n",
    "    # row 2 column 1\n",
    "    r2c1_descripts = [\"begin date: \",\"end date: \",\n",
    "                      \"put% otm: \",\"rebal trg%: \",\"rebal adj%: \"]\n",
    "    r2c1_objs = [dpr_beg_date,dpr_end_date,put_otm_inputbox,\n",
    "                 init_rebal_target_inputbox,init_rebal_adjust_inputbox]\n",
    "    # lambda to make dashapp.multi_column_panel's\n",
    "    r2c1_lambda = lambda i:dashapp.multi_column_panel(\n",
    "        [html.Div(r2c1_descripts[i]),\n",
    "        r2c1_objs[i]],grid_template=['1fr 3fr'],\n",
    "        parent_class=\"aligncenter\")\n",
    "    r2c1 = dashapp.multi_row_panel([r2c1_lambda(i) for i in range(len(r2c1_objs))],\n",
    "        panel_background_color='#A6B2E2',parent_class=dashapp.pn,div_id='r2c1')\n",
    "    \n",
    "    # row 2 col 2 row 1\n",
    "    r2c2r1 = dashapp.nopanel_cell([html.H3(\"Compare Strategy Results\")])\n",
    "    # row 2 col 2 row 2\n",
    "    r2c2r2 = dashapp.multi_column_panel([dt_values],\n",
    "                                       parent_class=dashapp.pnncnm)\n",
    "    # row 2 column 2\n",
    "    r2c2 = dashapp.multi_row_panel([r2c2r1,r2c2r2],                                \n",
    "                                grid_template='1fr 4fr',div_id='r2c2')\n",
    "    # row 2\n",
    "    r2 = dashapp.multi_column_panel(\n",
    "        [r2c1,r2c2],grid_template='1fr 4fr',parent_class=dashapp.pn,div_id='r2')\n",
    "\n",
    "    #  create a DashLink between r2c1 and the df_values DataFrame in r2c2    \n",
    "    def _update_dt_values(input_data):\n",
    "        dft_new,df_values,_,_ = _get_df_values_from_input_data(input_data)\n",
    "        df_strategy_compare = df_values_to_df_strategy(df_values)\n",
    "        return [df_strategy_compare.to_dict('rows')]\n",
    "        \n",
    "    r2c1_intuplist = [(dpr_beg_date,'date'),(dpr_end_date,'date'),(put_otm_inputbox,'value'),\n",
    "        (init_rebal_target_inputbox,'value'),(init_rebal_adjust_inputbox,'value')]\n",
    "    r2c1_outlist = [('dt_values','data')]\n",
    "    r2_link = dashapp.DashLink(r2c1_intuplist,r2c1_outlist,io_callback=_update_dt_values)\n",
    "    return r2,r2_link,r2c1_intuplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row 3\n",
    "def create_row_3(dap,r2c1_intuplist):\n",
    "    # *************** Create row 3 ****************************\n",
    "    # row 3 subplot graphs\n",
    "    get_close_vs_hedge_stock_vs_cash = dcc.Graph(\n",
    "        id='get_close_vs_hedge_stock_vs_cash',style={'width':'90vw'})\n",
    "    def _update_close_vs_hedge_stock_vs_cash(input_data):\n",
    "        return [_get_close_vs_hedge_stock_vs_cash_figure(input_data)]\n",
    "    r3_link = dashapp.DashLink(\n",
    "        r2c1_intuplist,\n",
    "        [(get_close_vs_hedge_stock_vs_cash,'figure')],\n",
    "        io_callback=_update_close_vs_hedge_stock_vs_cash\n",
    "    )\n",
    "    \n",
    "    r3 = dashapp.multi_column_panel([get_close_vs_hedge_stock_vs_cash],\n",
    "                          parent_class=dashapp.pn,\n",
    "                          div_id='r3')\n",
    "    return r3,r3_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row 4\n",
    "def create_row_4(dap):\n",
    "    dft_new,df_values,df_daily_values,df_rebalance_info = _get_df_values(\n",
    "        init_beg_yyyymmdd,init_end_yyyymmdd,\n",
    "        init_put_perc_otm,init_rebal_target,init_rebal_adjust,\n",
    "        years_to_hedge=init_years_to_hedge)\n",
    "    \n",
    "    dt_dft,link_for_dynamic_paging = dashapp.make_dashtable(\n",
    "        'dt_dtc',df_in=dft_new,filtering=True,displayed_rows=0)\n",
    "    r4 = dashapp.panel_cell([dt_dft],div_id='r4')\n",
    "    return r4,link_for_dynamic_paging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_5(dap):\n",
    "    app_title2 = \"\"\"\n",
    "    Downside Put Protection (blue)\n",
    "    vs\n",
    "    60/40 Standard Portfolio Allocation (red)\n",
    "    \"\"\"\n",
    "    r5 = make_page_title(app_title2,div_id='r5',html_container=html.H5,\n",
    "                        panel_background_color='#fff2e6')                  \n",
    "    return r5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_6(dap,df_all_init):\n",
    "    # row 6 col 1 \n",
    "#     df_spy = get_redis_df('df_spy')\n",
    "#     init_beg_year = int(str(df_spy.settle_date.min())[:4])\n",
    "    beg_year_inputbox = dcc.Input(\n",
    "        id='beg_year_inputbox',type=\"number\",value=int(init_beg_year),\n",
    "        style=put_otm_style,debounce=True,step=1\n",
    "    )    \n",
    "    r6c1 = dashapp.multi_column_panel([html.Div(\"begin year: \"),\n",
    "                            beg_year_inputbox],grid_template=['1fr 3fr'],\n",
    "                                        parent_class=\"aligncenter\")\n",
    "    # row 6 col 2\n",
    "    init_end_year =  df_all_init.year.max()\n",
    "    end_year_inputbox = dcc.Input(\n",
    "        id='end_year_inputbox',type=\"number\",value=int(init_end_year),\n",
    "        style=put_otm_style,debounce=True,step=1\n",
    "    )    \n",
    "    r6c2 = dashapp.multi_column_panel([html.Div(\"end year: \"),\n",
    "                            end_year_inputbox],grid_template=['1fr 3fr'],\n",
    "                                        parent_class=\"aligncenter\")\n",
    "    # row 6 col 3\n",
    "    low_pom_inputbox = dcc.Input(\n",
    "        id='low_pom_inputbox',type=\"number\",value=init_low_pom,\n",
    "        style=put_otm_style,debounce=True,step=.001\n",
    "    )    \n",
    "    r6c3 = dashapp.multi_column_panel([html.Div(\"low% otm: \"),\n",
    "                            low_pom_inputbox],grid_template=['1fr 3fr'],\n",
    "                                        parent_class=\"aligncenter\")\n",
    "    # row 6 col 4\n",
    "    high_pom_inputbox = dcc.Input(\n",
    "        id='high_pom_inputbox',type=\"number\",value=init_high_pom,\n",
    "        style=put_otm_style,debounce=True,step=.001\n",
    "    )    \n",
    "    r6c4 = dashapp.multi_column_panel([html.Div(\"high% otm: \"),\n",
    "                            high_pom_inputbox],grid_template=['1fr 3fr'],\n",
    "                                        parent_class=\"aligncenter\")\n",
    "    # row 6\n",
    "    r6 = dashapp.multi_column_panel([r6c1,r6c2,r6c3,r6c4],\n",
    "                          parent_class=dashapp.pn,\n",
    "                          div_id='r6')\n",
    "    # Create scenario inputs\n",
    "    scenario_inputboxes = [beg_year_inputbox,end_year_inputbox,low_pom_inputbox,high_pom_inputbox]\n",
    "    scenario_inputs = [(v,'value') for v in scenario_inputboxes]\n",
    "\n",
    "    return r6,scenario_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_7(dap,scenario_inputs,df_all_init):\n",
    "    # Create data store that will hold the 2 main DataFrames for row 7\n",
    "    data_store = dcc.Store(id='data_store')\n",
    "    data_store_loading = dcc.Loading(\n",
    "        id='data_store_loading',children=[data_store],fullscreen=True)\n",
    "    # the dcc.Store object must be loaded into the DOM, eventhough it is not seen\n",
    "    data_store_link = dashapp.DashLink(\n",
    "        scenario_inputs,[(data_store,'data')],\n",
    "        io_callback=_get_scenarios_data\n",
    "    )\n",
    "\n",
    "    # Create the 3d multi scenario graph for row 7\n",
    "    no_zoom_config = dict({'scrollZoom': False})\n",
    "    graph_multi_scenarios = dcc.Graph(\n",
    "        id='graph_multi_scenarios',config=no_zoom_config,style={'width':'45vw'})\n",
    "    # Create the DashLink that links the graph to the input boxes in row 6\n",
    "    def _update_multi_scenarios(input_data):\n",
    "        f = _get_scenarios_figure_from_data(input_data)\n",
    "        return [f]\n",
    "    graph_multi_scenarios_link = dashapp.DashLink(\n",
    "        [(data_store,'data')],\n",
    "        [(graph_multi_scenarios,'figure')],\n",
    "        io_callback=_update_multi_scenarios\n",
    "    )\n",
    "    \n",
    "    # Create the row 7 col 2 DataFrame of data being displayed in row 7 col 1\n",
    "    # Create the title of the DataFrame\n",
    "    dt_multi_scenarios_title = make_page_title(\n",
    "        \"\"\"All Data\"\"\",\n",
    "        html_container=html.H3) \n",
    "    # Create the DashLink linked the DataFrame with row 6 inputs\n",
    "    dt_multi_scenarios,dt_multi_scenarios_nav_link = dashapp.make_dashtable(\n",
    "        \"dt_multi_scenarios\",df_all_init,input_store=data_store,\n",
    "        input_store_key='df_all',max_width=None)\n",
    "    \n",
    "    # Assemble row 7\n",
    "    # row 7 col 1 \n",
    "    r7c1 = dashapp.panel_cell(graph_multi_scenarios)\n",
    "    # row 7 col 2 row 1 \n",
    "    r7c2r1 = dt_multi_scenarios_title\n",
    "    # row 7 col 2 row 2\n",
    "    r7c2r2 = html.Div(dt_multi_scenarios,style={'width':'45vw'})\n",
    "    # row 7 col 2\n",
    "    r7c2 = dashapp.multi_row_panel([r7c2r1,r7c2r2],                                \n",
    "                                grid_template='1fr 10fr',div_id='r7c2')\n",
    "    # row 7\n",
    "    r7 = dashapp.multi_column_panel([r7c1,r7c2],\n",
    "                                    grid_template='1fr 1fr',\n",
    "                                    parent_class=dashapp.pnnc,\n",
    "                                    div_id='r7') \n",
    "    r7_div_list = [r7,data_store_loading]\n",
    "    r7_link_list = [data_store_link,graph_multi_scenarios_link,dt_multi_scenarios_nav_link]\n",
    "    return r7_div_list,r7_link_list \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 07: Assemble rows and launch the app\n",
    "1. Create an instance of DashApp, \n",
    "2. Create all of the html and dcc elements for each row\n",
    "3. Create the DashLinks for each row\n",
    "4. Call DashApp.create_app to create the main instance of Dash.app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 15:37:18,940 - root - DEBUG - dt_values entering create_dt_div\n",
      "2020-07-15 15:37:18,943 - root - DEBUG - dt_values exiting create_dt_div\n",
      "2020-07-15 15:37:19,115 - root - DEBUG - dt_dtc entering create_dt_div\n",
      "2020-07-15 15:37:19,119 - root - DEBUG - dt_dtc exiting create_dt_div\n",
      "2020-07-15 15:37:19,122 - root - DEBUG - dt_multi_scenarios entering create_dt_div\n",
      "2020-07-15 15:37:19,125 - root - DEBUG - dt_multi_scenarios exiting create_dt_div\n",
      "2020-07-15 15:37:19,139 - root - INFO - This app will run at the URL: http://127.0.0.1:8800/dps/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"dashapp.dashapp2\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 48] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6c4f164832f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# Create the dash app object by calling the create_app method of dap (the instance of DashApp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mmyapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_divs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapp_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'downside_put_strategy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl_base_pathname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/dps/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmyapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'127.0.0.1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8804\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/dash/dash.py\u001b[0m in \u001b[0;36mrun_server\u001b[0;34m(self, host, port, debug, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_prune_errors, **flask_run_options)\u001b[0m\n\u001b[1;32m   1507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Debugger PIN: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger_pin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mflask_run_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/flask/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;31m# reset the first request information if the development server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mrun_with_reloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreloader_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreloader_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mpassthrough_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m         )\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mmake_server\u001b[0;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mthreaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         return ThreadedWSGIServer(\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassthrough_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         )\n\u001b[1;32m    850\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress_family\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maf_unix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mHTTPServer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socketserver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_address, RequestHandlerClass, bind_and_activate)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbind_and_activate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_activate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;34m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0msocketserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCPServer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfqdn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socketserver.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_reuse_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSO_REUSEADDR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 48] Address already in use"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    panel_color = '#FFFFFA'\n",
    "    all_links = []\n",
    "    \n",
    "    init_end_year = int(datetime.datetime.now().year)\n",
    "#     dft_dict_init = build_scenarios(init_end_year-1,init_end_year,init_low_pom,init_high_pom,\n",
    "#                                init_rebal_target,init_rebal_adjust)\n",
    "#     df_all3_init,df_all_init = build_3d_display_df(dft_dict_init)\n",
    "    \n",
    "    df_all_init = pd.DataFrame(_get_scenarios_data([1990,2020,.1,.18])[0]['df_all'])\n",
    "    \n",
    "    # Create an instance of DashApp, which holds all of the html and dcc elements, \n",
    "    #    as well as all of the DashLinks, and finally creates the instance of Dash.app\n",
    "    dap = dashapp.DashApp()\n",
    "    \n",
    "    # *********** Assemble all of he rows and columns below ***************\n",
    "\n",
    "    # ************ Create row 1 (the main title) *******************\n",
    "    r1 = create_row_1(dap)\n",
    "\n",
    "    # *************** Create row 2 ****************************\n",
    "    r2,r2_link,r2c1_intuplist = create_row_2(dap)\n",
    "    all_links.append(r2_link)\n",
    "    \n",
    "    # *************** Create row 3 ****************************\n",
    "    r3,r3_link = create_row_3(dap,r2c1_intuplist)\n",
    "    all_links.append(r3_link)\n",
    "    \n",
    "    # ************ Create row 4 *******************\n",
    "    r4,r4_link = create_row_4(dap)\n",
    "    all_links.append(r4_link)\n",
    "    \n",
    "    # *********** Create row 5 (title for scenario analysis in rows 6 and 7) ********************\n",
    "    r5 = create_row_5(dap)\n",
    "    \n",
    "    # *********** Create row 6 ********************\n",
    "    r6,scenario_inputs = create_row_6(dap,df_all_init)\n",
    "    \n",
    "    # ******** Create row 7 (holds the multi scenario output graph and DataFrame) ******\n",
    "    r7_div_list,r7_link_list = create_row_7(dap,scenario_inputs,df_all_init)\n",
    "    \n",
    "    \n",
    "    tabs_styles = {\n",
    "    'height': '44px'\n",
    "    }\n",
    "    tab_style = {\n",
    "        'borderBottom': '1px solid #d6d6d6',\n",
    "        'padding': '6px',\n",
    "        'fontWeight': 'bold'\n",
    "    }\n",
    "\n",
    "    tab_selected_style = {\n",
    "        'borderTop': '1px solid #d6d6d6',\n",
    "        'borderBottom': '1px solid #d6d6d6',\n",
    "        'backgroundColor': '#119DFF',\n",
    "        'color': 'white',\n",
    "        'padding': '6px'\n",
    "    }\n",
    "\n",
    "    tab1_text=\"\"\"CLICK for: S&P Portfolios with/without Protection\"\"\"\n",
    "    tab2_text=\"\"\"CLICK for: Put Protect vs 60/40 Returns Scenarios\"\"\"\n",
    "    tab_divs = html.Div([r1,\n",
    "        dcc.Tabs(id='tabs-example', value='tab-1', children=[\n",
    "            dcc.Tab(label=tab1_text, value='tab-1', style=tab_style, selected_style=tab_selected_style),\n",
    "            dcc.Tab(label=tab2_text, value='tab-2', style=tab_style, selected_style=tab_selected_style),\n",
    "        ]),\n",
    "        html.Div(id='tabs-example-content')\n",
    "    ])\n",
    "    \n",
    "    def _render_tab(input_data):\n",
    "        tab = input_data[0]\n",
    "        if tab == 'tab-1':\n",
    "            return [html.Div([r2,r3])]\n",
    "        elif tab == 'tab-2':\n",
    "            return [html.Div([r6]+r7_div_list)]\n",
    "    \n",
    "    tabs_link = dashapp.DashLink([('tabs-example','value')],\n",
    "                         [('tabs-example-content','children')],\n",
    "                        _render_tab)\n",
    "    \n",
    "    all_links = all_links + r7_link_list + [tabs_link]\n",
    "\n",
    "    # Add all of the DashLinks to the DashApp instance (dap)\n",
    "    dap.add_links(all_links)\n",
    "    # Create the dash app object by calling the create_app method of dap (the instance of DashApp)\n",
    "    myapp = dap.create_app(tab_divs,app_title='downside_put_strategy',url_base_pathname='/dps/',run=False)\n",
    "    myapp.run_server(host='127.0.0.1',port=8804)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script dashapp_downside_put_hedge_strategy_on_sp500.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
