{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import ipdb\n",
    "import importlib\n",
    "# importlib.reload(db_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_TO_POSTGRES = False\n",
    "CONTRACT_LIST = ['ES']#['CL','CB']\n",
    "STRIKE_DIVISOR = 1\n",
    "csv_temp_path = './temp_folder/df_all_temp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_request(url,dict_headers=None):\n",
    "    '''\n",
    "    Example:\n",
    "    1. get google page\n",
    "        text_of_webpage =  do_request('https://www.google.com')\n",
    "    2. get text file from barchart daily \n",
    "        barchart_daily_text_file = do_request('http://acs.barchart.com/mri/data/opv07059.csv',dict_headers={\"Authorization\": \"Basic myauthcode\"})\n",
    "\n",
    "    '''\n",
    "    if dict_headers is None:\n",
    "        req = urllib.request.Request(url)\n",
    "    else:\n",
    "        req = urllib.request.Request(url, headers=dict_headers)\n",
    "    f = urllib.request.urlopen(req)\n",
    "    alines = f.read()#.decode('utf-8')\n",
    "    return alines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_daily(commod_code_list,yyyymmdd=None,barchart_auth_code=None,text_file_path=None):\n",
    "    '''\n",
    "    commod_code_list: like ['ES'] or ['CL','CB']\n",
    "    yyyymmdd: like 20190705.  It must be a date in the current month\n",
    "    Example:\n",
    "    df_this_day = build_daily(['ES'],20190705)\n",
    "    '''\n",
    "    tfp = './temp_folder/opv.txt' if text_file_path is None else text_file_path\n",
    "    ymd = yyyymmdd\n",
    "    if ymd is None:\n",
    "        # get yesterday\n",
    "        ymd = int((datetime.datetime.now()-datetime.timedelta(1)).strftime('%Y%m%d'))\n",
    "    bac = barchart_auth_code\n",
    "    if bac is None:\n",
    "        bac = open('./temp_folder/barchart_authcode.txt','r').read()\n",
    "    y = str(ymd)[3]\n",
    "    mm = str(ymd)[4:6]\n",
    "    dd = str(ymd)[6:8]\n",
    "    opv = 'opv' + mm + dd + y\n",
    "    url = f'http://acs.barchart.com/mri/data/{opv}.csv'\n",
    "    dict_header = {\"Authorization\": f\"Basic {bac}\"}\n",
    "    opvtxt = do_request(url,dict_headers=dict_header)\n",
    "    opvtxt = opvtxt.decode('utf-8')\n",
    "    open(tfp,'w').write(opvtxt)\n",
    "    builder = build_db.BuildDb(None,strike_divisor=1,\n",
    "                           contract_list=commod_code_list,write_to_database=False)\n",
    "    dft = builder.build_options_pg_from_csvs(tfp)\n",
    "    return dft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single day test for yesterday\n",
    "uncomment the line below to test for a single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_es = build_daily(commod_code_list=['CL','CB'])\n",
    "# df_es.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a range of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = None\n",
    "ipdb.set_trace()\n",
    "year = 2019\n",
    "month = 7\n",
    "day_list = [1,2,3,5,8,9]\n",
    "for day in tqdm_notebook(day_list):\n",
    "    yyyymmdd = year*100*100 + month*100 + day\n",
    "    print(f'executing yyyymmdd {yyyymmdd} at {datetime.datetime.now()}')\n",
    "    try:\n",
    "        df_temp = build_daily(commod_code_list=CONTRACT_LIST,yyyymmdd=yyyymmdd)\n",
    "        if df_all is None:\n",
    "            df_all = df_temp.copy()\n",
    "        else:\n",
    "            df_all = df_all.append(df_temp)\n",
    "            df_all.index = list(range(len(df_all)))\n",
    "    except Exception as e:\n",
    "        bdb.logger.warn(f'ERROR MAIN LOOP: {str(e)}')\n",
    "    \n",
    "# NOW WRITE THIS DATA FOR THIS YEAR\n",
    "df_all.to_csv(csv_temp_path,index=False)\n",
    "if WRITE_TO_POSTGRES:\n",
    "    bdb.logger.info(f'MAIN LOOP: writing data for year {yyyy} to database')\n",
    "    abspath = os.path.abspath(csv_temp_path)\n",
    "    bdb.pga.exec_sql_raw(f\"COPY sec_schema.options_table FROM '{abspath}' DELIMITER ',' CSV HEADER\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.shape)\n",
    "print(sorted(df_all.symbol.unique()))\n",
    "print(df_all.settle_date.min(),df_all.settle_date.max())\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
