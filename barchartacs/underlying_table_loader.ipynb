{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import importlib\n",
    "\n",
    "DB_USER_NAME = None\n",
    "DB_NAME = 'sec_db'\n",
    "SCHEMA_NAME = 'sec_schema'\n",
    "UNDERLYING_TABLE_NAME = 'underlying_table'\n",
    "FULL_TABLE_NAME = f'{SCHEMA_NAME}.{UNDERLYING_TABLE_NAME}'\n",
    "CSV_TEMP_PATH = './temp_folder/df_all_temp.csv'\n",
    "\n",
    "DELETE_ALL = False # set to True if you want to delete all data in postgres db for UNDERLYING_TABLE_NAME\n",
    "WRITE_DATA=False # set to True if you want to copy new data to postgres using psql copy \n",
    "zip_folder_parent = open('./temp_folder/zip_folder_parent.txt','r').read()\n",
    "futures_parent = f'{zip_folder_parent}/futures'\n",
    "\n",
    "\n",
    "# importlib.reload(db_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\n",
    "    1:'jan',\n",
    "    2:'feb',\n",
    "    3:'mar',\n",
    "    4:'apr',\n",
    "    5:'may',\n",
    "    6:'jun',\n",
    "    7:'jul',\n",
    "    8:'aug',\n",
    "    9:'sep',\n",
    "    10:'oct',\n",
    "    11:'nov',\n",
    "    12:'dec'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! YOU MUST SET MONTHS_TO_INCLUDE AND YEARS_TO_INCLUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS_TO_INCLUDE = ['sep']#['jul','aug']\n",
    "YEARS_TO_INCLUDE = list(np.arange(19,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_names_ordered = []\n",
    "for yy in YEARS_TO_INCLUDE:# np.arange(19,20):\n",
    "    if len(MONTHS_TO_INCLUDE)>0:\n",
    "        fnames = []\n",
    "        for mm in MONTHS_TO_INCLUDE:\n",
    "            fnames.append(glob.glob(f'{futures_parent}/*{mm}{yy}.txt')[0])\n",
    "    else:\n",
    "        fnames = glob.glob(f'{futures_parent}/*{yy}.txt')\n",
    "                          \n",
    "    d = {}\n",
    "    for fname in fnames:\n",
    "        mmm = fname.split('/')[-1].split('.txt')[0][0:-2][-3:]\n",
    "        d[mmm] = fname\n",
    "    fnames_ordered = [d[d1[m]] for m in d1.keys() if d1[m] in d]\n",
    "    all_names_ordered += fnames_ordered\n",
    "all_names_ordered\n",
    "\n",
    "df_all = None\n",
    "header = ['contract','month_year','yymmdd','open','high','low','close','volume','open_interest']\n",
    "\n",
    "for fname in tqdm_notebook(all_names_ordered):\n",
    "    df_temp = pd.read_csv(fname,header=None)\n",
    "    df_temp.columns = header\n",
    "    if df_all is None:\n",
    "        df_all = df_temp.copy()\n",
    "    else:\n",
    "        df_all = df_all.append(df_temp,ignore_index=True)\n",
    "        df_all.index = list(range(len(df_all)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_all.copy()#.iloc[:1000]\n",
    "isnas = df_temp.yymmdd.isna()\n",
    "df_temp = df_temp[~isnas]\n",
    "df_temp = df_temp[~df_temp.open_interest.isna()]\n",
    "df_temp.volume = df_temp.volume.fillna(0)\n",
    "df_temp = df_temp[df_temp.open.astype(str).str.count('\\.')<=1]\n",
    "df_temp.index = list(range(len(df_temp)))\n",
    "df_temp.loc[df_temp.month_year=='Y','month_year'] = '2099Z'\n",
    "symbols = df_temp.contract + df_temp.month_year.str.slice(-1,)  + df_temp.month_year.str.slice(2,4)\n",
    "settle_dates = ('20' + df_temp.yymmdd.astype(str)).astype(float).astype(int)\n",
    "opens = df_temp.open.astype(float)\n",
    "highs = df_temp.high.astype(float)\n",
    "lows = df_temp.low.astype(float)\n",
    "closes = df_temp.close.astype(float)\n",
    "volumes = df_temp.volume.astype(int)\n",
    "open_interests = df_temp.open_interest.astype(int)\n",
    "df_final = pd.DataFrame({'symbol':symbols,\n",
    "    'settle_date':settle_dates,\n",
    "    'open':opens,\n",
    "    'high':highs,\n",
    "    'low':lows,\n",
    "    'close':closes,\n",
    "    'adj_close':closes,\n",
    "    'volume':volumes,\n",
    "    'open_interest':open_interests})\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add month_num to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthnum = pd.read_csv('month_codes.csv')\n",
    "df_monthnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.symbol.str.slice(0,-3).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu2 = df_final.copy()\n",
    "dfu2['contract'] = dfu2.symbol.str.slice(0,-3)\n",
    "dfu2['year'] = dfu2.symbol.apply(lambda s: 2000 + int(s[-2:]))\n",
    "dfu2['month_code'] = dfu2.symbol.str.slice(-3,-2)\n",
    "dfu3 = dfu2.merge(df_monthnum,on='month_code',how='inner')\n",
    "dfu3['yyyymm'] = dfu3.year*100+dfu3.month_num\n",
    "display(dfu2.month_code.unique())\n",
    "dfu4 = dfu3[['contract','symbol','settle_date','yyyymm']]\n",
    "dfu4['contract_num'] =dfu4[['contract','settle_date','yyyymm']].groupby(['contract','settle_date']).yyyymm.rank()\n",
    "dfu4['contract_num'] = dfu4['contract_num'].astype(int)\n",
    "dfu4 = dfu4.sort_values(['settle_date','contract','yyyymm'])\n",
    "dfu4.index = list(range(len(dfu4)))\n",
    "print(len(df_final),len(dfu4))\n",
    "dfu5 = df_final.merge(dfu4[['symbol','settle_date','contract_num']],on=['symbol','settle_date'])\n",
    "dfu5.index = list(range(len(dfu5)))\n",
    "dfu5.open=dfu5.open.round(8)\n",
    "dfu5.high=dfu5.high.round(8)\n",
    "dfu5.low=dfu5.low.round(8)\n",
    "dfu5.close=dfu5.close.round(8)\n",
    "dfu5.adj_close = dfu5.adj_close.round(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all),len(df_final),len(dfu5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there dupes??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = ['symbol','settle_date']\n",
    "df_counts = dfu5[ag+['close']].groupby(ag,as_index=False).count()\n",
    "dupes_exist  = len(df_counts[df_counts.close>1])>0\n",
    "dupes_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if there are dupes, get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dupes_exist > 0:\n",
    "    dfu5 = dfu5.drop_duplicates()\n",
    "    dfu5.index = list(range(len(dfu5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show unique contract_num numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu5.contract_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WRITE THE DATA FOR ALL YEARs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create an instance of PgPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_temp_path = CSV_TEMP_PATH#'./temp_folder/df_all_temp.csv'\n",
    "print(os.path.abspath(csv_temp_path))\n",
    "pga = db_info.get_db_info()\n",
    "tbname = FULL_TABLE_NAME# 'sec_schema.underlying_table'\n",
    "print(tbname)\n",
    "col_tuple_list =   [('symbol','text'),('settle_date','integer'),('contract_num','integer'),\n",
    "     ('open','numeric'),('high','numeric'),('low','numeric'),('close','numeric'),\n",
    "     ('adj_close','numeric'),('volume','integer'),('open_interest','integer')]\n",
    "col_list = [l[0] for l in col_tuple_list]\n",
    "print(col_list)\n",
    "print(f'creating csv file {csv_temp_path}: {datetime.datetime.now()}')\n",
    "dfu5[col_list].to_csv(csv_temp_path,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all rows if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETE_ALL,WRITE_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DELETE_ALL:\n",
    "    # drop table\n",
    "    sql = f\"drop table IF EXISTS {tbname}\"\n",
    "    pga.exec_sql_raw(sql) \n",
    "    # re create it\n",
    "    table_create = f'create table {tbname}('\n",
    "    table_create += ','.join([f\"{l[0]} {l[1]} not null\" for l in col_tuple_list])\n",
    "    table_create += ', primary key(symbol,settle_date));'\n",
    "    pga.exec_sql_raw(table_create) \n",
    "    \n",
    "pga.get_sql(f\"select count(*) from {tbname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psql_copy():\n",
    "    copy_cmd = f\"\\COPY {FULL_TABLE_NAME} FROM '{CSV_TEMP_PATH}' DELIMITER ',' CSV HEADER;\"\n",
    "#     copy_cmd = f\"select count(*) from {FULL_TABLE_NAME};\"\n",
    "    username_clause = ''\n",
    "    if DB_USER_NAME is not None:\n",
    "        username_clause = f' -U {DB_USER_NAME} '\n",
    "    psql_cmd = f'psql {username_clause} -d sec_db -c \"CMD\"'\n",
    "    psql_cmd = psql_cmd.replace('CMD',copy_cmd)\n",
    "    if  WRITE_DATA:  # double check !!!\n",
    "       !{psql_cmd}\n",
    "    else:\n",
    "        print(psql_cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_contract(pga,contract,\n",
    "            month_code_clause=None,\n",
    "             settle_date_clause=None,\n",
    "             limit=None):\n",
    "    futtab = tbname\n",
    "    cl_month_code = '' if month_code_clause is None else f\"and substring(symbol,3,1) {month_code_clause}\"\n",
    "    cl_sd = '' if settle_date_clause is None else f\"and 'settle_date {settle_date_clause}\"\n",
    "    clim = '' if limit is None else f\"limit {limit}\"\n",
    "    other_criteria = f'{cl_month_code} {cl_sd} {clim}'\n",
    "    sql = f\"select * from {tbname} where substring(symbol,1,2) = '{contract}' {other_criteria};\"\n",
    "    print(sql)\n",
    "    df=  pga.get_sql(sql)\n",
    "    return df\n",
    "\n",
    "dfc = get_data_by_contract(pga,'CB',limit=3)\n",
    "display(dfc)\n",
    "dfc = get_data_by_contract(pga,'CB',month_code_clause=\"in ('G','N')\",limit=3)\n",
    "display(dfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_DATA:\n",
    "    psql_copy()\n",
    "#     clist = [l[0] for l in col_list]\n",
    "#     print(f'writing data all to database BEGIN: {datetime.datetime.now()}')\n",
    "#     abspath = os.path.abspath(csv_temp_path)\n",
    "#     sql = f\"COPY {tbname} FROM '{abspath}' DELIMITER ',' CSV HEADER;\"\n",
    "#     print(sql)\n",
    "#     print('open Dbeaver and copy the sql COPY command into it and execute it')\n",
    "#     print(f'writing data all to database END: {datetime.datetime.now()}')\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pga.get_sql(\"select * from sec_schema.underlying_table limit 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
