{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load downloaded zip futures files to Postgres DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import importlib\n",
    "import pathlib\n",
    "HOME_FOLDER = pathlib.Path.home()\n",
    "\n",
    "MMM_LIST = {\n",
    "    1:'jan',\n",
    "    2:'feb',\n",
    "    3:'mar',\n",
    "    4:'apr',\n",
    "    5:'may',\n",
    "    6:'jun',\n",
    "    7:'jul',\n",
    "    8:'aug',\n",
    "    9:'sep',\n",
    "    10:'oct',\n",
    "    11:'nov',\n",
    "    12:'dec'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Important constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER_NAME = None\n",
    "DB_PASSWORD = None\n",
    "DELETE_ALL = False # set to True if you want to delete all data in postgres db for UNDERLYING_TABLE_NAME\n",
    "WRITE_DATA=False # set to True if you want to copy new data to postgres using psql copy \n",
    "ZIP_FOLDER_PARENT = './temp_folder/zip_files' #os.path.join(HOME_FOLDER, 'barchart_downloads/barchart') \n",
    "BEGIN_YY = 21\n",
    "END_YY = 21\n",
    "MONTHS_TO_INCLUDE = ['feb','mar','apr','may','jun','jul'] #MMM_LIST.values() #['jul','aug']\n",
    "COMMODS_TO_INCLUDE = ['SB'] #['HO','RB','CL','NG','ES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(MMM_LIST.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variable derived from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_INCLUDE = list(np.arange(BEGIN_YY,END_YY+1))\n",
    "DB_NAME = 'sec_db'\n",
    "SCHEMA_NAME = 'sec_schema'\n",
    "UNDERLYING_TABLE_NAME = 'underlying_table'\n",
    "FULL_TABLE_NAME = f'{SCHEMA_NAME}.{UNDERLYING_TABLE_NAME}'\n",
    "CSV_TEMP_PATH = './temp_folder/df_all_temp.csv'\n",
    "FUTURES_ZIP_FOLDER = f'{ZIP_FOLDER_PARENT}/futures' \n",
    "FUTURES_UNZIP_FOLDER = './temp_folder/unzipfolder_futures'\n",
    "if not os.path.isdir(FUTURES_UNZIP_FOLDER):\n",
    "    print(f'futures unzip folder {FUTURES_UNZIP_FOLDER} being created')\n",
    "    os.mkdir(FUTURES_UNZIP_FOLDER)\n",
    "else:\n",
    "    print(f'futures unzip folder {FUTURES_UNZIP_FOLDER} already created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip futures files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_ordered = []\n",
    "for yy in YEARS_TO_INCLUDE:\n",
    "    if len(MONTHS_TO_INCLUDE)>0:\n",
    "        fnames = []\n",
    "        for mm in MONTHS_TO_INCLUDE:\n",
    "            txt_file_list = glob.glob(f'{FUTURES_ZIP_FOLDER}/*{mm}{yy}.txt')\n",
    "            if len(txt_file_list)>0:\n",
    "                fnames.append(txt_file_list[0])\n",
    "                continue\n",
    "            path_to_zip_file = glob.glob(f'{FUTURES_ZIP_FOLDER}/*{mm}{yy}.zip')[0]\n",
    "            zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "            zip_ref.extractall(FUTURES_UNZIP_FOLDER)\n",
    "            zip_ref.close()  \n",
    "            txt_file = glob.glob(f'{FUTURES_UNZIP_FOLDER}/*{mm}{yy}.txt')[0]\n",
    "            fnames.append(txt_file)\n",
    "                          \n",
    "    d = {}\n",
    "    for fname in fnames:\n",
    "        mmm = fname.split('/')[-1].split('.txt')[0][0:-2][-3:]\n",
    "        d[mmm] = fname\n",
    "    fnames_ordered = [d[MMM_LIST[m]] for m in MMM_LIST.keys() if MMM_LIST[m] in d]\n",
    "    all_names_ordered += fnames_ordered\n",
    "all_names_ordered\n",
    "\n",
    "df_all = None\n",
    "header = ['contract','month_year','yymmdd','open','high','low','close','volume','open_interest']\n",
    "\n",
    "for fname in tqdm_notebook(all_names_ordered):\n",
    "    df_temp = pd.read_csv(fname,header=None)\n",
    "    df_temp.columns = header\n",
    "    df_temp['commod'] = df_temp.contract.str.slice(0,2)\n",
    "    df_temp = df_temp[df_temp.commod.isin(COMMODS_TO_INCLUDE)]\n",
    "    if df_all is None:\n",
    "        df_all = df_temp.copy()\n",
    "    else:\n",
    "        df_all = df_all.append(df_temp,ignore_index=True)\n",
    "        df_all.index = list(range(len(df_all)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_all.copy()#.iloc[:1000]\n",
    "isnas = df_temp.yymmdd.isna()\n",
    "df_temp = df_temp[~isnas]\n",
    "df_temp = df_temp[~df_temp.open_interest.isna()]\n",
    "df_temp.volume = df_temp.volume.fillna(0)\n",
    "df_temp = df_temp[df_temp.open.astype(str).str.count('\\.')<=1]\n",
    "df_temp.index = list(range(len(df_temp)))\n",
    "df_temp.loc[df_temp.month_year=='Y','month_year'] = '2099Z'\n",
    "symbols = df_temp.contract + df_temp.month_year.str.slice(-1,)  + df_temp.month_year.str.slice(2,4)\n",
    "settle_dates = ('20' + df_temp.yymmdd.astype(str)).astype(float).astype(int)\n",
    "opens = df_temp.open.astype(float)\n",
    "highs = df_temp.high.astype(float)\n",
    "lows = df_temp.low.astype(float)\n",
    "closes = df_temp.close.astype(float)\n",
    "volumes = df_temp.volume.astype(int)\n",
    "open_interests = df_temp.open_interest.astype(int)\n",
    "df_final = pd.DataFrame({'symbol':symbols,\n",
    "    'settle_date':settle_dates,\n",
    "    'open':opens,\n",
    "    'high':highs,\n",
    "    'low':lows,\n",
    "    'close':closes,\n",
    "    'adj_close':closes,\n",
    "    'volume':volumes,\n",
    "    'open_interest':open_interests})\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add month_num to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthnum = pd.read_csv('month_codes.csv')\n",
    "df_monthnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.symbol.str.slice(0,-3).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu2 = df_final.copy()\n",
    "dfu2['contract'] = dfu2.symbol.str.slice(0,-3)\n",
    "dfu2['year'] = dfu2.symbol.apply(lambda s: 2000 + int(s[-2:]))\n",
    "dfu2['month_code'] = dfu2.symbol.str.slice(-3,-2)\n",
    "dfu3 = dfu2.merge(df_monthnum,on='month_code',how='inner')\n",
    "dfu3['yyyymm'] = dfu3.year*100+dfu3.month_num\n",
    "display(dfu2.month_code.unique())\n",
    "dfu4 = dfu3[['contract','symbol','settle_date','yyyymm']]\n",
    "dfu4['contract_num'] =dfu4[['contract','settle_date','yyyymm']].groupby(['contract','settle_date']).yyyymm.rank()\n",
    "dfu4['contract_num'] = dfu4['contract_num'].astype(int)\n",
    "dfu4 = dfu4.sort_values(['settle_date','contract','yyyymm'])\n",
    "dfu4.index = list(range(len(dfu4)))\n",
    "print(len(df_final),len(dfu4))\n",
    "dfu5 = df_final.merge(dfu4[['symbol','settle_date','contract_num']],on=['symbol','settle_date'])\n",
    "dfu5.index = list(range(len(dfu5)))\n",
    "dfu5.open=dfu5.open.round(8)\n",
    "dfu5.high=dfu5.high.round(8)\n",
    "dfu5.low=dfu5.low.round(8)\n",
    "dfu5.close=dfu5.close.round(8)\n",
    "dfu5.adj_close = dfu5.adj_close.round(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all),len(df_final),len(dfu5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there dupes??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = ['symbol','settle_date']\n",
    "df_counts = dfu5[ag+['close']].groupby(ag,as_index=False).count()\n",
    "dupes_exist  = len(df_counts[df_counts.close>1])>0\n",
    "dupes_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if there are dupes, get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dupes_exist > 0:\n",
    "    dfu5 = dfu5.drop_duplicates()\n",
    "    dfu5.index = list(range(len(dfu5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show unique contract_num numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu5.contract_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WRITE THE DATA FOR ALL YEARs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create an instance of PgPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_temp_path = CSV_TEMP_PATH#'./temp_folder/df_all_temp.csv'\n",
    "# pga = db_info.get_db_info()\n",
    "tbname = FULL_TABLE_NAME# 'sec_schema.underlying_table'\n",
    "col_tuple_list =   [('symbol','text'),('settle_date','integer'),('contract_num','integer'),\n",
    "     ('open','numeric'),('high','numeric'),('low','numeric'),('close','numeric'),\n",
    "     ('adj_close','numeric'),('volume','integer'),('open_interest','integer')]\n",
    "col_list = [l[0] for l in col_tuple_list]\n",
    "print(f'creating csv file {csv_temp_path}: {datetime.datetime.now()}')\n",
    "dfu5[col_list].to_csv(os.path.abspath(csv_temp_path),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all rows if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psql_copy():\n",
    "    copy_cmd = f\"\\COPY {FULL_TABLE_NAME} FROM '{os.path.abspath(CSV_TEMP_PATH)}' DELIMITER ',' CSV HEADER;\"\n",
    "#     copy_cmd = f\"select count(*) from {FULL_TABLE_NAME};\"\n",
    "    username_clause = ''\n",
    "    if DB_USER_NAME is not None and len(DB_USER_NAME)>0:\n",
    "        username_clause = f' -U {DB_USER_NAME} '\n",
    "    psql_cmd = f'psql {username_clause} -d sec_db -c \"CMD\"'\n",
    "    psql_cmd = psql_cmd.replace('CMD',copy_cmd)\n",
    "    if  WRITE_DATA:  # double check !!!\n",
    "       !{psql_cmd}\n",
    "    else:\n",
    "        print(psql_cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_by_contract(pga,contract,\n",
    "            month_code_clause=None,\n",
    "             settle_date_clause=None,\n",
    "             limit=None):\n",
    "    futtab = tbname\n",
    "    cl_month_code = '' if month_code_clause is None else f\"and substring(symbol,3,1) {month_code_clause}\"\n",
    "    cl_sd = '' if settle_date_clause is None else f\"and 'settle_date {settle_date_clause}\"\n",
    "    clim = '' if limit is None else f\"limit {limit}\"\n",
    "    other_criteria = f'{cl_month_code} {cl_sd} {clim}'\n",
    "    sql = f\"select * from {tbname} where substring(symbol,1,2) = '{contract}' {other_criteria};\"\n",
    "    print(sql)\n",
    "    df=  pga.get_sql(sql)\n",
    "    return df\n",
    "\n",
    "for commod in COMMODS_TO_INCLUDE:\n",
    "    dfc = get_data_by_contract(pga,commod,limit=3)\n",
    "    display(dfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if WRITE_DATA:\n",
    "psql_copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms_string = ','.join([f\"'{s}'\" for s in dfu5.symbol.str.slice(0,2).unique()])\n",
    "\n",
    "sql_cmd = f\"\"\"\n",
    "select substring(symbol,1,2),max(settle_date) from sec_schema.underlying_table \n",
    "where substring(symbol,1,2) in ({syms_string}) \n",
    "group by substring(symbol,1,2) order  by substring(symbol,1,2);\n",
    "\"\"\"\n",
    "pga.get_sql(sql_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert step_03_underlying_table_loader.ipynb --to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
