{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks builds 2 csv files for any commodity that you specify in the variable `SYMBOL_TO_RESEARCH`\n",
    "\n",
    "The csv files are then written to as follows:\n",
    "```\n",
    "df_iv_final.to_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "df_iv_skew.to_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "```\n",
    "\n",
    "They can be copied to the volgrid project to be used by the Dash server that displays skew graphs for ES, CL and CB (Brent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb\n",
    "import traceback\n",
    "\n",
    "MONTH_CODES = 'FGHJKMNQUVXZ'\n",
    "DICT_MONTH_NUMS = {MONTH_CODES[i]:i+1 for i in range(len(MONTH_CODES))}\n",
    "\n",
    "# importlib.reload(db_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n",
    "SYMBOL_TO_RESEARCH = 'CB'\n",
    "STRIKE_DIVISORS = {}\n",
    "\n",
    "# df_expiry_dates_additions = pd.read_csv('df_expiry_dates_additions.csv')\n",
    "df_expiry_dates_additions = pd.read_csv('live_option_expirations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USE_PYVOL = True\n",
    "def lam_pyvol(r):\n",
    "    try:\n",
    "        return implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "    except:\n",
    "        return -1\n",
    "# lam_pyvol = lambda r:implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "lam_mibian = lambda r:mibian.BS([r.close_y,r.strike,2,r.dte], callPrice=r.close_x).impliedVolatility\n",
    "\n",
    "def get_implieds(df,df_expiry_dates,contract):\n",
    "    df2 = df[['symbol','contract_num','pc','settle_date','strike','close_x','close_y']]\n",
    "    df2 = df2[(((df2.pc=='C' )& (df2.strike>=df2.close_y)) | ((df2.pc=='P' ) & (df2.strike<df2.close_y)))  & (df2.symbol.str.contains(contract))]\n",
    "    cnum = _get_contract_number_from_symbol(contract)\n",
    "    df2 = df2[df2.contract_num==2]\n",
    "    phigh = df2.close_y.max()\n",
    "    plow = df2.close_y.min()\n",
    "    high_strike = round(phigh * 1.3)\n",
    "    low_strike = round(plow * .7)\n",
    "    df2 = df2[(df2.strike>=low_strike) & (df2.strike<=high_strike)]\n",
    "\n",
    "    df9 = df2[df2.symbol==contract]\n",
    "    df9 = df9.merge(df_expiry_dates.rename(columns={'settle_date':'expiry'}),on='symbol',how='inner')\n",
    "    df9['syear'] = df9.settle_date.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['smon'] = df9.settle_date.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['sday'] = df9.settle_date.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['eyear'] = df9.expiry.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['emon'] = df9.expiry.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['eday'] = df9.expiry.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['sdatetime'] = df9.apply(lambda r:datetime.datetime(r.syear,r.smon,r.sday),axis=1)\n",
    "    df9['edatetime'] = df9.apply(lambda r:datetime.datetime(r.eyear,r.emon,r.eday),axis=1)\n",
    "    df9['dte'] = df9.edatetime - df9.sdatetime\n",
    "    df9.dte = df9.dte.dt.days\n",
    "    df9 = df9[['symbol','settle_date','pc','contract_num','strike','close_x','close_y','dte']]\n",
    "    df10 = df9.iloc[:len(df9)].copy()\n",
    "    df10.index = list(range(len(df10)))\n",
    "    if USE_PYVOL:\n",
    "        df10['iv'] = df10.apply(lam_pyvol,axis=1)\n",
    "    else:\n",
    "        n = 100\n",
    "        for i in tqdm_notebook(np.arange(0,len(df10)-n,n)):\n",
    "                df10.loc[i:i+n,'iv'] = df10.loc[i:i+n].apply(lam_mibian,axis=1)\n",
    "        print(f'doing remaining {datetime.datetime.now()}')\n",
    "        i = df10[df10.iv.isna()].index[0]\n",
    "        df10.loc[i:,'iv'] = df10.loc[i:].apply(lam_mbian,axis=1)\n",
    "        print(f'done with remaining {datetime.datetime.now()}')\n",
    "    return df10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example of using mibian for options calcs (we use py_vollib instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_mibian():\n",
    "    underlying=1.4565\n",
    "    strike=1.45\n",
    "    interest = 1\n",
    "    days=30\n",
    "    opt_info = [underlying,strike,interest,days]\n",
    "    c = mibian.BS(opt_info, volatility=20)\n",
    "    print(c.callPrice,\n",
    "    c.putPrice,\n",
    "    c.callDelta,\n",
    "    c.putDelta,\n",
    "    c.callDelta2,\n",
    "    c.putDelta2,\n",
    "    c.callTheta,\n",
    "    c.putTheta,\n",
    "    c.callRho,\n",
    "    c.putRho,\n",
    "    c.vega,\n",
    "    c.gamma)\n",
    "\n",
    "\n",
    "    co = mibian.BS(opt_info, callPrice=c.callPrice)\n",
    "    co.impliedVolatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show simple example of using py_vol package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_py_vollib():\n",
    "    #CL,Q2019,560P,07/02/2019,0.6,1.61,0.54,1.54,1997,4465\n",
    "    F = 56.25\n",
    "    K = 56\n",
    "    sigma = .366591539\n",
    "    flag = 'p'\n",
    "    t = 15/365.0\n",
    "    r = .025\n",
    "    discounted_call_price = black.black(flag, F, K, t, r, sigma)\n",
    "    dcp = 1.54\n",
    "    ivpy = implied_volatility.implied_volatility(dcp, F, K, r, t, flag)\n",
    "    ivmn = mibian.BS([F,K,2.5,15], callPrice=dcp).impliedVolatility\n",
    "    discounted_call_price,ivpy,ivmn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot(df_in,x_column,plot_title=None,\n",
    "                y_left_label=None,y_right_label=None,\n",
    "                bar_plot=False,figsize=(16,10),\n",
    "                number_of_ticks_display=20,\n",
    "                yaxis2_cols=None):\n",
    "    ya2c = [] if yaxis2_cols is None else yaxis2_cols\n",
    "    ycols = [c for c in df_in.columns.values if c != x_column]\n",
    "    # create tdvals, which will have x axis labels\n",
    "    td = list(df_in[x_column]) \n",
    "    nt = len(df_in)-1 if number_of_ticks_display > len(df_in) else number_of_ticks_display\n",
    "    spacing = len(td)//nt\n",
    "    tdvals = td[::spacing]\n",
    "    \n",
    "    # create data for graph\n",
    "    data = []\n",
    "    # iterate through all ycols to append to data that gets passed to go.Figure\n",
    "    for ycol in ycols:\n",
    "        if bar_plot:\n",
    "            b = go.Bar(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        else:\n",
    "            b = go.Scatter(x=td,y=df_in[ycol],name=ycol,yaxis='y' if ycol not in ya2c else 'y2')\n",
    "        data.append(b)\n",
    "\n",
    "    # create a layout\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        xaxis=dict(\n",
    "            ticktext=tdvals,\n",
    "            tickvals=tdvals,\n",
    "            tickangle=45,\n",
    "            type='category'),\n",
    "        yaxis=dict(\n",
    "            title='y main' if y_left_label is None else y_left_label\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='y alt' if y_right_label is None else y_right_label,\n",
    "            overlaying='y',\n",
    "            side='right'),\n",
    "        margin=Margin(\n",
    "            b=100\n",
    "        )        \n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define method to get a contract from postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _next_monthyear_code(contract):\n",
    "    code_val = contract[-3]\n",
    "    code_num = DICT_MONTH_NUMS[code_val]\n",
    "    y = int(contract[-2:])\n",
    "    if code_num+1>12:\n",
    "        next_code_num = 1\n",
    "        next_y = y + 1\n",
    "    else:\n",
    "        next_code_num = code_num+1\n",
    "        next_y = y\n",
    "    next_code_val = MONTH_CODES[next_code_num-1]\n",
    "    next_contract = contract[0:-3] + next_code_val + '%02d' %(next_y)\n",
    "    return next_contract\n",
    "\n",
    "def get_postgres_data(contract,strike_divisor=None):\n",
    "    '''\n",
    "    Get options and underlying data for ONLY ONE CONTRACT\n",
    "    '''\n",
    "    osql = f\"select * from {opttab} where symbol='{contract}';\"\n",
    "    dfo = pga.get_sql(osql)\n",
    "    if len(dfo)<10:\n",
    "        e = f'''\n",
    "        get_postgres_data ERROR: not enough option data for contract {contract} \n",
    "        '''\n",
    "        raise ValueError(e)\n",
    "    num_settle_days = len(dfo.settle_date.unique())\n",
    "    u_contract = contract\n",
    "    for i in range(12):\n",
    "        usql = f\"select * from {futtab} where symbol='{u_contract}';\"\n",
    "        dfu = pga.get_sql(usql)\n",
    "        if len(dfu) < num_settle_days:\n",
    "            u_contract = _next_monthyear_code(u_contract)\n",
    "            print(f'trying contract {u_contract}')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if len(dfu)< num_settle_days:\n",
    "        e = f'''\n",
    "        get_postgres_data ERROR: not enough underlying days found for options contract {contract} \n",
    "        where len(underlying) = {len(dfu)} and num_settle_days = {num_settle_days}\n",
    "        '''\n",
    "        raise ValueError(e)\n",
    "    # Merge options and futures data\n",
    "    dfu = dfu.rename(columns={'symbol':'u_symbol'})\n",
    "    df = dfo.merge(dfu,how='inner',on=['settle_date'])\n",
    "    # Get options expiration dates\n",
    "    df_expiry_dates = dfo[['symbol','settle_date']].groupby('symbol',as_index=False).max()\n",
    "    df_additions = df_expiry_dates_additions[df_expiry_dates_additions.symbol==contract]\n",
    "    df_additions = df_additions[['symbol','yyyymmdd_option']].rename(columns={'yyyymmdd_option':'settle_date'})\n",
    "    additional_symbols = df_additions.symbol.values\n",
    "    df_expiry_dates = df_expiry_dates[~df_expiry_dates.symbol.isin(additional_symbols)]\n",
    "    df_expiry_dates = df_expiry_dates.append(df_additions).sort_values('symbol').copy()\n",
    "    if strike_divisor is not None:\n",
    "        df.strike = df.strike/strike_divisor\n",
    "    return df,df_expiry_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_contract_number_from_symbol(symbol):\n",
    "    c = symbol[0:2]\n",
    "    if c in ['CL','CB','ES','GE','NG']:\n",
    "        return 2\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use py_vol to get options skews by percent in/out of the money (moneyness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in even \"amount in/out the money strikes, and interpolate their implied vols and skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_even_moneyness_strikes(df10):\n",
    "    # define amounts around the money which will help create strikes to add\n",
    "    moneyness = np.arange(.7,1.4,.05).round(6)\n",
    "    # define columns on which to execute groupby\n",
    "#     gb_cols = ['symbol','settle_date','pc','contract_num','dte','close_y']\n",
    "    gb_cols = ['symbol','settle_date','contract_num','dte','close_y']\n",
    "    # define function used in groupby.apply to create strikes and iv's at those strikes\n",
    "    #   where the strikes are an even amount from the money \n",
    "    #   (like .7, .8, ... 1, 1.1, 1.2, etc)\n",
    "    def _add_even_moneyness_strikes(df):\n",
    "        # get underlying from first row (the groupby makes them all the same)\n",
    "        r = df.iloc[0]\n",
    "        underlying = r.close_y\n",
    "        # create new rows to append to df, using only the gb_cols\n",
    "        df_ret1 = df.iloc[:len(moneyness)][gb_cols].copy()\n",
    "        # add nan iv's !!!! MUST BE np.nan - NOT None\n",
    "        df_ret1['iv'] = np.nan\n",
    "        # add new strikes\n",
    "        df_ret1['strike'] = moneyness * underlying\n",
    "        # append the new strikes\n",
    "        dfa = df.append(df_ret1,ignore_index=True,sort=True).copy()\n",
    "        df_ret2 = dfa.sort_values(['symbol','settle_date','pc','strike'])\n",
    "        df_ret2 = df_ret2.drop_duplicates(subset='strike')\n",
    "        # set the index to the strike so that interpolate works\n",
    "        df_ret2.index = df_ret2.strike\n",
    "        # create interpolated iv's\n",
    "        df_ret2['iv'] = df_ret2.iv.interpolate(method='polynomial', order=2)\n",
    "        # reset the index\n",
    "        df_ret2.index = list(range(len(df_ret2)))\n",
    "        return df_ret2\n",
    "\n",
    "    # start here\n",
    "    df11 = df10.groupby(gb_cols).apply(_add_even_moneyness_strikes).copy()\n",
    "    df11.index = list(range(len(df11)))\n",
    "    df11['moneyness'] = df11.strike / df11.close_y\n",
    "    df11.moneyness = df11.moneyness.round(4)\n",
    "\n",
    "    df12 = df11[(df11.moneyness.isin(moneyness)) & (~df11.iv.isna())].copy()\n",
    "    df12.moneyness  = df12.moneyness - 1\n",
    "    df12.index = list(range(len(df12)))\n",
    "    df12_atm = df12[df12.moneyness==0][['symbol','settle_date','pc','iv']]\n",
    "    df12_atm = df12_atm.rename(columns={'iv':'atm_iv'})\n",
    "    \n",
    "    df12_atm = df12_atm.drop_duplicates()\n",
    "    df12 = df12.merge(df12_atm,on=['symbol','settle_date','pc'],how='inner')\n",
    "    df12.moneyness = df12.moneyness.round(4)\n",
    "    df12['vol_skew'] = (df12.iv - df12.atm_iv).round(4)\n",
    "    return df12\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get all contracts in the options database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_contracts = pga.get_sql(f\"select distinct symbol from {opttab} where symbol~'^{SYMBOL_TO_RESEARCH}'\").sort_values('symbol').values.reshape(-1)\n",
    "len(all_contracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show last dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "select symbol, count(settle_date) from {opttab} \n",
    "where substring(symbol,1,2)='{SYMBOL_TO_RESEARCH}'\n",
    "group by symbol\n",
    "order by symbol;\n",
    "'''\n",
    "display.display(pga.get_sql(sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew_per_date_df(df):\n",
    "    '''\n",
    "    Find the first settle_date whose count of rows is equal to max count of rows.\n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df.symbol.unique()[0]\n",
    "    # get just that symbol's data\n",
    "    df12 = df[df.symbol==contract]\n",
    "    df_counts = df12[['settle_date','moneyness']].groupby('settle_date',as_index=False).count()\n",
    "    max_count = df_counts.moneyness.max()\n",
    "    first_max_count_settle_date = df_counts[df_counts.moneyness==max_count].iloc[0].settle_date\n",
    "    \n",
    "    df_ret = df12[df12.settle_date==first_max_count_settle_date][['moneyness']]\n",
    "    all_settle_dates = sorted(df_counts.settle_date.unique())\n",
    "    for settle_date in all_settle_dates:\n",
    "        df_temp = df12[df12.settle_date==settle_date][['moneyness','vol_skew']]\n",
    "        df_ret = df_ret.merge(df_temp,on='moneyness',how='outer')\n",
    "        df_ret = df_ret.rename(columns={'vol_skew':str(settle_date)})\n",
    "    df_ret = df_ret.sort_values('moneyness')\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew per contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_per_symbol(symbol,strike_divisor=None):\n",
    "    '''\n",
    "    For a symbol like CLM16 or EZH19, create 2 Dataframes\n",
    "      1. df_iv - contains rows of implied vols, for only the 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "      2. df_skew - contains one row per day of skew data of for 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "    '''\n",
    "    _exception = None\n",
    "    _stacktrace = None\n",
    "    df_iv = None\n",
    "    df_skew = None\n",
    "    try:\n",
    "        df,df_expiry_dates = get_postgres_data(symbol)\n",
    "        if len(df[df.contract_num==2])>0:\n",
    "            df10 = get_implieds(df,df_expiry_dates,symbol)\n",
    "            df12 = get_even_moneyness_strikes(df10)\n",
    "            df_sk = create_skew_per_date_df(df12)\n",
    "            df_skt = df_sk.T\n",
    "            df_skt.columns = df_skt.loc['moneyness']\n",
    "            df_skt = df_skt.iloc[1:].copy()\n",
    "            df_skt['symbol'] = symbol\n",
    "            df_skt['settle_date'] = df_skt.index\n",
    "            df_iv = df12.copy() \n",
    "            df_skew = df_skt.copy()\n",
    "    except Exception as e:\n",
    "        _exception = str(e)\n",
    "        _stacktrace = traceback.format_exc()\n",
    "    return df_iv,df_skew,_exception,_stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN LOOP\n",
    "#### Loop through all contracts and create DataFrames for implied vol and skew (`df_iv_final` and `df_iv_skew`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strike_div = None if SYMBOL_TO_RESEARCH not in STRIKE_DIVISORS.keys() else STRIKE_DIVISORS[SYMBOL_TO_RESEARCH]\n",
    "df_iv_final = None\n",
    "df_iv_skew = None\n",
    "dict_exceptions = {}\n",
    "dict_stacktraces = {}\n",
    "contracts = all_contracts\n",
    "if SYMBOL_TO_RESEARCH in ['ES','GE']:\n",
    "    contracts = [c for c in all_contracts if c[-3] in ['H','M','U','Z']]\n",
    "for contract in tqdm_notebook(contracts):\n",
    "    df12,df_skew,_exception,_stacktrace = skew_per_symbol(contract,strike_divisor=strike_div)\n",
    "    if _exception is not None:\n",
    "        dict_exceptions[contract] = _exception\n",
    "        dict_stacktraces[contract] = _stacktrace\n",
    "        continue\n",
    "    \n",
    "    if (df12 is None or len(df12)<1) or (df_skew is None or len(df_skew)<1):\n",
    "        if (df12 is None or len(df12)<1):\n",
    "            dict_exceptions[contract] = \"No data returned for df in skew_per_symbol\"\n",
    "        if (df_skew is None or len(df_skew)<1):\n",
    "            dict_exceptions[contract] = \"No data returned for df_skew in skew_per_symbol\"\n",
    "        continue\n",
    "    if df12 is not None:\n",
    "        if df_iv_final is None:\n",
    "            df_iv_final = df12.copy()\n",
    "        else:\n",
    "            df_iv_final = df_iv_final.append(df12,ignore_index=True)\n",
    "        if df_iv_skew is None:\n",
    "            df_iv_skew = df_skew.copy()\n",
    "        else:\n",
    "            df_iv_skew = df_iv_skew.append(df_skew,ignore_index=True)\n",
    "            df_iv_skew.index = list(range(len(df_iv_skew)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_iv_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to csv and print any exceptions that might have occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_exceptions)\n",
    "df_iv_final.to_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "df_iv_skew.to_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_skew(df,do_plot=False):\n",
    "    '''\n",
    "    Graph skew for ONLY ONE symbol.\n",
    "    If df contains more than one symbol, we will only graph the first symbol in the DataFrames    \n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df.symbol.unique()[0]\n",
    "    dfp = create_skew_per_date_df(df_iv_final[df_iv_final.symbol==contract])\n",
    "    \n",
    "#     display.display(dfp)\n",
    "    settle_dates = sorted([c for c in dfp.columns.values if c != 'moneyness'])\n",
    "    splits = list(np.arange(5,len(settle_dates),5))\n",
    "#     settle_date_strings = [str(yyyymmdd) for yyyymmdd in settle_dates]\n",
    "    settle_date_groups = np.split(np.array(settle_dates),splits)\n",
    "    ret_figs = []\n",
    "    for sdg in settle_date_groups:\n",
    "        sdg_sorted = [str(c) for c in sorted(sdg)]\n",
    "        cols = ['moneyness']+list(sdg_sorted)\n",
    "        dfp_sub = dfp[cols]\n",
    "        t = f'{contract} {sdg[0]} - {sdg[-1]}' \n",
    "        f = plotly_plot(dfp_sub,x_column='moneyness',plot_title=t,y_left_label='vol skew')\n",
    "        ret_figs.append(f)\n",
    "        if do_plot:\n",
    "            iplot(f)\n",
    "    return ret_figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same plots as above, but using a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_skew_subplots(df):\n",
    "    rfs = graph_skew(df)\n",
    "    n = 4   \n",
    "    # using list comprehension \n",
    "    rfs_groups = [rfs[i*n:(i + 1)*n] for i in range((len(rfs) + n - 1) // n )]  \n",
    "    for rfs_group in rfs_groups:\n",
    "        iplot(graph_skew_subplot_quad(rfs_group))\n",
    "    \n",
    "def graph_skew_subplot_quad(rfs):\n",
    "    '''\n",
    "    Use subplots to output the results of the method graph_skew above\n",
    "    '''\n",
    "    rows = 2#len(rfs)//2\n",
    "    f1 = tls.make_subplots(rows=rows, cols=2,  \n",
    "        shared_yaxes=False, \n",
    "        subplot_titles=[rfs[i]['layout'].title for i in range(len(rfs))],\n",
    "        horizontal_spacing=0.09,\n",
    "        vertical_spacing=0.11,                       \n",
    "        print_grid=False)\n",
    "\n",
    "    pl_width=900\n",
    "    pl_height=800 \n",
    "    title = 'Skew plots<br>'\n",
    "\n",
    "    f1['layout'].update(title=title,                                 \n",
    "        font= Font(family=\"Open Sans, sans-serif\"),\n",
    "        showlegend=True,     \n",
    "        hovermode='x',  \n",
    "        autosize=True,       \n",
    "        width=pl_width,       \n",
    "        height=pl_height,\n",
    "        plot_bgcolor='#EFECEA', \n",
    "        bargap=0.05,\n",
    "        margin=Margin(\n",
    "                      l=45,\n",
    "                      r=15,\n",
    "                      b=55,\n",
    "                      t=50\n",
    "        )\n",
    "    )    \n",
    "    for i in range(len(rfs)):\n",
    "        x = int(i/2) + 1\n",
    "        y = i % 2 + 1\n",
    "        f = rfs[i]\n",
    "        l = f.layout\n",
    "        \n",
    "        try:\n",
    "            yaxis = f'yaxis{i+1}'\n",
    "            xaxis = f'xaxis{i+1}'\n",
    "            if i < 10:\n",
    "                yaxis = yaxis.replace('1','') \n",
    "                xaxis = xaxis.replace('1','') \n",
    "            f1['layout'].update({xaxis:l.xaxis})\n",
    "            f1['layout'].update({yaxis:l.yaxis})\n",
    "            gname = f'chart {x,y}'#rfs[i]['layout'].title\n",
    "            for d in f.data:\n",
    "                data_y = f'y{i+1}'.replace('1','') \n",
    "                d['yaxis']=data_y\n",
    "                d['legendgroup'] =  gname\n",
    "                d['name'] = f\"{gname} {d.name}\"\n",
    "                f1.append_trace(d,x,y)\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            ipdb.set_trace()\n",
    "            print(f'graph_skew_subplots ERRORS: {str(e)}')\n",
    "    return f1\n",
    "# iplot(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_final[df_iv_final.symbol.str.contains(f'{SYMBOL_TO_RESEARCH}')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(list(set(df_iv_final.symbol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_plot=True\n",
    "clist = [c for c in all_contracts if (c[:2]==f'{SYMBOL_TO_RESEARCH}') & (c[-2:]=='19')]\n",
    "for c in clist:\n",
    "    dft = df_iv_final[df_iv_final.symbol==c]\n",
    "    if len(dft)<=0:\n",
    "        print(f'no data for symbol {c}')\n",
    "        continue\n",
    "    if grid_plot:\n",
    "        graph_skew_subplots(df_iv_final[df_iv_final.symbol==c])\n",
    "    else:\n",
    "        rls = graph_skew(df_iv_final[df_iv_final.symbol==c],do_plot=True)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
