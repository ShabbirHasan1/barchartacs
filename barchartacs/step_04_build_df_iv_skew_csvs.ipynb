{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebooks builds 2 csv files for any commodity that you specify in the variable `SYMBOL_TO_RESEARCH`\n",
    "\n",
    "The csv files are then written to as follows:\n",
    "```\n",
    "df_iv_final.to_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "df_iv_skew.to_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "```\n",
    "\n",
    "They can be copied to the volgrid project to be used by the Dash server that displays skew graphs for ES, CL, CB (Brent), and NG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 08:37:58,260 - numexpr.utils - INFO - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "from argparse import ArgumentParser\n",
    "from argparse import RawDescriptionHelpFormatter\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "from barchartacs import plotly_utilities as pu\n",
    "from barchartacs import cme_expirations as cmeexp\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from plotly.graph_objs.layout import Font,Margin\n",
    "from IPython import display\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import traceback\n",
    "import db_info\n",
    "MONTH_CODES = 'FGHJKMNQUVXZ'\n",
    "DICT_MONTH_NUMS = {MONTH_CODES[i]:i+1 for i in range(len(MONTH_CODES))}\n",
    "\n",
    "# importlib.reload(db_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sec_db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEBUG_IT=False\n",
    "opttab = 'sec_schema.options_table'\n",
    "futtab = 'sec_schema.underlying_table'\n",
    "pga = db_info.get_db_info()\n",
    "SYMBOL_TO_RESEARCH = 'ES'\n",
    "STRIKE_DIVISORS = {}\n",
    "\n",
    "# df_expiry_dates_additions = pd.read_csv('df_expiry_dates_additions.csv')\n",
    "df_expiry_dates_additions = pd.read_csv('live_option_expirations.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### methods to build options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_contract_number_from_symbol(symbol):\n",
    "    c = symbol[0:2]\n",
    "    if c in ['CL','ES','NG']:\n",
    "        return 2\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USE_PYVOL = True\n",
    "def lam_pyvol(r):\n",
    "    try:\n",
    "        return implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "    except:\n",
    "        return -1\n",
    "# lam_pyvol = lambda r:implied_volatility.implied_volatility(r.close_x,r.close_y,r.strike,.02,r.dte/365, r.pc.lower())\n",
    "lam_mibian = lambda r:mibian.BS([r.close_y,r.strike,2,r.dte], callPrice=r.close_x).impliedVolatility\n",
    "\n",
    "def get_implieds(df,df_expiry_dates,contract):\n",
    "    df2 = df[['symbol','contract_num','pc','settle_date','strike','close_x','close_y']]\n",
    "    df2 = df2[(((df2.pc=='C' )& (df2.strike>=df2.close_y)) | ((df2.pc=='P' ) & (df2.strike<df2.close_y)))  & (df2.symbol.str.contains(contract))]\n",
    "    cnum = _get_contract_number_from_symbol(contract)\n",
    "    df2 = df2[df2.contract_num==2]\n",
    "    phigh = df2.close_y.max()\n",
    "    plow = df2.close_y.min()\n",
    "    high_strike = round(phigh * 1.3)\n",
    "    low_strike = round(plow * .7)\n",
    "    df2 = df2[(df2.strike>=low_strike) & (df2.strike<=high_strike)]\n",
    "\n",
    "    df9 = df2[df2.symbol==contract]\n",
    "    df9 = df9.merge(df_expiry_dates.rename(columns={'settle_date':'expiry'}),on='symbol',how='inner')\n",
    "    df9['syear'] = df9.settle_date.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['smon'] = df9.settle_date.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['sday'] = df9.settle_date.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['eyear'] = df9.expiry.astype(str).str.slice(0,4).astype(int)\n",
    "    df9['emon'] = df9.expiry.astype(str).str.slice(4,6).astype(int)\n",
    "    df9['eday'] = df9.expiry.astype(str).str.slice(6,8).astype(int)\n",
    "    df9['sdatetime'] = df9.apply(lambda r:datetime.datetime(r.syear,r.smon,r.sday),axis=1)\n",
    "    df9['edatetime'] = df9.apply(lambda r:datetime.datetime(r.eyear,r.emon,r.eday),axis=1)\n",
    "    df9['dte'] = df9.edatetime - df9.sdatetime\n",
    "    df9.dte = df9.dte.dt.days\n",
    "    df9 = df9[['symbol','settle_date','pc','contract_num','strike','close_x','close_y','dte']]\n",
    "    df10 = df9.iloc[:len(df9)].copy()\n",
    "    df10.index = list(range(len(df10)))\n",
    "    if USE_PYVOL:\n",
    "        df10['iv'] = df10.apply(lam_pyvol,axis=1)\n",
    "    else:\n",
    "        n = 100\n",
    "        for i in tqdm_notebook(np.arange(0,len(df10)-n,n)):\n",
    "                df10.loc[i:i+n,'iv'] = df10.loc[i:i+n].apply(lam_mibian,axis=1)\n",
    "        print(f'doing remaining {datetime.datetime.now()}')\n",
    "        i = df10[df10.iv.isna()].index[0]\n",
    "        df10.loc[i:,'iv'] = df10.loc[i:].apply(lam_mbian,axis=1)\n",
    "        print(f'done with remaining {datetime.datetime.now()}')\n",
    "    return df10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example of using mibian for options calcs (we use py_vollib instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_mibian():\n",
    "    underlying=1.4565\n",
    "    strike=1.45\n",
    "    interest = 1\n",
    "    days=30\n",
    "    opt_info = [underlying,strike,interest,days]\n",
    "    c = mibian.BS(opt_info, volatility=20)\n",
    "    print(c.callPrice,\n",
    "    c.putPrice,\n",
    "    c.callDelta,\n",
    "    c.putDelta,\n",
    "    c.callDelta2,\n",
    "    c.putDelta2,\n",
    "    c.callTheta,\n",
    "    c.putTheta,\n",
    "    c.callRho,\n",
    "    c.putRho,\n",
    "    c.vega,\n",
    "    c.gamma)\n",
    "\n",
    "\n",
    "    co = mibian.BS(opt_info, callPrice=c.callPrice)\n",
    "    co.impliedVolatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show simple example of using py_vol package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_py_vollib():\n",
    "    #CL,Q2019,560P,07/02/2019,0.6,1.61,0.54,1.54,1997,4465\n",
    "    F = 56.25\n",
    "    K = 56\n",
    "    sigma = .366591539\n",
    "    flag = 'p'\n",
    "    t = 15/365.0\n",
    "    r = .025\n",
    "    discounted_call_price = black.black(flag, F, K, t, r, sigma)\n",
    "    dcp = 1.54\n",
    "    ivpy = implied_volatility.implied_volatility(dcp, F, K, r, t, flag)\n",
    "    ivmn = mibian.BS([F,K,2.5,15], callPrice=dcp).impliedVolatility\n",
    "    discounted_call_price,ivpy,ivmn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define method to get a contract from postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _next_monthyear_code(contract):\n",
    "    code_val = contract[-3]\n",
    "    code_num = DICT_MONTH_NUMS[code_val]\n",
    "    y = int(contract[-2:])\n",
    "    if code_num+1>12:\n",
    "        next_code_num = 1\n",
    "        next_y = y + 1\n",
    "    else:\n",
    "        next_code_num = code_num+1\n",
    "        next_y = y\n",
    "    next_code_val = MONTH_CODES[next_code_num-1]\n",
    "    next_contract = contract[0:-3] + next_code_val + '%02d' %(next_y)\n",
    "    return next_contract\n",
    "\n",
    "def get_symbol_expiries(df,symbol_col='symbol',is_option=True):\n",
    "    all_syms = df[symbol_col].unique()\n",
    "    all_expiries = [cmeexp.get_expiry(s,is_option=is_option) for s in all_syms]\n",
    "    all_expiries = [d.strftime('%Y%m%d') for d in all_expiries]\n",
    "    return pd.DataFrame({'symbol':all_syms,'settle_date':all_expiries})\n",
    "\n",
    "def get_postgres_data(contract,strike_divisor=None):\n",
    "    '''\n",
    "    Get options and underlying data for ONLY ONE CONTRACT\n",
    "    '''\n",
    "    osql = f\"select * from {opttab} where symbol='{contract}';\"\n",
    "    dfo = pga.get_sql(osql)\n",
    "    if len(dfo)<10:\n",
    "        e = f'''\n",
    "        get_postgres_data ERROR: not enough option data for contract {contract} \n",
    "        '''\n",
    "        raise ValueError(e)\n",
    "    num_settle_days = len(dfo.settle_date.unique())\n",
    "    u_contract = contract\n",
    "    for i in range(12):\n",
    "        usql = f\"select * from {futtab} where symbol='{u_contract}';\"\n",
    "        dfu = pga.get_sql(usql)\n",
    "        if len(dfu) < num_settle_days:\n",
    "            u_contract = _next_monthyear_code(u_contract)\n",
    "            print(f'trying contract {u_contract}')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if len(dfu)< num_settle_days:\n",
    "        e = f'''\n",
    "        get_postgres_data ERROR: not enough underlying days found for options contract {contract} \n",
    "        where len(underlying) = {len(dfu)} and num_settle_days = {num_settle_days}\n",
    "        '''\n",
    "        raise ValueError(e)\n",
    "    # Merge options and futures data\n",
    "    dfu = dfu.rename(columns={'symbol':'u_symbol'})\n",
    "    df = dfo.merge(dfu,how='inner',on=['settle_date'])\n",
    "    # Get options expiration dates\n",
    "#     df_expiry_dates = dfo[['symbol','settle_date']].groupby('symbol',as_index=False).max()\n",
    "#     df_expiry_dates = dfo[['symbol','settle_date']]\n",
    "#     df_additions = df_expiry_dates_additions[df_expiry_dates_additions.symbol==contract]\n",
    "#     df_additions = df_additions[['symbol','yyyymmdd_option']].rename(columns={'yyyymmdd_option':'settle_date'})\n",
    "#     additional_symbols = df_additions.symbol.values\n",
    "#     df_expiry_dates = df_expiry_dates[~df_expiry_dates.symbol.isin(additional_symbols)]\n",
    "#     df_expiry_dates = df_expiry_dates.append(df_additions).sort_values('symbol').copy()\n",
    "    df_expiry_dates = get_symbol_expiries(dfo)\n",
    "    if strike_divisor is not None:\n",
    "        df.strike = df.strike/strike_divisor\n",
    "    return df,df_expiry_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use py_vol to get options skews by percent in/out of the money (moneyness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in even \"amount in/out the money strikes, and interpolate their implied vols and skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_moneyness_strikes(df10):\n",
    "    # define amounts around the money which will help create strikes to add\n",
    "    moneyness = np.arange(.7,1.4,.05).round(6)\n",
    "    # define columns on which to execute groupby\n",
    "#     gb_cols = ['symbol','settle_date','pc','contract_num','dte','close_y']\n",
    "    gb_cols = ['symbol','settle_date','contract_num','dte','close_y']\n",
    "    # define function used in groupby.apply to create strikes and iv's at those strikes\n",
    "    #   where the strikes are an even amount from the money \n",
    "    #   (like .7, .8, ... 1, 1.1, 1.2, etc)\n",
    "    def _add_even_moneyness_strikes(df):\n",
    "        # get underlying from first row (the groupby makes them all the same)\n",
    "        r = df.iloc[0]\n",
    "        underlying = r.close_y\n",
    "        # create new rows to append to df, using only the gb_cols\n",
    "        df_ret1 = df.iloc[:len(moneyness)][gb_cols].copy()\n",
    "        # add nan iv's !!!! MUST BE np.nan - NOT None\n",
    "        df_ret1['iv'] = np.nan\n",
    "        # add new strikes\n",
    "        df_ret1['strike'] = moneyness * underlying\n",
    "        # append the new strikes\n",
    "        try:\n",
    "            # try with using the sort=True options for versions of pandas after 0.23\n",
    "            dfa = df.append(df_ret1,ignore_index=True,sort=True).copy()\n",
    "        except:\n",
    "            # otherwise do not specify sort\n",
    "            dfa = df.append(df_ret1,ignore_index=True).copy()\n",
    "        df_ret2 = dfa.sort_values(['symbol','settle_date','pc','strike'])\n",
    "        df_ret2 = df_ret2.drop_duplicates(subset='strike')\n",
    "        # set the index to the strike so that interpolate works\n",
    "        df_ret2.index = df_ret2.strike\n",
    "        # create interpolated iv's\n",
    "        df_ret2['iv'] = df_ret2.iv.interpolate(method='polynomial', order=2)\n",
    "        # reset the index\n",
    "        df_ret2.index = list(range(len(df_ret2)))\n",
    "        return df_ret2\n",
    "\n",
    "    # start here\n",
    "    df11 = df10.groupby(gb_cols).apply(_add_even_moneyness_strikes).copy()\n",
    "    df11.index = list(range(len(df11)))\n",
    "    df11['moneyness'] = df11.strike / df11.close_y\n",
    "    df11.moneyness = df11.moneyness.round(4)\n",
    "\n",
    "    df12 = df11[(df11.moneyness.isin(moneyness)) & (~df11.iv.isna())].copy()\n",
    "    df12.moneyness  = df12.moneyness - 1\n",
    "    df12.index = list(range(len(df12)))\n",
    "    df12_atm = df12[df12.moneyness==0][['symbol','settle_date','pc','iv']]\n",
    "    df12_atm = df12_atm.rename(columns={'iv':'atm_iv'})\n",
    "    \n",
    "    df12_atm = df12_atm.drop_duplicates()\n",
    "    df12_atm.pc = ''#np.nan\n",
    "    df12.pc = ''#np.nan\n",
    "\n",
    "    df12 = df12.merge(df12_atm,on=['symbol','settle_date','pc'],how='inner')\n",
    "\n",
    "    df12.moneyness = df12.moneyness.round(4)\n",
    "    df12['vol_skew'] = (df12.iv - df12.atm_iv).round(4)\n",
    "    return df12\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get all contracts in the options database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_contracts = pga.get_sql(f\"select distinct symbol from {opttab} where symbol~'^{SYMBOL_TO_RESEARCH}'\").sort_values('symbol').values.reshape(-1)\n",
    "len(all_contracts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show last dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew_per_date_df(df):\n",
    "    '''\n",
    "    Find the first settle_date whose count of rows is equal to max count of rows.\n",
    "    df: DataFrame from df_iv_final_SS.csv, where SS is like ES, CL, NG, etc.\n",
    "         df contains data for ONLY ONE SYMBOL\n",
    "    '''\n",
    "    # get the first symbol (which should be the only symbol)\n",
    "    contract = df.symbol.unique()[0]\n",
    "    # get just that symbol's data\n",
    "    df12 = df[df.symbol==contract]\n",
    "    df_counts = df12[['settle_date','moneyness']].groupby('settle_date',as_index=False).count()\n",
    "    max_count = df_counts.moneyness.max()\n",
    "    first_max_count_settle_date = df_counts[df_counts.moneyness==max_count].iloc[0].settle_date\n",
    "\n",
    "    df_ret2 = df12[df12.settle_date==first_max_count_settle_date][['moneyness']]\n",
    "    all_settle_dates = sorted(df_counts.settle_date.unique())\n",
    "    for settle_date in all_settle_dates:\n",
    "        df_temp = df12[df12.settle_date==settle_date][['moneyness','vol_skew']]\n",
    "        df_ret2 = df_ret2.merge(df_temp,on='moneyness',how='outer')\n",
    "        df_ret2 = df_ret2.rename(columns={'vol_skew':str(settle_date)})\n",
    "    df_ret2 = df_ret2.sort_values('moneyness')\n",
    "    df_ret2.index = list(range(len(df_ret2)))\n",
    "    df_ret3 = df_ret2.fillna(0)\n",
    "    df_ret3['csum'] = df_ret3.apply(lambda r: sum([r[c] for c in df_ret2.columns.values]),axis=1)\n",
    "    df_csum = df_ret3[['moneyness','csum']].groupby('moneyness',as_index=False).max()\n",
    "    df_ret4 = df_ret3.merge(df_csum,how='inner',on=['moneyness','csum']).drop_duplicates()\n",
    "    df_ret4.index = list(range(len(df_ret4)))\n",
    "    \n",
    "    # eliminate csum column from returned DataFrame\n",
    "    df_ret4 = df_ret4[[c for c in df_ret4.columns.values if 'csum' not in c]]\n",
    "    \n",
    "    # convert zero values to np.NaN, for those Out of the Money columns\n",
    "    for col in [c for c in df_ret4.columns.values if 'moneyness' not in c]:\n",
    "        df_ret4[col] = df_ret4[col].apply(lambda v: np.NaN if v==0.0 else v)\n",
    "    df_ret4[df_ret4.moneyness==0] = 0.0\n",
    "    return df_ret4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew per contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_per_symbol(symbol,strike_divisor=None):\n",
    "    '''\n",
    "    For a symbol like CLM16 or EZH19, create 2 Dataframes\n",
    "      1. df_iv - contains rows of implied vols, for only the 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "      2. df_skew - contains one row per day of skew data of for 'pseudo' strikes that are an even\n",
    "                 percent away from the money for each settle_date\n",
    "    '''\n",
    "    _exception = None\n",
    "    _stacktrace = None\n",
    "    df_iv = None\n",
    "    df_skew = None\n",
    "    try:\n",
    "        df,df_expiry_dates = get_postgres_data(symbol)\n",
    "        if len(df[df.contract_num==2])>0:\n",
    "            df10 = get_implieds(df,df_expiry_dates,symbol)\n",
    "            df12 = get_even_moneyness_strikes(df10)\n",
    "            df_sk = create_skew_per_date_df(df12)\n",
    "            df_sk.index = list(range(len(df_sk)))\n",
    "            df_skt = df_sk.T\n",
    "            df_skt.columns = df_skt.loc['moneyness']\n",
    "            df_skt = df_skt.iloc[1:].copy()\n",
    "            df_skt['symbol'] = symbol\n",
    "            df_skt['settle_date'] = df_skt.index\n",
    "            df_iv = df12.copy() \n",
    "            df_skew = df_skt.copy()\n",
    "    except Exception as e:\n",
    "        _exception = str(e)\n",
    "        _stacktrace = traceback.format_exc()\n",
    "    return df_iv,df_skew,_exception,_stacktrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN LOOP\n",
    "#### Loop through all contracts and create DataFrames for implied vol and skew (`df_iv_final` and `df_iv_skew`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd2686019c24a8a97616e8d50398b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing commodity: ES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c59cdddcb243f19715b1aa15720f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying contract ESV22\n",
      "trying contract ESX22\n",
      "trying contract ESZ22\n",
      "trying contract ESF23\n",
      "trying contract ESG23\n",
      "trying contract ESH23\n",
      "trying contract ESJ23\n",
      "trying contract ESK23\n",
      "trying contract ESM23\n",
      "trying contract ESN23\n",
      "trying contract ESQ23\n",
      "trying contract ESU23\n",
      "trying contract ESF23\n",
      "trying contract ESG23\n",
      "trying contract ESH23\n",
      "trying contract ESJ23\n",
      "trying contract ESK23\n",
      "trying contract ESM23\n",
      "trying contract ESN23\n",
      "trying contract ESQ23\n",
      "trying contract ESU23\n",
      "trying contract ESV23\n",
      "trying contract ESX23\n",
      "trying contract ESZ23\n",
      "{'ESH11': 'No data returned for df_skew in skew_per_symbol', 'ESH22': 'No data returned for df_skew in skew_per_symbol', 'ESH23': 'No data returned for df_skew in skew_per_symbol', 'ESM22': 'No data returned for df_skew in skew_per_symbol', 'ESM23': 'No data returned for df_skew in skew_per_symbol', 'ESU22': '\\n        get_postgres_data ERROR: not enough underlying days found for options contract ESU22 \\n        where len(underlying) = 0 and num_settle_days = 36\\n        ', 'ESU23': 'No data returned for df_skew in skew_per_symbol', 'ESZ22': '\\n        get_postgres_data ERROR: not enough underlying days found for options contract ESZ22 \\n        where len(underlying) = 0 and num_settle_days = 36\\n        ', 'ESZ23': 'No data returned for df_skew in skew_per_symbol', 'ESZ24': 'No data returned for df_skew in skew_per_symbol', 'ESZ25': 'No data returned for df_skew in skew_per_symbol'}\n",
      "processing commodity: CL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c40b711f114d58ad3fb949ca3e95a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CLF22': 'No data returned for df_skew in skew_per_symbol', 'CLF23': 'No data returned for df_skew in skew_per_symbol', 'CLG11': 'No data returned for df_skew in skew_per_symbol', 'CLG22': 'No data returned for df_skew in skew_per_symbol', 'CLG23': '\\n        get_postgres_data ERROR: not enough option data for contract CLG23 \\n        ', 'CLH22': 'No data returned for df_skew in skew_per_symbol', 'CLH23': 'No data returned for df_skew in skew_per_symbol', 'CLJ22': 'No data returned for df_skew in skew_per_symbol', 'CLK22': 'No data returned for df_skew in skew_per_symbol', 'CLM22': 'No data returned for df_skew in skew_per_symbol', 'CLM23': 'No data returned for df_skew in skew_per_symbol', 'CLM24': 'No data returned for df_skew in skew_per_symbol', 'CLM25': 'No data returned for df_skew in skew_per_symbol', 'CLN22': 'No data returned for df_skew in skew_per_symbol', 'CLQ22': 'No data returned for df_skew in skew_per_symbol', 'CLU22': 'No data returned for df_skew in skew_per_symbol', 'CLV22': 'No data returned for df_skew in skew_per_symbol', 'CLX21': 'No data returned for df_skew in skew_per_symbol', 'CLX22': 'No data returned for df_skew in skew_per_symbol', 'CLZ21': 'No data returned for df_skew in skew_per_symbol', 'CLZ22': 'No data returned for df_skew in skew_per_symbol', 'CLZ23': 'No data returned for df_skew in skew_per_symbol', 'CLZ24': 'No data returned for df_skew in skew_per_symbol', 'CLZ25': 'No data returned for df_skew in skew_per_symbol'}\n",
      "processing commodity: NG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e57ffc4809b40288c29f27c70324477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NGF12': 'No data returned for df_skew in skew_per_symbol', 'NGF22': 'No data returned for df_skew in skew_per_symbol', 'NGG12': 'No data returned for df_skew in skew_per_symbol', 'NGG22': 'No data returned for df_skew in skew_per_symbol', 'NGH12': 'No data returned for df_skew in skew_per_symbol', 'NGH22': 'No data returned for df_skew in skew_per_symbol', 'NGJ12': 'No data returned for df_skew in skew_per_symbol', 'NGJ22': 'No data returned for df_skew in skew_per_symbol', 'NGK12': 'No data returned for df_skew in skew_per_symbol', 'NGK22': 'No data returned for df_skew in skew_per_symbol', 'NGM12': 'No data returned for df_skew in skew_per_symbol', 'NGM22': 'No data returned for df_skew in skew_per_symbol', 'NGN11': 'No data returned for df_skew in skew_per_symbol', 'NGN22': 'No data returned for df_skew in skew_per_symbol', 'NGQ22': '\\n        get_postgres_data ERROR: not enough option data for contract NGQ22 \\n        ', 'NGU11': 'No data returned for df_skew in skew_per_symbol', 'NGV11': 'No data returned for df_skew in skew_per_symbol', 'NGV21': 'No data returned for df_skew in skew_per_symbol', 'NGX11': 'No data returned for df_skew in skew_per_symbol', 'NGX21': 'No data returned for df_skew in skew_per_symbol', 'NGZ21': 'No data returned for df_skew in skew_per_symbol'}\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    for sym_to_res in tqdm_notebook(['ES','CL','NG']):\n",
    "        SYMBOL_TO_RESEARCH = sym_to_res\n",
    "        print(f\"processing commodity: {SYMBOL_TO_RESEARCH}\")\n",
    "        all_contracts = pga.get_sql(f\"select distinct symbol from {opttab} where symbol~'^{SYMBOL_TO_RESEARCH}'\").sort_values('symbol').values.reshape(-1)\n",
    "        strike_div = None if SYMBOL_TO_RESEARCH not in STRIKE_DIVISORS.keys() else STRIKE_DIVISORS[SYMBOL_TO_RESEARCH]\n",
    "        df_iv_final = None\n",
    "        df_iv_skew = None\n",
    "        dict_exceptions = {}\n",
    "        dict_stacktraces = {}\n",
    "        contracts = all_contracts\n",
    "        if SYMBOL_TO_RESEARCH in ['ES','GE']:\n",
    "            contracts = [c for c in all_contracts if c[-3] in ['H','M','U','Z']]\n",
    "        for contract in tqdm_notebook(contracts):\n",
    "            df12,df_skew,_exception,_stacktrace = skew_per_symbol(contract,strike_divisor=strike_div)\n",
    "            if _exception is not None:\n",
    "                dict_exceptions[contract] = _exception\n",
    "                dict_stacktraces[contract] = _stacktrace\n",
    "                continue\n",
    "\n",
    "            if (df12 is None or len(df12)<1) or (df_skew is None or len(df_skew)<1):\n",
    "                if (df12 is None or len(df12)<1):\n",
    "                    dict_exceptions[contract] = \"No data returned for df in skew_per_symbol\"\n",
    "                if (df_skew is None or len(df_skew)<1):\n",
    "                    dict_exceptions[contract] = \"No data returned for df_skew in skew_per_symbol\"\n",
    "                continue\n",
    "            if df12 is not None:\n",
    "                if df_iv_final is None:\n",
    "                    df_iv_final = df12.copy()\n",
    "                else:\n",
    "                    df_iv_final = df_iv_final.append(df12,ignore_index=True)\n",
    "                if df_iv_skew is None:\n",
    "                    df_iv_skew = df_skew.copy()\n",
    "                else:\n",
    "                    df_iv_skew = df_iv_skew.append(df_skew,ignore_index=True)\n",
    "                    df_iv_skew.index = list(range(len(df_iv_skew)))\n",
    "\n",
    "        df_iv_final = df_iv_final.sort_values(['settle_date','moneyness'])\n",
    "        print(dict_exceptions)\n",
    "        df_iv_final.to_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "        df_iv_skew.to_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv',index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to csv and print any exceptions that might have occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dict_exceptions)\n",
    "# df_iv_final.to_csv(f'./temp_folder/df_iv_final_{SYMBOL_TO_RESEARCH}.csv',index=False)\n",
    "# df_iv_skew.to_csv(f'./temp_folder/df_iv_skew_{SYMBOL_TO_RESEARCH}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE ENDS HERE FOR BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook step_04_build_df_iv_skew_csvs.ipynb to script\n",
      "[NbConvertApp] Writing 17630 bytes to step_04_build_df_iv_skew_csvs.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script step_04_build_df_iv_skew_csvs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
